{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6. NYC_TaxiFare_XGBoost_GP_EI.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9wHutsqZUcn"
      },
      "source": [
        "XGBoost Regression - 'real-world' example: NYC Taxi-Fare Predictor\n",
        "\n",
        "https://www.kaggle.com/c/new-york-city-taxi-fare-prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7PwmXsgZO8D",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "5deffecc-0730-4d3d-b715-4b3c5c60db7f"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a5fae88a-e242-4db1-834d-05877b9b16c7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a5fae88a-e242-4db1-834d-05877b9b16c7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle (1).json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"conorc2006\",\"key\":\"c5c5a6382a7d50c022aab991694fc17f\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMwbJ6hjZltI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caa7f2eb-caca-44c4-aec5-a0041185c9b9"
      },
      "source": [
        "## Ensure the kaggle.json file is present:\n",
        "!ls -lha kaggle.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 66 Jun  9 10:12 kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8Pu-UlWZovH"
      },
      "source": [
        "## Next, install the Kaggle API client:\n",
        "!pip install -q kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUOQ4SE7Zuj3"
      },
      "source": [
        "## The Kaggle API Client expects this file to be ~/.kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJcEztjCZxOn"
      },
      "source": [
        "## Permissions' change\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-u4Tmj7ZUD3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b15c2e9f-ddd9-451b-aa18-ea7af39d0c7c"
      },
      "source": [
        "!kaggle competitions download -c new-york-city-taxi-fare-prediction"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "train.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "sample_submission.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "GCP-Coupons-Instructions.rtf: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-0Pe1i4Z2R_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bacc408b-d6d2-49ff-bc9c-eef2b96f45c8"
      },
      "source": [
        "!pip install pyGPGO"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyGPGO in /usr/local/lib/python3.7/dist-packages (0.4.0.dev1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (0.22.2.post1)\n",
            "Requirement already satisfied: pyMC3 in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (3.11.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.0.1)\n",
            "Requirement already satisfied: theano in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.0.5)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (0.5.1)\n",
            "Requirement already satisfied: arviz>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (0.11.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (0.3.3)\n",
            "Requirement already satisfied: semver in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (2.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (3.7.4.3)\n",
            "Requirement already satisfied: cachetools>=4.2.1 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (4.2.2)\n",
            "Requirement already satisfied: theano-pymc==1.1.2 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (1.1.2)\n",
            "Requirement already satisfied: fastprogress>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (1.0.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (1.1.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from theano->pyGPGO) (1.15.0)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (3.2.2)\n",
            "Requirement already satisfied: setuptools>=38.4 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (57.0.0)\n",
            "Requirement already satisfied: netcdf4 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (1.5.6)\n",
            "Requirement already satisfied: xarray>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (0.18.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (20.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from theano-pymc==1.1.2->pyMC3->pyGPGO) (3.0.12)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->pyMC3->pyGPGO) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->pyMC3->pyGPGO) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (1.3.1)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.7/dist-packages (from netcdf4->arviz>=0.11.0->pyMC3->pyGPGO) (1.5.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7zDTf1naBsH"
      },
      "source": [
        "# Load some default Python modules:\n",
        "\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import xgboost as xgb\n",
        "import time\n",
        "\n",
        "from matplotlib.pyplot import rc\n",
        "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
        "rc('text', usetex=False)\n",
        "import seaborn as sns\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "\n",
        "from collections import OrderedDict\n",
        "from joblib import Parallel, delayed\n",
        "from numpy.linalg import slogdet, inv, cholesky, solve\n",
        "from scipy.optimize import minimize\n",
        "from scipy.spatial.distance import cdist\n",
        "from scipy.special import gamma\n",
        "from scipy.stats import norm, t\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "from pyGPGO.logger import EventLogger\n",
        "from pyGPGO.GPGO import GPGO\n",
        "from pyGPGO.surrogates.GaussianProcess import GaussianProcess\n",
        "from pyGPGO.surrogates.tStudentProcess import tStudentProcess\n",
        "from pyGPGO.surrogates.tStudentProcess import logpdf\n",
        "from pyGPGO.acquisition import Acquisition\n",
        "from pyGPGO.covfunc import squaredExponential\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from xgboost import XGBRegressor\n",
        "from pandas_datareader import data\n",
        "\n",
        "import warnings\n",
        "import random\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXicekJhaE0P"
      },
      "source": [
        "# Read data in pandas dataframe:\n",
        "\n",
        "df_train =  pd.read_csv('/content/train.csv.zip', nrows = 1_000_000, parse_dates=[\"pickup_datetime\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ0mDzt_cBmw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "12ca978d-1c25-4618-9344-b19a2a40672e"
      },
      "source": [
        "# List first rows:\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>key</th>\n",
              "      <th>fare_amount</th>\n",
              "      <th>pickup_datetime</th>\n",
              "      <th>pickup_longitude</th>\n",
              "      <th>pickup_latitude</th>\n",
              "      <th>dropoff_longitude</th>\n",
              "      <th>dropoff_latitude</th>\n",
              "      <th>passenger_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2009-06-15 17:26:21.0000001</td>\n",
              "      <td>4.5</td>\n",
              "      <td>2009-06-15 17:26:21+00:00</td>\n",
              "      <td>-73.844311</td>\n",
              "      <td>40.721319</td>\n",
              "      <td>-73.841610</td>\n",
              "      <td>40.712278</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010-01-05 16:52:16.0000002</td>\n",
              "      <td>16.9</td>\n",
              "      <td>2010-01-05 16:52:16+00:00</td>\n",
              "      <td>-74.016048</td>\n",
              "      <td>40.711303</td>\n",
              "      <td>-73.979268</td>\n",
              "      <td>40.782004</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-08-18 00:35:00.00000049</td>\n",
              "      <td>5.7</td>\n",
              "      <td>2011-08-18 00:35:00+00:00</td>\n",
              "      <td>-73.982738</td>\n",
              "      <td>40.761270</td>\n",
              "      <td>-73.991242</td>\n",
              "      <td>40.750562</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2012-04-21 04:30:42.0000001</td>\n",
              "      <td>7.7</td>\n",
              "      <td>2012-04-21 04:30:42+00:00</td>\n",
              "      <td>-73.987130</td>\n",
              "      <td>40.733143</td>\n",
              "      <td>-73.991567</td>\n",
              "      <td>40.758092</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2010-03-09 07:51:00.000000135</td>\n",
              "      <td>5.3</td>\n",
              "      <td>2010-03-09 07:51:00+00:00</td>\n",
              "      <td>-73.968095</td>\n",
              "      <td>40.768008</td>\n",
              "      <td>-73.956655</td>\n",
              "      <td>40.783762</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             key  ...  passenger_count\n",
              "0    2009-06-15 17:26:21.0000001  ...                1\n",
              "1    2010-01-05 16:52:16.0000002  ...                1\n",
              "2   2011-08-18 00:35:00.00000049  ...                2\n",
              "3    2012-04-21 04:30:42.0000001  ...                1\n",
              "4  2010-03-09 07:51:00.000000135  ...                1\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9fZujMycFMo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b02d77e-97e6-48a3-c7ab-eb9d92df85d5"
      },
      "source": [
        "# Format 'pickup_datetime' variable:\n",
        "\n",
        "df_train['pickup_datetime'] =  pd.to_datetime(df_train['pickup_datetime'], utc=True, format='%Y-%m-%d %H:%M')\n",
        "df_train['pickup_datetime'].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0   2009-06-15 17:26:21+00:00\n",
              "1   2010-01-05 16:52:16+00:00\n",
              "2   2011-08-18 00:35:00+00:00\n",
              "3   2012-04-21 04:30:42+00:00\n",
              "4   2010-03-09 07:51:00+00:00\n",
              "Name: pickup_datetime, dtype: datetime64[ns, UTC]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nReKu62HcVFI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "bc93fd3f-7681-49f6-d881-c9d759e6920e"
      },
      "source": [
        "df_train.sort_values(by = 'pickup_datetime').tail() ### June 2015 the final month\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>key</th>\n",
              "      <th>fare_amount</th>\n",
              "      <th>pickup_datetime</th>\n",
              "      <th>pickup_longitude</th>\n",
              "      <th>pickup_latitude</th>\n",
              "      <th>dropoff_longitude</th>\n",
              "      <th>dropoff_latitude</th>\n",
              "      <th>passenger_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>286276</th>\n",
              "      <td>2015-06-30 23:38:21.0000003</td>\n",
              "      <td>26.5</td>\n",
              "      <td>2015-06-30 23:38:21+00:00</td>\n",
              "      <td>-74.008385</td>\n",
              "      <td>40.711571</td>\n",
              "      <td>-73.884071</td>\n",
              "      <td>40.737385</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>955575</th>\n",
              "      <td>2015-06-30 23:45:57.0000003</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2015-06-30 23:45:57+00:00</td>\n",
              "      <td>-74.002342</td>\n",
              "      <td>40.739819</td>\n",
              "      <td>-74.005829</td>\n",
              "      <td>40.745239</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>915826</th>\n",
              "      <td>2015-06-30 23:48:35.0000005</td>\n",
              "      <td>30.5</td>\n",
              "      <td>2015-06-30 23:48:35+00:00</td>\n",
              "      <td>-73.983826</td>\n",
              "      <td>40.729546</td>\n",
              "      <td>-73.927917</td>\n",
              "      <td>40.661186</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>751350</th>\n",
              "      <td>2015-06-30 23:53:23.0000002</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2015-06-30 23:53:23+00:00</td>\n",
              "      <td>-73.978020</td>\n",
              "      <td>40.757439</td>\n",
              "      <td>-73.980705</td>\n",
              "      <td>40.753544</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>785182</th>\n",
              "      <td>2015-06-30 23:53:49.0000003</td>\n",
              "      <td>7.5</td>\n",
              "      <td>2015-06-30 23:53:49+00:00</td>\n",
              "      <td>-73.959969</td>\n",
              "      <td>40.762405</td>\n",
              "      <td>-73.953064</td>\n",
              "      <td>40.782688</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                key  ...  passenger_count\n",
              "286276  2015-06-30 23:38:21.0000003  ...                5\n",
              "955575  2015-06-30 23:45:57.0000003  ...                1\n",
              "915826  2015-06-30 23:48:35.0000005  ...                2\n",
              "751350  2015-06-30 23:53:23.0000002  ...                1\n",
              "785182  2015-06-30 23:53:49.0000003  ...                1\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9j9LnIfcXcX"
      },
      "source": [
        "# Add time variables:\n",
        "\n",
        "df_train['hour'] = df_train['pickup_datetime'].dt.hour\n",
        "df_train['weekday'] = df_train['pickup_datetime'].dt.weekday\n",
        "df_train['month'] = df_train['pickup_datetime'].dt.month\n",
        "df_train['year'] = df_train['pickup_datetime'].dt.year\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVyFZIVIcaj3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "c60d0f2e-bb6f-4415-b6dc-ce2530ccdee9"
      },
      "source": [
        "df_train = df_train.drop(['pickup_datetime','key'], axis = 1)\n",
        "df_train.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fare_amount</th>\n",
              "      <th>pickup_longitude</th>\n",
              "      <th>pickup_latitude</th>\n",
              "      <th>dropoff_longitude</th>\n",
              "      <th>dropoff_latitude</th>\n",
              "      <th>passenger_count</th>\n",
              "      <th>hour</th>\n",
              "      <th>weekday</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.5</td>\n",
              "      <td>-73.844311</td>\n",
              "      <td>40.721319</td>\n",
              "      <td>-73.841610</td>\n",
              "      <td>40.712278</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16.9</td>\n",
              "      <td>-74.016048</td>\n",
              "      <td>40.711303</td>\n",
              "      <td>-73.979268</td>\n",
              "      <td>40.782004</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.7</td>\n",
              "      <td>-73.982738</td>\n",
              "      <td>40.761270</td>\n",
              "      <td>-73.991242</td>\n",
              "      <td>40.750562</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>2011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.7</td>\n",
              "      <td>-73.987130</td>\n",
              "      <td>40.733143</td>\n",
              "      <td>-73.991567</td>\n",
              "      <td>40.758092</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>2012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.3</td>\n",
              "      <td>-73.968095</td>\n",
              "      <td>40.768008</td>\n",
              "      <td>-73.956655</td>\n",
              "      <td>40.783762</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2010</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fare_amount  pickup_longitude  pickup_latitude  ...  weekday  month  year\n",
              "0          4.5        -73.844311        40.721319  ...        0      6  2009\n",
              "1         16.9        -74.016048        40.711303  ...        1      1  2010\n",
              "2          5.7        -73.982738        40.761270  ...        3      8  2011\n",
              "3          7.7        -73.987130        40.733143  ...        5      4  2012\n",
              "4          5.3        -73.968095        40.768008  ...        1      3  2010\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVfm-KSqcdVY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "924a7999-f3ed-46b8-9285-413a8b73e7a7"
      },
      "source": [
        "# Remove negative fares and postive outliers:\n",
        "\n",
        "df_train = df_train[df_train.fare_amount>=0]\n",
        "df_train = df_train[df_train.fare_amount<=60]\n",
        "print('New size: %d' % len(df_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "New size: 997297\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTVDAD2KchTv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8c33b27-7632-45c5-de0b-fed4bee08e04"
      },
      "source": [
        "# Remove missing data:\n",
        "\n",
        "df_train = df_train.dropna(how = 'any', axis = 'rows')\n",
        "print('New size: %d' % len(df_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "New size: 997288\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUYksJ2cclVQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c14bfa47-5ced-42fd-8d97-c931db716f47"
      },
      "source": [
        "# June 2015 NYC taxi data (Wu et al, 2017):\n",
        "\n",
        "df_train = df_train[df_train.month==6]\n",
        "df_train = df_train[df_train.year==2015]\n",
        "print('New size: %d' % len(df_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "New size: 11269\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXgSHPyYcnuv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "e59423a8-27e9-46fa-fd1f-1a7c56a124a7"
      },
      "source": [
        "# Histogram fare plot:\n",
        "\n",
        "df_train[df_train.fare_amount<15].fare_amount.hist(bins=100, figsize=(16,5), color = \"red\")\n",
        "plt.xlabel('$ US Dollars', weight = 'bold', family = 'Arial')\n",
        "plt.title('June 2015 Fares', weight = 'bold', family = 'Arial')\n",
        "plt.grid(b=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "findfont: Font family ['Arial'] not found. Falling back to DejaVu Sans.\n",
            "findfont: Font family ['Arial'] not found. Falling back to DejaVu Sans.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA58AAAFJCAYAAAAc6ZlnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dfZRVZaEG8GcQRsJGEWJIWEmmNnoFkQ8rSExArtGXqIg2AeklM4PSLgVIZpZWal4hkNTKrkZZ1GjJNRPS1KwmKvASlIloH4QIMzqIAZM6zv2j5ay8IgPE5szg77fWrHXOPnuf99l7nRl5fPfep6y5ubk5AAAAUKAOpQ4AAADA3k/5BAAAoHDKJwAAAIVTPgEAACic8gkAAEDhlE8AAAAKp3wCAABQOOUTgDZjxIgRqaqqyl133VWS8desWZOPfvSjGTFiRPr165dhw4blU5/6VJ566qmWdZ5//vnMnTs3xx9/fPr27ZuTTz459913X8vr69evzznnnJM3velNqaqqSlVV1UvGeWE///nn3HPPfdlcM2bMeMn6VVVVufHGG3fr/gNAkTqWOgAAtBWPPfZY7rnnnrz5zW/Om9/85tx555357ne/m40bN2bu3LlJkq997Wu55ppr0rt377zzne/MHXfckfPOOy+33XZbDj/88DQ0NOTPf/5z+vbtm5///OcvO9Z+++2X0047reX54Ycf3mq+I488Mscee2zL83/7t3/bpf189tln06lTp13aFgB2lfIJQJs0YcKE/OpXv8oXvvCFnHrqqVmyZEkmTpyY3r175yc/+Un++te/ZuTIkUmSz33uc7nmmmuyefPmnHLKKZk5c2bL+9TU1OQb3/hG1qxZkx49euTUU0/NBz7wgXTs+NL/BL7+9a/P3XffncrKyiTJsccemwsvvLClRD733HO54YYbkiRz5sxJ3759c9BBB+Xaa6/NDTfckMsvvzxHHHFEFi9enAcffHC75bNr16755Cc/uVPH5Nhjj33JNhs2bMjHPvaxrF69On/7299SUVGR4447LhdffHH233//Fx2nSy65JPPmzcshhxyS+fPnZ9WqVbnqqquyYsWKNDc3t+xvr1690tzcnFmzZuW2227LE088kQMOOCBHHHFErrrqqhx44IE7lRsAEuUTgL3ANddck8GDB+eHP/xhbrrppgwfPjxDhgzJd77znXz605/OQQcdlLe//e1ZuXJlZs2aleeeey5Tpkx5yfv07NnzRc+fffbZJMlrX/vaJMm6deuycePGdOjQIUcddVSSpG/fvkmSBx98cKcyr1+/PgMGDMi+++6bAQMGZNq0aTnkkEO2u82vf/3rfO5zn2t5Pn78+Dz//PNpbGzMiBEjsu+++6a2tjb/8z//ky5duuSzn/3si7afPXt2Ro4cmR49eqSuri7jx4/Pli1bcsIJJ6RDhw5ZtGhRVq9endtuuy2/+c1vcv3116d3794ZO3ZsGhoasnTp0mzevFn5BGCXKJ8AtHtz5szJ0Ucfnccffzy//vWv8/vf/z5DhgzJ/PnzkyRHH310Xv3qV6eqqiqrVq3Kt7/97W2Wz3/26KOPZtasWenQoUM+8YlPJEmeeOKJJEnnzp1TVlaWJOnSpUuSpL6+fofzdu3aNX379k3Xrl1TW1ubn/zkJ3n44Yfzwx/+MPvuu+/Lbvfggw++qOSeeOKJefOb35xLL700P//5z/Pkk0/msMMOy5/+9KcsWbLkJdvPnj07Q4YMSfKP04efeuqpHHrooTnooIOSJN26dcujjz6aX/7yl2lubk6SHHzwwRk9enQOO+ywdOvWrWU5AOws5ROAduH5559/2ddeuPaxoqIiSbJly5Ykydq1a5MkixYtetH69fX12bx5c/bbb79tvt9vf/vbfPCDH8ymTZvy+c9/PsOHD0+SdO/ePUnS2NiY559/Ph06dGgZ6zWvec0O78stt9zSUl43bdqUYcOGZc2aNfn973+fAQMGvOx2EydOfMlpt7fffnumTp36knWffPLJlywbNGhQy+MXjs0jjzySRx555EXr/eUvf8l73/veVFdX57bbbsvEiROT/GOW99prr205LRkAdoa73QLQJr3qVa9Kkvztb39Lkqxatepl133h+s0XCt0LevfunST58pe/nIceeqjl56677nrZ4vnzn/8873//+7Nly5bMmTMnp5xySstrBx10ULp27Zrnn38+K1euTJKsWLEiSXLEEUfs0H41NDRk06ZN23ytQ4ed/8/yHXfckSQ544wzsmLFisyaNStJtjlDWV5e3vL4hWMzatSoFx2bn/3sZxk7dmyamppy8cUX5ze/+U1+/OMfZ8yYMVm5cmW+973v7XRGAEjMfALQRh155JG57777cuONN2bdunW7VHre97735TOf+UymTZuWUaNGtZTG7t27t5yS+88efvjhnHvuuXn22WczYMCALFmypOX01cmTJ6dr1645++yzM2vWrFxwwQUZPHhwfvSjH2WfffbJpEmTkvxjxvHKK6/Mxo0bW953xowZSZLLL788q1atyoc+9KG85S1vSY8ePVJbW5vGxsYcdthhOfLII3d6H1+Ycf3pT3+aSy65JD/96U93aLt3v/vduf766/PjH/84kyZNSu/evfOXv/wlv/71r7No0aKsXbs2F154YY455pgccMABWbZsWZJk//333+mMAJAonwC0IU1NTUn+MZN59tln53e/+12WLl2aJUuW5Kyzzmr5upMd9d73vjedOnXKt771rSxatCjl5eU5/PDDM3bs2G2u/+STT7bcZOiBBx7IAw880PLa+9///nTt2jXnnHNOGhsbc8stt+SOO+7IG97whnzsYx/LG9/4xiT/OOX3+9///ove94Xnl19+efr06ZMRI0Zk6dKl+dnPfpYDDzwwJ598cj72sY+9aGZyR02ePDl/+tOf8r//+7/53e9+l3PPPTeXXXZZq9v17Nkz8+fPz+zZs/Pb3/42S5cuzUEHHZTq6uoceOCBee6559KnT5/U1tbm6aefTteuXXPmmWfmjDPO2OmMAJAkZc3uHABAG7BmzZqcdNJJaWpqyu23375D33sJALQfrvkEoOSuueaajBkzJk1NTTnqqKNy6KGHljoSALCbOe0WgJJbu3ZtXvWqV2XYsGGZNm3aLt14BwBo25x2CwAAQOH8r2UAAAAKp3wCAABQuD1+zefSpUv39JAAAADsIYMGDdrm8pLccOjlwgAAANB+bW+y0Wm3AAAAFE75BAAAoHDKJwAAAIVTPgEAACic8gkAAEDhlE8AAAAKp3wCAABQOOUTAACAwimfAAAAFE75BAAAoHAdSx0AoN0qK9v+683NeyYHAEA7YOYTAACAwimfAAAAFE75BAAAoHDKJwAAAIVTPgEAACic8gkAAEDhlE8AAAAKp3wCAABQOOUTAACAwnUsdQAAdlFZWevrNDcXnwMAYAeY+QQAAKBwZj4BaL/M/gJAu2HmEwAAgMKZ+QTar9Zmvcx4AQC0Ga2WzyVLluT888/P4YcfniR54xvfmA984AOZNm1ampqa0qNHj3zxi19MeXl5Fi5cmJtuuikdOnTIuHHjcvrppxe+AwAAALR9OzTz+aY3vSlz5sxpeX7hhRemuro6o0ePztVXX52ampqMGTMm8+bNS01NTTp16pSxY8dm1KhR6dq1a2HhAQAAaB926ZrPJUuWZOTIkUmS4cOHp7a2NsuXL0+/fv1SUVGRzp07Z+DAgVm2bNluDQsAAED7tEMzn6tXr86HPvShPPXUU5kyZUq2bt2a8vLyJEn37t1TV1eX+vr6dOvWrWWbbt26pa6urpjUAAAAtCutls/Xv/71mTJlSkaPHp01a9Zk4sSJaWpqanm9+WVu6PFyywEAAHjlafW02549e+Yd73hHysrKcvDBB+c1r3lNnnrqqTQ2NiZJ1q9fn8rKylRWVqa+vr5luw0bNqSysrK45AAAALQbrZbPhQsX5oYbbkiS1NXV5Yknnsipp56aRYsWJUkWL16cYcOGpX///lmxYkU2bdqUzZs3Z9myZRk8eHCx6QEAAGgXWj3tdsSIEfn4xz+eu+++O88++2wuueSSHHnkkZk+fXoWLFiQXr16ZcyYMenUqVOmTp2aSZMmpaysLJMnT05FRcWe2AcAAADauLLmPXxx5tKlSzNo0KA9OSSwtyor2/7rRf95a+vj74kMpdYejkGpPycAsAdtr+/t0letAAAAwM5QPgEAACjcDn3PJ8BLOJUQAICdYOYTAACAwimfAAAAFE75BAAAoHCu+QRg17n2FwDYQWY+AQAAKJzyCQAAQOGUTwAAAAqnfAIAAFA45RMAAIDCKZ8AAAAUTvkEAACgcL7nE9qi1r47MfH9iQAAtCtmPgEAACic8gkAAEDhlE8AAAAKp3wCAABQOOUTAACAwimfAAAAFE75BAAAoHDKJwAAAIVTPgEAACic8gkAAEDhlE8AAAAKp3wCAABQOOUTAACAwimfAAAAFE75BAAAoHDKJwAAAIXrWOoAAECByspaX6e5ufgcALzimfkEAACgcMonAAAAhVM+AQAAKJzyCQAAQOGUTwAAAAqnfAIAAFA45RMAAIDC7VD5bGxszIknnphbb70169aty4QJE1JdXZ3zzz8/zzzzTJJk4cKFOe2003L66afne9/7XqGhAQAAaF92qHxee+21OeCAA5Ikc+bMSXV1dW6++eb06dMnNTU12bJlS+bNm5cbb7wx8+fPz0033ZSNGzcWGhwAAID2o9Xy+cgjj2T16tU54YQTkiRLlizJyJEjkyTDhw9PbW1tli9fnn79+qWioiKdO3fOwIEDs2zZskKDAwAA0H60Wj6vuOKKzJgxo+X51q1bU15eniTp3r176urqUl9fn27durWs061bt9TV1RUQFwBod8rKtv8DwCvCdsvnD37wgxxzzDF53etet83Xm5ubd2o5AAAAr0wdt/fivffemzVr1uTee+/N448/nvLy8nTp0iWNjY3p3Llz1q9fn8rKylRWVqa+vr5luw0bNuSYY44pPDwAAADtw3bL5+zZs1sez507N717984DDzyQRYsW5eSTT87ixYszbNiw9O/fPxdddFE2bdqUffbZJ8uWLcvMmTMLDw8AAED7sN3yuS0f+chHMn369CxYsCC9evXKmDFj0qlTp0ydOjWTJk1KWVlZJk+enIqKiiLyAgAA0A6VNe/hCzSXLl2aQYMG7ckhof3ZkRtwlPra6tYy7ol8pc7Q1sdvCxlKPf6eyNAax6j0xwCAPWZ7fW+nZz7hFcE/lAAAYLdq9atWAAAA4F+lfAIAAFA45RMAAIDCKZ8AAAAUTvkEAACgcMonAAAAhVM+AQAAKJzyCQAAQOGUTwAAAAqnfAIAAFA45RMAAIDCKZ8AAAAUTvkEAACgcMonAAAAhVM+AQAAKJzyCQAAQOE6ljoAAEChysq2/3pz857JAfAKZ+YTAACAwimfAAAAFE75BAAAoHDKJwAAAIVzwyEAgKK56RGAmU8AAACKp3wCAABQOOUTAACAwimfAAAAFE75BAAAoHDKJwAAAIVTPgEAACic8gkAAEDhlE8AAAAKp3wCAABQOOUTAACAwimfAAAAFE75BAAAoHDKJwAAAIVTPgEAACic8gkAAEDhOra2wtatWzNjxow88cQT+fvf/54Pf/jDOeKIIzJt2rQ0NTWlR48e+eIXv5jy8vIsXLgwN910Uzp06JBx48bl9NNP3xP7AAAAQBvXavm855570rdv35xzzjlZu3Zt/uM//iMDBw5MdXV1Ro8enauvvjo1NTUZM2ZM5s2bl5qamnTq1Cljx47NqFGj0rVr1z2xHwAAALRhrZ52+453vCPnnHNOkmTdunXp2bNnlixZkpEjRyZJhg8fntra2ixfvjz9+vVLRUVFOnfunIEDB2bZsmXFpgcAoHVlZdv/AdgDWp35fMGZZ56Zxx9/PNddd13OPvvslJeXJ0m6d++eurq61NfXp1u3bi3rd+vWLXV1dbs/MQAAAO3ODpfP73znO3nwwQfziU98Is3NzS3L//nxP3u55QAAALzytHra7cqVK7Nu3bokyZFHHpmmpqbst99+aWxsTJKsX78+lZWVqaysTH19fct2GzZsSGVlZUGxAQAAaE9aLZ+/+c1v8vWvfz1JUl9fny1btmTo0KFZtGhRkmTx4sUZNmxY+vfvnxUrVmTTpk3ZvHlzli1blsGDBxebHgAAgHah1dNuzzzzzHzyk59MdXV1Ghsbc/HFF6dv376ZPn16FixYkF69emXMmDHp1KlTpk6dmkmTJqWsrCyTJ09ORUXFntgHAAAA2riy5j18cebSpUszaNCgPTkk7LzW7vxX9K/Njtx5sNTXVZf6GLWFDG19/LaQodTj74kMrXGM2v4x8Peq9L8nwF5je32v1dNuAQAA4F+lfAIAAFA45RMAAIDCKZ8AAAAUrtW73QIAwF7PTZmgcGY+AQAAKJzyCQAAQOGUTwAAAArnmk8AAErPNZew1zPzCQAAQOGUTwAAAArntFvaJqfeAADAXsXMJwAAAIVTPgEAACic024BAKAtcNkRezkznwAAABRO+QQAAKBwyicAAACFUz4BAAAonPIJAABA4ZRPAAAACqd8AgAAUDjlEwAAgMIpnwAAABRO+QQAAKBwyicAAACF61jqAAAAQBtQVrb915ub90wO9lpmPgEAACic8gkAAEDhlE8AAAAKp3wCAABQOOUTAACAwimfAAAAFE75BAAAoHDKJwAAAIVTPgEAACic8gkAAEDhlE8AAAAKp3wCAABQOOUTAACAwnXckZWuvPLKLF26NM8991zOPffc9OvXL9OmTUtTU1N69OiRL37xiykvL8/ChQtz0003pUOHDhk3blxOP/30ovMDAADQDrRaPn/5y1/m4YcfzoIFC9LQ0JBTTjklQ4YMSXV1dUaPHp2rr746NTU1GTNmTObNm5eampp06tQpY8eOzahRo9K1a9c9sR8AAAC0Ya2ednvsscfmS1/6UpJk//33z9atW7NkyZKMHDkySTJ8+PDU1tZm+fLl6devXyoqKtK5c+cMHDgwy5YtKzY9AAAA7UKr5XOfffZJly5dkiQ1NTU5/vjjs3Xr1pSXlydJunfvnrq6utTX16dbt24t23Xr1i11dXUFxQYAANgLlZVt/6cd2+EbDt11112pqanJxRdf/KLlzc3N21z/5ZYDAADwyrND5fP+++/Pddddl69+9aupqKhIly5d0tjYmCRZv359KisrU1lZmfr6+pZtNmzYkMrKymJSAwAA7G578axjW9Bq+Xz66adz5ZVX5vrrr2+5edDQoUOzaNGiJMnixYszbNiw9O/fPytWrMimTZuyefPmLFu2LIMHDy42PQAAAO1Cq3e7veOOO9LQ0JALLrigZdnll1+eiy66KAsWLEivXr0yZsyYdOrUKVOnTs2kSZNSVlaWyZMnp6KiotDwAAAAtA9lzXv44sylS5dm0KBBe3JI2qPWTmso+mPb1sffExlaU+pj1BYytPXx20KGUo+/JzK0xjFq+8fA36vS/54kpc9Y6vHbQoZSj98WtIVj0BYy/Au21/d2+IZDAAAAsKuUTwAAAAqnfAIAAFA45RMAAIDCtXq3WwAAgD2ind9sh+0z8wkAAEDhlE8AAAAKp3wCAABQOOUTAACAwimfAAAAFE75BAAAoHDKJwAAAIVTPgEAACic8gkAAEDhlE8AAAAKp3wCAABQOOUTAACAwimfAAAAFE75BAAAoHDKJwAAAIVTPgEAACic8gkAAEDhlE8AAAAKp3wCAABQOOUTAACAwimfAAAAFK5jqQPQBpWVbf/15uY9kwMAANhrmPkEAACgcMonAAAAhVM+AQAAKJzyCQAAQOGUTwAAAAqnfAIAAFA45RMAAIDCKZ8AAAAUTvkEAACgcMonAAAAhVM+AQAAKJzyCQAAQOF2qHyuWrUqJ554Yr75zW8mSdatW5cJEyakuro6559/fp555pkkycKFC3Paaafl9NNPz/e+973iUgMAANCutFo+t2zZkksvvTRDhgxpWTZnzpxUV1fn5ptvTp8+fVJTU5MtW7Zk3rx5ufHGGzN//vzcdNNN2bhxY6HhAQAAaB9aLZ/l5eX56le/msrKypZlS5YsyciRI5Mkw4cPT21tbZYvX55+/fqloqIinTt3zsCBA7Ns2bLikgMAANBudGx1hY4d07Hji1fbunVrysvLkyTdu3dPXV1d6uvr061bt5Z1unXrlrq6ut0cFwAAgPboX77hUHNz804tBwAA4JVnl8pnly5d0tjYmCRZv359KisrU1lZmfr6+pZ1NmzY8KJTdQEAAHjl2qXyOXTo0CxatChJsnjx4gwbNiz9+/fPihUrsmnTpmzevDnLli3L4MGDd2tYAAAA2qdWr/lcuXJlrrjiiqxduzYdO3bMokWLctVVV2XGjBlZsGBBevXqlTFjxqRTp06ZOnVqJk2alLKyskyePDkVFRV7Yh8AAABo48qa9/DFmUuXLs2gQYP25JDsrLKy7b++Jz4ypc7Q1sffExlaU+pj1BYytPXx20KGUo+/JzK0xjFq+8fA36vS/54kpc9Y6vHbQoZSj98WMpR6/LaS4V+wvb73L99wCAAAAFqjfAIAAFA45RMAAIDCKZ8AAAAUTvkEAACgcMonAAAAhVM+AQAAKJzyCQAAQOGUTwAAAAqnfAIAAFA45RMAAIDCKZ8AAAAUTvkEAACgcMonAAAAhVM+AQAAKJzyCQAAQOGUTwAAAAqnfAIAAFA45RMAAIDCKZ8AAAAUTvkEAACgcB1LHYBtKCvb/uvNzXsmBwAAwG5i5hMAAIDCKZ8AAAAUzmm3/59TXgEAAHY7M58AAAAUTvkEAACgcMonAAAAhVM+AQAAKJzyCQAAQOGUTwAAAAqnfAIAAFA45RMAAIDCKZ8AAAAUTvkEAACgcMonAAAAhVM+AQAAKJzyCQAAQOGUTwAAAArXcXe/4ec///ksX748ZWVlmTlzZo4++ujdPQQAAADtzG4tn7/61a/y5z//OQsWLMgjjzySmTNnZsGCBbtzCAAAANqh3XrabW1tbU488cQkyaGHHpqnnnoqf/vb33bnEAAAALRDZc3Nzc27680+9alP5W1ve1tLAa2urs7nPve5HHLIIS3rLF26dHcNBwAAQBszaNCgbS7f7dd8/rNt9dqXCwIAAMDea7eedltZWZn6+vqW5xs2bEiPHj125xAAAAC0Q7u1fL71rW/NokWLkiS/+93vUllZmVe/+tW7cwgAAADaod1aPgcOHJijjjoqZ555Zi677LJ8+tOf3qHtrrzyypxxxhk57bTTsnjx4t0Zib1AY2NjTjzxxNx6662ljkIbs3DhwrznPe/JqaeemnvvvbfUcWgjNm/enClTpmTChAk588wzc//995c6Em3AqlWrcuKJJ+ab3/xmkmTdunWZMGFCqqurc/755+eZZ54pcUJKZVufjbPOOivjx4/PWWedlbq6uhInpFT+/2fjBffff3+qqqpKlKp92+3XfH784x/fqfV/+ctf5uGHH86CBQvS0NCQU045Jf/+7/++u2PRjl177bU54IADSh2DNqahoSHz5s3LLbfcki1btmTu3Lk54YQTSh2LNuD73/9+DjnkkEydOjXr16/P+9///tx5552ljkUJbdmyJZdeemmGDBnSsmzOnDmprq7O6NGjc/XVV6empibV1dUlTEkpbOuzMXv27IwbNy7veMc78q1vfSv//d//nWnTppUwJaWwrc9Gkvz973/PV77yFZcW7qLdOvO5K4499th86UtfSpLsv//+2bp1a5qamkqcirbikUceyerVq5UKXqK2tjZDhgzJq1/96lRWVubSSy8tdSTaiAMPPDAbN25MkmzatCkHHnhgiRNRauXl5fnqV7+aysrKlmVLlizJyJEjkyTDhw9PbW1tqeJRQtv6bHz605/OSSedlOTFf094ZdnWZyNJrrvuulRXV6e8vLxEydq3kpfPffbZJ126dEmS1NTU5Pjjj88+++xT4lS0FVdccUVmzJhR6hi0QX/961/T2NiYD33oQ6murvYPR1q8853vzGOPPZZRo0Zl/PjxmT59eqkjUWIdO3ZM586dX7Rs69atLf947N69u1MrX6G29dno0qVL9tlnnzQ1NeXmm2/Ou9/97hKlo5S29dn44x//mD/84Q8ZPXp0iVK1f4V+1crOuOuuu1JTU5Ovf/3rpY5CG/GDH/wgxxxzTF73uteVOgpt1MaNG3PNNdfksccey8SJE3PPPfekrKys1LEosdtuuy29evXKDTfckD/84Q+ZOXOma8bZrt34lefsJZqamjJt2rS85S1veclpl7xyfeELX8hFF11U6hjtWpson/fff3+uu+66fO1rX0tFRUWp49BG3HvvvVmzZk3uvffePP744ykvL89rX/vaDB06tNTRaAO6d++eAQMGpGPHjjn44IOz33775cknn0z37t1LHY0SW7ZsWY477rgkyRFHHJENGzakqanJWTW8SJcuXdLY2JjOnTtn/fr1Lzm1jle2Cy+8MH369MmUKVNKHYU2Yv369Xn00Udb7m+zYcOGjB8//iU3I2L7Sl4+n3766Vx55ZW58cYb07Vr11LHoQ2ZPXt2y+O5c+emd+/eiictjjvuuMyYMSPnnHNOnnrqqWzZssW1fSRJ+vTpk+XLl+ekk07K2rVrs99++ymevMTQoUOzaNGinHzyyVm8eHGGDRtW6ki0EQsXLkynTp3y0Y9+tNRRaEN69uyZu+66q+X5iBEjFM9dUPLyeccdd6ShoSEXXHBBy7IrrrgivXr1KmEqoK3r2bNnTjrppIwbNy5JctFFF6VDh5Jfxk4bcMYZZ2TmzJkZP358nnvuuVxyySWljkSJrVy5MldccUXWrl2bjh07ZtGiRbnqqqsyY8aMLFiwIL169cqYMWNKHZMS2NZn44knnsi+++6bCRMmJEkOPfRQf0degbb12Zg7d67Jsn9RWbMLHQAAACiYaQIAAAAKp3wCAABQOOUTAACAwimfAAAAFE75BAAAoHDKJwB7taamppx55pl55plnXnadCRMmpKqqKk8++WSS5M4770xVVVXmzp2bJFm7dm0mTZqUAcqq42kAAAT7SURBVAMGZODAgXnPe96T2trabb5XVVVVqqqq0rdv37z1rW/Nhz/84Tz44IM7lLWqqirvete7kvzj+42rqqpy55137szuAkCbpXwCsNeaPXt2+vfvnwceeCD9+/fPlClTdul9vvCFL6S2tjbnnXdeZsyYkaOPPjoNDQ0vu/5rX/vaXHbZZRk9enTuu+++VFdXZ/Xq1bu6Gzvlueee2yPjAMDO6ljqAABQhPXr1+faa6/N29/+9jz66KM599xzs2bNml16r0cffTQdO3bM8ccfnyOOOCLjxo3b7voVFRUZM2ZMxowZk9e85jWZNWtWvvKVr+TKK6/Mww8/nMsuuywrVqzIAQcckLFjx+bDH/5wysrKtvue48aNy+rVq9PU1JRDDz00M2fOzODBg7NkyZJMnDgxxx9/fBoaGvL888/nqquuyvTp0/PQQw9l3333zeGHH56bb755l/YdAHYXM58A7JXKyspSVlaWurq6NDU1ZcCAATnvvPN26b0GDx6cv//97zn55JNz3HHH5TOf+Uw2bty4Q9sef/zxSZKVK1fm2WefzXnnnZff/va3ueCCC1JVVZU5c+bklltuafV9hg4dmgsvvDBTpkxJXV1dZs6c+aLXa2trM2rUqJx11lm5+eabs2LFinziE5/If/7nf6ZXr147v9MAsJuZ+QRgr1RZWZnp06fn+uuvT0NDQ0aMGJHRo0dn1qxZL5ll/P/Pm5ubX7T8oosuysEHH5zFixdn5cqVufnmm9PQ0JDZs2e3muOf3+uPf/xj1qxZk3e9610ts5X33HNPfvrTn2bs2LEv+x6bN2/O73//+3zlK19JU1NTy/LGxsaWxyeccELOPffcJMmmTZvS3Nyc++67L/369cvEiRNbzQkARTPzCcBe6+yzz84vfvGL9OvXL+973/vyox/9KA899NBL1uvRo0eSpK6uLkmyYcOGJEnPnj1b1vnABz6Q7373u7nzzjtTVlaWhx9+eIcy/OxnP0uSHHXUUS3LXii1rZ1q+4KFCxfmvvvuy+jRo3PDDTe0vNc/30SpsrKy5fH48eNz4403pl+/frn77rtzxhln5NFHH92hsQCgKGY+AdgrPfLII/mv//qvDBkyJFu2bGk5TbZz584vWXfYsGG5/fbbM3PmzAwdOjS33nprOnXqlLe85S1JkrPOOiuHH354jjrqqDz22GNpbm7OG9/4xpcd++mnn84PfvCDrFy5Mt/5znfSpUuXfPCDH0yfPn1y8MEH5+677878+fPzi1/8Iknytre9bYf2afPmzXnooYeyatWq7a737W9/Ow0NDenTp0/69OmThx56KE888UTe8IY37NA4AFAE5ROAvVLXrl3T1NSUa665Jhs3bsyTTz6Zj3zkI3n961//knVPPvnkrF27Nrfccku+8Y1vpE+fPvnsZz+b173udUmS4447Lrfffntuu+22dOzYMSeccEKmT5/+smM//vjjueiii9K1a9e87W1vy0c+8pEcdthhSZIvf/nLufTSS3P11VfngAMOyEc/+tGceuqp292Xd7/73Vm8eHFLWT322GNbHm9LeXl5br311jz++OPZb7/98r73vS+DBg1q7ZABQKHKml+4GAUA9lITJkzI/PnzSx0DAF7RXPMJAABA4cx8AgAAUDgznwAAABRO+QQAAKBwyicAAACFUz4BAAAonPIJAABA4ZRPAAAACvd/SxoeQY0f1QIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1152x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TMSdAAjcr4o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8f6e702-b884-48e7-9bdd-d255a543cd0a"
      },
      "source": [
        "y = df_train.fare_amount.values + 1e-10\n",
        "y ### for supervised learning: output vector y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([22.54,  8.  , 34.  , ...,  4.5 ,  6.5 ,  7.  ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FOeHvi3cu1n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "b061a246-d5b0-4656-fc68-6f7543f75f09"
      },
      "source": [
        "# List first rows (post-cleaning):\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fare_amount</th>\n",
              "      <th>pickup_longitude</th>\n",
              "      <th>pickup_latitude</th>\n",
              "      <th>dropoff_longitude</th>\n",
              "      <th>dropoff_latitude</th>\n",
              "      <th>passenger_count</th>\n",
              "      <th>hour</th>\n",
              "      <th>weekday</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>22.54</td>\n",
              "      <td>-74.010483</td>\n",
              "      <td>40.717667</td>\n",
              "      <td>-73.985771</td>\n",
              "      <td>40.660366</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>310</th>\n",
              "      <td>8.00</td>\n",
              "      <td>-74.010727</td>\n",
              "      <td>40.710091</td>\n",
              "      <td>-73.998100</td>\n",
              "      <td>40.722900</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>314</th>\n",
              "      <td>34.00</td>\n",
              "      <td>-73.974899</td>\n",
              "      <td>40.751095</td>\n",
              "      <td>-73.908546</td>\n",
              "      <td>40.881878</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321</th>\n",
              "      <td>8.00</td>\n",
              "      <td>-73.961784</td>\n",
              "      <td>40.759579</td>\n",
              "      <td>-73.978943</td>\n",
              "      <td>40.772606</td>\n",
              "      <td>4</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>486</th>\n",
              "      <td>11.50</td>\n",
              "      <td>-73.957443</td>\n",
              "      <td>40.761703</td>\n",
              "      <td>-73.973236</td>\n",
              "      <td>40.787079</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2015</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     fare_amount  pickup_longitude  pickup_latitude  ...  weekday  month  year\n",
              "31         22.54        -74.010483        40.717667  ...        6      6  2015\n",
              "310         8.00        -74.010727        40.710091  ...        5      6  2015\n",
              "314        34.00        -73.974899        40.751095  ...        1      6  2015\n",
              "321         8.00        -73.961784        40.759579  ...        0      6  2015\n",
              "486        11.50        -73.957443        40.761703  ...        0      6  2015\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-lT9BBicw4P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "6f40ab6b-ff41-4d2a-9985-96a27f67b277"
      },
      "source": [
        "X = df_train.drop(['fare_amount', 'month', 'year'], axis = 1)\n",
        "X.head() ### for supervised learning: input matrix X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pickup_longitude</th>\n",
              "      <th>pickup_latitude</th>\n",
              "      <th>dropoff_longitude</th>\n",
              "      <th>dropoff_latitude</th>\n",
              "      <th>passenger_count</th>\n",
              "      <th>hour</th>\n",
              "      <th>weekday</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>-74.010483</td>\n",
              "      <td>40.717667</td>\n",
              "      <td>-73.985771</td>\n",
              "      <td>40.660366</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>310</th>\n",
              "      <td>-74.010727</td>\n",
              "      <td>40.710091</td>\n",
              "      <td>-73.998100</td>\n",
              "      <td>40.722900</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>314</th>\n",
              "      <td>-73.974899</td>\n",
              "      <td>40.751095</td>\n",
              "      <td>-73.908546</td>\n",
              "      <td>40.881878</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321</th>\n",
              "      <td>-73.961784</td>\n",
              "      <td>40.759579</td>\n",
              "      <td>-73.978943</td>\n",
              "      <td>40.772606</td>\n",
              "      <td>4</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>486</th>\n",
              "      <td>-73.957443</td>\n",
              "      <td>40.761703</td>\n",
              "      <td>-73.973236</td>\n",
              "      <td>40.787079</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     pickup_longitude  pickup_latitude  ...  hour  weekday\n",
              "31         -74.010483        40.717667  ...    21        6\n",
              "310        -74.010727        40.710091  ...     9        5\n",
              "314        -73.974899        40.751095  ...    23        1\n",
              "321        -73.961784        40.759579  ...    21        0\n",
              "486        -73.957443        40.761703  ...    19        0\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eC8SDPzczNY"
      },
      "source": [
        "### Optimum rmse: regression model objective function is Root Mean Square Error (RMSE); \n",
        "### Should be minimized (as close to zero as possible):\n",
        "\n",
        "y_global_orig = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoTmWEhSc1qQ"
      },
      "source": [
        "### Bayesian Optimization - inputs:\n",
        "\n",
        "obj_func = 'XGBoost'\n",
        "n_start_AcqFunc = 100\n",
        "n_test = 500 # test points\n",
        "df = 3 # nu\n",
        "\n",
        "util_approx = 'ExpectedImprovement'\n",
        "util_exact = 'dEI_GP'\n",
        "n_init = 5 # random initialisations\n",
        "opt = True\n",
        "\n",
        "test_perc = 0.667\n",
        "train_perc = 1 - test_perc\n",
        "\n",
        "n_test = int(len(df_train) * test_perc)\n",
        "n_train = int(len(df_train) - n_test)\n",
        "\n",
        "eps = 1e-08"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2ngnRxbc7cg"
      },
      "source": [
        "### Objective function:\n",
        "\n",
        "if obj_func == 'XGBoost': # 6-D\n",
        "            \n",
        "    # Constraints:\n",
        "    param_lb_alpha = 0\n",
        "    param_ub_alpha = 10\n",
        "    \n",
        "    param_lb_gamma = 0\n",
        "    param_ub_gamma = 10\n",
        "    \n",
        "    param_lb_max_depth = 5\n",
        "    param_ub_max_depth = 15\n",
        "    \n",
        "    param_lb_min_child_weight = 1\n",
        "    param_ub_min_child_weight = 20\n",
        "    \n",
        "    param_lb_subsample = .5\n",
        "    param_ub_subsample = 1\n",
        "    \n",
        "    param_lb_colsample = .1\n",
        "    param_ub_colsample = 1\n",
        "    \n",
        "    # 6-D inputs' parameter bounds:\n",
        "    param = { 'alpha':  ('cont', (param_lb_alpha, param_ub_alpha)),\n",
        "         'gamma':  ('cont', (param_lb_gamma, param_ub_gamma)),     \n",
        "         'max_depth':  ('int', (param_lb_max_depth, param_ub_max_depth)),\n",
        "         'subsample':  ('cont', (param_lb_subsample, param_ub_subsample)),\n",
        "          'min_child_weight':  ('int', (param_lb_min_child_weight, param_ub_min_child_weight)),\n",
        "            'colsample': ('cont', (param_lb_colsample, param_ub_colsample))\n",
        "        }\n",
        "       \n",
        "    # True y bounds:\n",
        "    dim = 6\n",
        "    \n",
        "    max_iter = 20  # iterations of Bayesian optimization\n",
        "    \n",
        "    operator = 1 \n",
        "    \n",
        "    n_est = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmJsNX29c_xA"
      },
      "source": [
        "### Surrogate derivatives: \n",
        "\n",
        "cov_func = squaredExponential()\n",
        "\n",
        "class dGaussianProcess(GaussianProcess):\n",
        "    l = GaussianProcess(cov_func, optimize=opt).getcovparams()['l']\n",
        "    sigmaf = GaussianProcess(cov_func, optimize=opt).getcovparams()['sigmaf']\n",
        "    sigman = GaussianProcess(cov_func, optimize=opt).getcovparams()['sigman']\n",
        "\n",
        "    def AcqGrad(self, Xstar):\n",
        "        Xstar = np.atleast_2d(Xstar)\n",
        "        Kstar = squaredExponential.K(self, self.X, Xstar).T\n",
        "        dKstar = Kstar * cdist(self.X, Xstar).T * -1\n",
        "        \n",
        "        v = solve(self.L, Kstar.T)\n",
        "        dv = solve(self.L, dKstar.T)\n",
        "        \n",
        "        ds = -2 * np.diag(np.dot(dv.T, v))\n",
        "        dm = np.dot(dKstar, self.alpha)\n",
        "        return ds, dm\n",
        "            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9ZuEB2VdE0W"
      },
      "source": [
        "### Set-seeds:\n",
        "\n",
        "run_num_1 = 0\n",
        "run_num_2 = 2\n",
        "run_num_3 = 3\n",
        "run_num_4 = 4\n",
        "run_num_5 = 5\n",
        "run_num_6 = 6\n",
        "run_num_7 = 7\n",
        "run_num_8 = 8\n",
        "run_num_9 = 9\n",
        "run_num_10 = 10\n",
        "run_num_11 = 11\n",
        "run_num_12 = 12\n",
        "run_num_13 = 13\n",
        "run_num_14 = 14\n",
        "run_num_15 = 15\n",
        "run_num_16 = 16\n",
        "run_num_17 = 17\n",
        "run_num_18 = 18\n",
        "run_num_19 = 19\n",
        "run_num_20 = 20\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgHMFEyPdCk4"
      },
      "source": [
        "### Cumulative Regret Calculator:\n",
        "\n",
        "def min_max_array(x):\n",
        "    new_list = []\n",
        "    for i, num in enumerate(x):\n",
        "            new_list.append(np.min(x[0:i+1]))\n",
        "    return new_list\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJMhL70fdHz_"
      },
      "source": [
        "class Acquisition_new(Acquisition):    \n",
        "    def __init__(self, mode, eps=1e-08, **params):\n",
        "        \n",
        "        self.params = params\n",
        "        self.eps = eps\n",
        "\n",
        "        mode_dict = {\n",
        "            'dEI_GP': self.dEI_GP,\n",
        "            'ExpectedImprovement': self.ExpectedImprovement\n",
        "        }\n",
        "\n",
        "        self.f = mode_dict[mode]\n",
        "    \n",
        "    def dEI_GP(self, tau, mean, std, ds, dm):\n",
        "        gamma = (mean - tau - self.eps) / (std + self.eps)\n",
        "        gamma_h = (mean - tau) / (std + self.eps)\n",
        "        dsdx = ds / (2 * (std + self.eps))\n",
        "        dmdx = (dm - gamma * dsdx) / (std + self.eps)\n",
        "        \n",
        "        f = (std + self.eps) * (gamma * norm.cdf(gamma) + norm.pdf(gamma))\n",
        "        df1 = f / (std + self.eps) * dsdx \n",
        "        df2 = (std + self.eps) * norm.cdf(gamma) * dmdx\n",
        "        df = df1 + df2\n",
        "\n",
        "        df_arr = []\n",
        "\n",
        "        for j in range(0, dim):\n",
        "          df_arr.append([df])\n",
        "        return f, np.asarray(df_arr).transpose()\n",
        "\n",
        "    def d_eval(self, tau, mean, std, ds, dm):\n",
        "    \n",
        "        return self.f(tau, mean, std, ds, dm, **self.params)\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S422jNLsdIMm"
      },
      "source": [
        "## dGPGO:\n",
        "\n",
        "class dGPGO(GPGO):  \n",
        "    n_start = n_start_AcqFunc\n",
        "    eps = 1e-08\n",
        "\n",
        "    def d_optimizeAcq(self, method='L-BFGS-B', n_start=n_start_AcqFunc):\n",
        "        start_points_dict = [self._sampleParam() for i in range(n_start)]\n",
        "        start_points_arr = np.array([list(s.values())\n",
        "                                     for s in start_points_dict])\n",
        "        x_best = np.empty((n_start, len(self.parameter_key)))\n",
        "        f_best = np.empty((n_start,))\n",
        "        opt = Parallel(n_jobs=self.n_jobs)(delayed(minimize)(self.acqfunc,\n",
        "                                                                 x0=start_point,\n",
        "                                                                 method=method,\n",
        "                                                                 jac = True,\n",
        "                                                                 bounds=self.parameter_range) for start_point in\n",
        "                                               start_points_arr)\n",
        "        x_best = np.array([res.x for res in opt])\n",
        "        f_best = np.array([np.atleast_1d(res.fun)[0] for res in opt])\n",
        "\n",
        "        self.x_best = x_best\n",
        "        self.f_best = f_best\n",
        "        self.best = x_best[np.argmin(f_best)]\n",
        "        self.start_points_arr = start_points_arr\n",
        "\n",
        "        return x_best, f_best\n",
        "    \n",
        "    def run(self, max_iter=10, init_evals=3, resume=False):\n",
        "        \n",
        "        if not resume:\n",
        "            self.init_evals = init_evals\n",
        "            self._firstRun(self.init_evals)\n",
        "            self.logger._printInit(self)\n",
        "        for iteration in range(max_iter):\n",
        "            self.d_optimizeAcq()\n",
        "            self.updateGP()\n",
        "            self.logger._printCurrent(self)\n",
        "\n",
        "    def acqfunc(self, xnew, n_start=n_start_AcqFunc):\n",
        "        new_mean, new_var = self.GP.predict(xnew, return_std=True)\n",
        "        new_std = np.sqrt(new_var + eps)\n",
        "        ds, dm = self.GP.AcqGrad(xnew)\n",
        "        f, df = self.A.d_eval(-self.tau, new_mean, new_std, ds=ds, dm=dm)\n",
        "        \n",
        "        return -f, df\n",
        "\n",
        "    def acqfunc_h(self, xnew, n_start=n_start_AcqFunc, eps=eps):\n",
        "        f = self.acqfunc(xnew)[0]\n",
        "        \n",
        "        new_mean_h, new_var_h = self.GP.predict(xnew + eps, return_std=True)\n",
        "        new_std_h = np.sqrt(new_var_h + eps)\n",
        "        ds_h, dm_h = self.GP.AcqGrad(xnew + eps)\n",
        "        f_h = self.A.d_eval(-self.tau, new_mean_h, new_std_h, ds=ds_h, dm=dm_h)[0]\n",
        "        \n",
        "        approx_grad = (-f_h - f)/eps\n",
        "        return approx_grad\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlilveEgdIR_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4191182-8a40-496f-9be8-87e88c1c0098"
      },
      "source": [
        "start_approx = time.time()\n",
        "start_approx"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1623251773.2153277"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wlzDSHbUG-c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efe7a57f-d58e-46f9-828a-549bd67bea09"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 1\n",
        "\n",
        "np.random.seed(run_num_1)\n",
        "surrogate_approx_1 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=test_perc, random_state=run_num_1)\n",
        "\n",
        "def f_syn_polarity1(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_1, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train1, y=y_train1).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_1 = GPGO(surrogate_approx_1, Acquisition_new(util_approx), f_syn_polarity1, param, n_jobs = -1) # define BayesOpt\n",
        "approx_1.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_1 = approx_1.getResult()[0]\n",
        "params_approx_1['max_depth'] = int(params_approx_1['max_depth'])\n",
        "params_approx_1['min_child_weight'] = int(params_approx_1['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train1 = xgb.DMatrix(X_train1, y_train1)\n",
        "dX_approx_test1 = xgb.DMatrix(X_test1, y_test1)\n",
        "model_approx_1 = xgb.train(params_approx_1, dX_approx_train1)\n",
        "pred_approx_1 = model_approx_1.predict(dX_approx_test1)\n",
        "\n",
        "rmse_approx_1 = np.sqrt(mean_squared_error(pred_approx_1, y_test1))\n",
        "rmse_approx_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [5.48813504 7.15189366 8.         0.92897281 8.         0.48128932]. \t  -0.5626915313589341 \t -0.46143572360276275\n",
            "init   \t [ 6.45894113  4.37587211 11.          0.52835649 13.          0.44509737]. \t  -0.5772881365468763 \t -0.46143572360276275\n",
            "init   \t [ 7.91725038  5.2889492  13.          0.6963924  14.          0.40365654]. \t  -0.5870544636272766 \t -0.46143572360276275\n",
            "init   \t [ 6.48171872  3.6824154  10.          0.88907838 16.          0.88307853]. \t  -0.46143572360276275 \t -0.46143572360276275\n",
            "init   \t [4.73608045 8.00910752 8.         0.83943977 8.         0.67592892]. \t  -0.5051288806760134 \t -0.46143572360276275\n",
            "1      \t [ 0.96098408  9.76459465  7.          0.75481219 17.          0.64436097]. \t  -0.5149059967458438 \t -0.46143572360276275\n",
            "2      \t [ 5.13759733  2.22657933 12.          0.58106013  2.          0.92007745]. \t  -0.46868154430393166 \t -0.46143572360276275\n",
            "3      \t [9.58067178 9.65734278 7.         0.88193436 1.         0.38223155]. \t  -0.5888715285109799 \t -0.46143572360276275\n",
            "4      \t [ 0.90969339  9.80979401 14.          0.8665633   3.          0.55460209]. \t  -0.5632471108749298 \t -0.46143572360276275\n",
            "5      \t [0.3028841  4.069464   5.         0.51500749 1.         0.27359263]. \t  -0.6787735406244566 \t -0.46143572360276275\n",
            "6      \t [ 8.87166351  9.3367646   5.          0.58200219 19.          0.4055524 ]. \t  -0.6087566280502396 \t -0.46143572360276275\n",
            "7      \t [ 0.51228404  8.90605177 14.          0.7949699  11.          0.73913262]. \t  \u001b[92m-0.46104762612970374\u001b[0m \t -0.46104762612970374\n",
            "8      \t [ 2.05150398  0.53599727  5.          0.71551734 11.          0.37377971]. \t  -0.60261611749113 \t -0.46104762612970374\n",
            "9      \t [8.38797278 0.6003286  6.         0.6181346  1.         0.60370114]. \t  -0.526164863483156 \t -0.46104762612970374\n",
            "10     \t [ 9.06530919  9.40796401 14.          0.73452132  4.          0.22638202]. \t  -0.6737273666958219 \t -0.46104762612970374\n",
            "11     \t [ 2.92761431  0.02841708 13.          0.97950295  9.          0.31091424]. \t  -0.5822275926277118 \t -0.46104762612970374\n",
            "12     \t [9.14092793 0.64739809 8.         0.90967035 8.         0.70435457]. \t  -0.5029298264030027 \t -0.46104762612970374\n",
            "13     \t [ 1.99180311  1.76156949  6.          0.52474573 18.          0.69397695]. \t  -0.5292680491699555 \t -0.46104762612970374\n",
            "14     \t [ 1.47165443  0.32474578 13.          0.93757169 15.          0.40230457]. \t  -0.5795930586132758 \t -0.46104762612970374\n",
            "15     \t [ 3.33998723  9.61997442 13.          0.87678219 17.          0.47112812]. \t  -0.562089749118206 \t -0.46104762612970374\n",
            "16     \t [ 0.59268574  5.88934857  8.          0.90451848 12.          0.19426621]. \t  -0.6701635295211161 \t -0.46104762612970374\n",
            "17     \t [ 7.96942817  9.76181769  7.          0.91046857 13.          0.32455735]. \t  -0.5870001390492389 \t -0.46104762612970374\n",
            "18     \t [0.45095418 9.96977628 8.         0.5330212  1.         0.30363698]. \t  -0.5984194428816372 \t -0.46104762612970374\n",
            "19     \t [ 9.20494996  2.86326342  5.          0.5        20.          1.        ]. \t  -0.4769047424474174 \t -0.46104762612970374\n",
            "20     \t [3.69919707 0.85322265 6.         0.75904625 5.         0.97222422]. \t  -0.4807633478348844 \t -0.46104762612970374\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.667222167746296"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClJ9rN2KUJzy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab730984-e580-4167-f9ef-417b33857d32"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 2\n",
        "\n",
        "np.random.seed(run_num_2)\n",
        "surrogate_approx_2 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=test_perc, random_state=run_num_2)\n",
        "\n",
        "def f_syn_polarity2(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_2, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train2, y=y_train2).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_2 = GPGO(surrogate_approx_2, Acquisition_new(util_approx), f_syn_polarity2, param, n_jobs = -1) # define BayesOpt\n",
        "approx_2.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_2 = approx_2.getResult()[0]\n",
        "params_approx_2['max_depth'] = int(params_approx_2['max_depth'])\n",
        "params_approx_2['min_child_weight'] = int(params_approx_2['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train2 = xgb.DMatrix(X_train2, y_train2)\n",
        "dX_approx_test2 = xgb.DMatrix(X_test2, y_test2)\n",
        "model_approx_2 = xgb.train(params_approx_2, dX_approx_train2)\n",
        "pred_approx_2 = model_approx_2.predict(dX_approx_test2)\n",
        "\n",
        "rmse_approx_2 = np.sqrt(mean_squared_error(pred_approx_2, y_test2))\n",
        "rmse_approx_2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 4.35994902  0.25926232 11.          0.97386531 12.          0.47833102]. \t  -0.5147867600449748 \t -0.4765694615523879\n",
            "init   \t [ 3.30334821  2.04648634 10.          0.55997527  6.          0.71472339]. \t  -0.4765694615523879 \t -0.4765694615523879\n",
            "init   \t [ 4.9856117   5.86796978  8.          0.89266757 11.          0.59158659]. \t  -0.4946399399702889 \t -0.4765694615523879\n",
            "init   \t [ 4.07307832  1.76984624 13.          0.75262305  7.          0.35908193]. \t  -0.5884370816585467 \t -0.4765694615523879\n",
            "init   \t [ 1.16193318  1.81727038  9.          0.79837265 19.          0.29965165]. \t  -0.584982798458911 \t -0.4765694615523879\n",
            "1      \t [ 9.41115874  8.16019152 11.          0.70945365  2.          0.28765225]. \t  -0.5900551627442152 \t -0.4765694615523879\n",
            "2      \t [ 8.78180153  6.61060882 12.          0.91523653 18.          0.29687212]. \t  -0.5840366351865409 \t -0.4765694615523879\n",
            "3      \t [ 0.66591974  9.26661294 14.          0.96342421 18.          0.94909068]. \t  \u001b[92m-0.3879430352217851\u001b[0m \t -0.3879430352217851\n",
            "4      \t [0.53023554 8.79041977 6.         0.85342606 1.         0.93968064]. \t  -0.41489686189456554 \t -0.3879430352217851\n",
            "5      \t [6.47584802 1.65960359 8.         0.80737784 1.         0.90602123]. \t  -0.4063073187409662 \t -0.3879430352217851\n",
            "6      \t [ 2.29390808  9.72620131 13.          0.87738596  7.          0.2041919 ]. \t  -0.6789018673924765 \t -0.3879430352217851\n",
            "7      \t [ 9.77744834  2.26597384  5.          0.98618685 19.          0.58642903]. \t  -0.520384169717879 \t -0.3879430352217851\n",
            "8      \t [7.36877801 8.87815651 5.         0.56972286 4.         0.80625064]. \t  -0.5008693406902159 \t -0.3879430352217851\n",
            "9      \t [ 5.76886466  6.30636441 11.          0.85075313  6.          0.94564556]. \t  -0.39766690308447894 \t -0.3879430352217851\n",
            "10     \t [ 0.92680624  0.80829442  5.          0.99163751 10.          0.48273491]. \t  -0.5317089151903325 \t -0.3879430352217851\n",
            "11     \t [ 8.66397635  9.94226364  5.          0.61754568 19.          0.46861962]. \t  -0.5385752501499373 \t -0.3879430352217851\n",
            "12     \t [ 2.21750241  8.1937508   6.          0.88756269 17.          0.73205426]. \t  -0.4886010805216155 \t -0.3879430352217851\n",
            "13     \t [ 9.78109337  2.52726344  5.          0.62902817 11.          0.70291169]. \t  -0.5193465670402935 \t -0.3879430352217851\n",
            "14     \t [ 2.61078484  8.48438058 14.          0.79784401 12.          0.37480602]. \t  -0.5873563000820609 \t -0.3879430352217851\n",
            "15     \t [ 9.63046012  9.46551843 14.          0.83717129 10.          0.78268661]. \t  -0.4661700953958383 \t -0.3879430352217851\n",
            "16     \t [ 9.16837918  2.32035478 14.          0.50291805  1.          0.25746282]. \t  -0.6778946275066893 \t -0.3879430352217851\n",
            "17     \t [ 1.36729794  4.89791321 13.          0.50996816  1.          0.64172429]. \t  -0.5046458287629003 \t -0.3879430352217851\n",
            "18     \t [6.0348008  1.05838904 5.         0.60659353 6.         0.66244736]. \t  -0.5184813195331227 \t -0.3879430352217851\n",
            "19     \t [10.          0.66999941 12.59822409  0.5        20.          0.1       ]. \t  -0.6752754033615737 \t -0.3879430352217851\n",
            "20     \t [1.05391958 2.10485253 7.         0.55626962 1.         0.19660783]. \t  -0.6761021573122338 \t -0.3879430352217851\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.600295852493361"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-45l3NU4UNiI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0248863-2d29-4dc2-b077-28b698ffa9be"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 3\n",
        "\n",
        "np.random.seed(run_num_3)\n",
        "surrogate_approx_3 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train3, X_test3, y_train3, y_test3 = train_test_split(X, y, test_size=test_perc, random_state=run_num_3)\n",
        "\n",
        "def f_syn_polarity3(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_3, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train3, y=y_train3).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_3 = GPGO(surrogate_approx_3, Acquisition_new(util_approx), f_syn_polarity3, param, n_jobs = -1) # define BayesOpt\n",
        "approx_3.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_3 = approx_3.getResult()[0]\n",
        "params_approx_3['max_depth'] = int(params_approx_3['max_depth'])\n",
        "params_approx_3['min_child_weight'] = int(params_approx_3['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train3 = xgb.DMatrix(X_train3, y_train3)\n",
        "dX_approx_test3 = xgb.DMatrix(X_test3, y_test3)\n",
        "model_approx_3 = xgb.train(params_approx_3, dX_approx_train3)\n",
        "pred_approx_3 = model_approx_3.predict(dX_approx_test3)\n",
        "\n",
        "rmse_approx_3 = np.sqrt(mean_squared_error(pred_approx_3, y_test3))\n",
        "rmse_approx_3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 5.50797903  7.08147823 13.          0.56066429 11.          0.11687321]. \t  -0.7165783188757435 \t -0.6409647951145182\n",
            "init   \t [ 0.40630737  2.47888297 11.          0.72040492 13.          0.23083313]. \t  -0.7204431346766296 \t -0.6409647951145182\n",
            "init   \t [ 4.53172301  2.15577008 11.          0.74631796  2.          0.60296868]. \t  -0.6409647951145182 \t -0.6409647951145182\n",
            "init   \t [ 2.59252447  4.15101197 13.          0.79330998  8.          0.24118096]. \t  -0.7214290072967551 \t -0.6409647951145182\n",
            "init   \t [ 5.44649018  7.80314765 10.          0.62879264 18.          0.44917413]. \t  -0.6558401549443297 \t -0.6409647951145182\n",
            "1      \t [1.56262424 9.7795241  5.         0.91450054 5.         0.53102391]. \t  -0.652766690473656 \t -0.6409647951145182\n",
            "2      \t [ 8.93142368  1.52910591 13.          0.84039318 17.          0.60846833]. \t  \u001b[92m-0.6320347814043803\u001b[0m \t -0.6320347814043803\n",
            "3      \t [ 6.38594331  1.19109066  5.          0.81189053 13.          0.59164768]. \t  \u001b[92m-0.6289274956252369\u001b[0m \t -0.6289274956252369\n",
            "4      \t [ 1.02918863  9.32189805 13.          0.88333707  1.          0.86998588]. \t  \u001b[92m-0.45190108244647254\u001b[0m \t -0.45190108244647254\n",
            "5      \t [ 9.74929058  1.51205926 11.          0.50025602  8.          0.46132437]. \t  -0.6593087000926661 \t -0.45190108244647254\n",
            "6      \t [ 9.45052852  8.62641484  7.          0.79615518 14.          0.32790361]. \t  -0.708730491334048 \t -0.45190108244647254\n",
            "7      \t [ 8.92744991  9.09956287 12.          0.74944313  3.          0.11030352]. \t  -0.7194264138705575 \t -0.45190108244647254\n",
            "8      \t [6.90239429 4.38257693 5.         0.77543741 6.         0.209803  ]. \t  -0.7198213013052538 \t -0.45190108244647254\n",
            "9      \t [ 9.02893081  7.64399312 14.          0.72894099 15.          0.70609928]. \t  -0.6325306398208942 \t -0.45190108244647254\n",
            "10     \t [9.43215663 9.14652183 5.         0.95117899 1.         0.516629  ]. \t  -0.657104878100571 \t -0.45190108244647254\n",
            "11     \t [ 2.84857043  0.57472701  5.          0.53705172 19.          0.51858228]. \t  -0.6589951838647294 \t -0.45190108244647254\n",
            "12     \t [ 0.63346059  9.87550877  6.          0.74382195 14.          0.39340576]. \t  -0.7092906536332471 \t -0.45190108244647254\n",
            "13     \t [ 0.63366318  7.00411349 14.          0.89817768 18.          0.82387154]. \t  -0.5088999933243639 \t -0.45190108244647254\n",
            "14     \t [ 9.9224789   2.12085607  6.          0.82807413 19.          0.27539821]. \t  -0.7196366943027934 \t -0.45190108244647254\n",
            "15     \t [ 8.38669041  0.14009263  7.          0.51525209 10.          0.83685663]. \t  -0.5364793690384302 \t -0.45190108244647254\n",
            "16     \t [ 7.3119424   8.32659537  5.          0.53292591 18.          0.53447904]. \t  -0.6598933219918404 \t -0.45190108244647254\n",
            "17     \t [0.58114767 0.49394646 7.         0.87185676 5.         0.42563352]. \t  -0.7090305881085761 \t -0.45190108244647254\n",
            "18     \t [ 2.77081064  4.33888713  7.          0.86748866 10.          0.91605352]. \t  -0.4747430674172078 \t -0.45190108244647254\n",
            "19     \t [ 9.8542409   3.34207335 14.          0.75035548  3.          0.6035725 ]. \t  -0.6317346576420496 \t -0.45190108244647254\n",
            "20     \t [4.27034104 6.89504758 8.         0.52242333 1.         0.93013039]. \t  -0.4688807931917104 \t -0.45190108244647254\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.649527586702978"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voPfk1UDUQU0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6588409e-ec1f-4811-cdbf-3b0a30ce5168"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 4\n",
        "\n",
        "np.random.seed(run_num_4)\n",
        "surrogate_approx_4 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train4, X_test4, y_train4, y_test4 = train_test_split(X, y, test_size=test_perc, random_state=run_num_4)\n",
        "\n",
        "def f_syn_polarity4(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_4, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train4, y=y_train4).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_4 = GPGO(surrogate_approx_4, Acquisition_new(util_approx), f_syn_polarity4, param, n_jobs = -1) # define BayesOpt\n",
        "approx_4.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_4 = approx_4.getResult()[0]\n",
        "params_approx_4['max_depth'] = int(params_approx_4['max_depth'])\n",
        "params_approx_4['min_child_weight'] = int(params_approx_4['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train4 = xgb.DMatrix(X_train4, y_train4)\n",
        "dX_approx_test4 = xgb.DMatrix(X_test4, y_test4)\n",
        "model_approx_4 = xgb.train(params_approx_4, dX_approx_train4)\n",
        "pred_approx_4 = model_approx_4.predict(dX_approx_test4)\n",
        "\n",
        "rmse_approx_4 = np.sqrt(mean_squared_error(pred_approx_4, y_test4))\n",
        "rmse_approx_4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [9.67029839 5.47232249 6.         0.92781047 9.         0.72795594]. \t  -0.5993772224326677 \t -0.4983304913999733\n",
            "init   \t [ 2.16089496  9.76274455 12.          0.62649118  9.          0.66966679]. \t  -0.6069567430422909 \t -0.4983304913999733\n",
            "init   \t [ 0.05159149  5.72356491  9.          0.99170034 10.          0.10808749]. \t  -0.7139334307278753 \t -0.4983304913999733\n",
            "init   \t [ 3.86571283  0.44160058 10.          0.90553105 18.          0.95407958]. \t  -0.4983304913999733 \t -0.4983304913999733\n",
            "init   \t [ 7.86305986  8.66289299  6.          0.53285477 14.          0.25117497]. \t  -0.7091576633146701 \t -0.4983304913999733\n",
            "1      \t [ 8.45443649  8.61014312 11.          0.83475494  1.          0.14018305]. \t  -0.7189305559932541 \t -0.4983304913999733\n",
            "2      \t [ 0.77431146  1.96668116 12.          0.50723361  3.          0.74768925]. \t  -0.6140173026050956 \t -0.4983304913999733\n",
            "3      \t [2.27858743 6.23199766 5.         0.58705984 2.         0.80794289]. \t  -0.5986031600147258 \t -0.4983304913999733\n",
            "4      \t [ 6.832625    9.87635293 14.          0.84450885 19.          0.20389666]. \t  -0.7153744507380464 \t -0.4983304913999733\n",
            "5      \t [ 7.37255369  2.03491596 13.          0.8921741   9.          0.46934318]. \t  -0.625550615237801 \t -0.4983304913999733\n",
            "6      \t [ 0.05992751  6.06320143 14.          0.89322475 17.          0.32211096]. \t  -0.6540035079472759 \t -0.4983304913999733\n",
            "7      \t [ 0.79250634  6.36332745  6.          0.84703891 17.          0.8628914 ]. \t  -0.5176542387032834 \t -0.4983304913999733\n",
            "8      \t [9.26767626 0.09691703 5.         0.59554562 3.         0.95249041]. \t  -0.524958204283032 \t -0.4983304913999733\n",
            "9      \t [ 9.93824172  2.34876498  7.          0.94210707 16.          0.6947317 ]. \t  -0.6069344861897712 \t -0.4983304913999733\n",
            "10     \t [3.43076773 0.51115291 6.         0.80398076 7.         0.163561  ]. \t  -0.7152347423610873 \t -0.4983304913999733\n",
            "11     \t [8.12039932 9.82838311 5.         0.6851891  3.         0.87462757]. \t  -0.5209212303565759 \t -0.4983304913999733\n",
            "12     \t [ 6.03647398  5.02077859  7.          0.51964174 12.          0.90396407]. \t  -0.5142832795776289 \t -0.4983304913999733\n",
            "13     \t [ 9.03174101  2.34471053 13.          0.52042845  3.          0.20136175]. \t  -0.7105427027924398 \t -0.4983304913999733\n",
            "14     \t [ 9.29091353  0.24848851 14.          0.65742606 17.          0.33836791]. \t  -0.655558370799832 \t -0.4983304913999733\n",
            "15     \t [3.19488299 9.73527155 6.         0.65266597 9.         0.60657999]. \t  -0.6104166590688074 \t -0.4983304913999733\n",
            "16     \t [ 2.02212851  9.9407933  10.          0.71009222  3.          0.59925198]. \t  -0.6118231860074616 \t -0.4983304913999733\n",
            "17     \t [ 7.85427932  8.81949282 14.          0.936894    6.          0.6768425 ]. \t  -0.6008015870134431 \t -0.4983304913999733\n",
            "18     \t [ 6.65760625  2.35253217 11.          0.58483338 14.          0.21088543]. \t  -0.7100640025661658 \t -0.4983304913999733\n",
            "19     \t [ 0.9141999   0.89707594 12.          0.91410151 11.          0.69348379]. \t  -0.6076939108347638 \t -0.4983304913999733\n",
            "20     \t [ 6.39825002  5.88858918  9.          0.67432081 18.          0.813834  ]. \t  -0.5921986299757287 \t -0.4983304913999733\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.04081354533672"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kEnTd7MUdlv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "505dc589-f880-4d07-d1a8-77c2176712a0"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 5\n",
        "\n",
        "np.random.seed(run_num_5)\n",
        "surrogate_approx_5 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train5, X_test5, y_train5, y_test5 = train_test_split(X, y, test_size=test_perc, random_state=run_num_5)\n",
        "\n",
        "def f_syn_polarity5(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_5, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train5, y=y_train5).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_5 = GPGO(surrogate_approx_5, Acquisition_new(util_approx), f_syn_polarity5, param, n_jobs = -1) # define BayesOpt\n",
        "approx_5.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_5 = approx_5.getResult()[0]\n",
        "params_approx_5['max_depth'] = int(params_approx_5['max_depth'])\n",
        "params_approx_5['min_child_weight'] = int(params_approx_5['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train5 = xgb.DMatrix(X_train5, y_train5)\n",
        "dX_approx_test5 = xgb.DMatrix(X_test5, y_test5)\n",
        "model_approx_5 = xgb.train(params_approx_5, dX_approx_train5)\n",
        "pred_approx_5 = model_approx_5.predict(dX_approx_test5)\n",
        "\n",
        "rmse_approx_5 = np.sqrt(mean_squared_error(pred_approx_5, y_test5))\n",
        "rmse_approx_5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 2.21993171  8.70732306 11.          0.68186845 10.          0.53957007]. \t  -0.5323233521622429 \t -0.48683475961332984\n",
            "init   \t [ 6.11743863  7.65907856  5.          0.64840025 16.          0.82745351]. \t  -0.48683475961332984 \t -0.48683475961332984\n",
            "init   \t [ 6.49458883  8.19472793  6.          0.93996852 19.          0.36647194]. \t  -0.586475577548452 \t -0.48683475961332984\n",
            "init   \t [ 6.28787909  5.7983781   6.          0.63290956 17.          0.18402673]. \t  -0.633609225551848 \t -0.48683475961332984\n",
            "init   \t [8.26554249 8.33492742 9.         0.97900675 3.         0.26957319]. \t  -0.6326249738244012 \t -0.48683475961332984\n",
            "1      \t [1.95474956 1.21548467 5.         0.65548996 6.         0.3261206 ]. \t  -0.5882279171378358 \t -0.48683475961332984\n",
            "2      \t [ 8.68915106  0.84881749 13.          0.9945373   7.          0.34624572]. \t  -0.5633370634302679 \t -0.48683475961332984\n",
            "3      \t [ 6.12310163  2.21013771 14.          0.74740665 18.          0.42989776]. \t  -0.5333068626906653 \t -0.48683475961332984\n",
            "4      \t [ 9.64635884  9.52633265 14.          0.67611826 10.          0.87506739]. \t  \u001b[92m-0.4423357727617705\u001b[0m \t -0.4423357727617705\n",
            "5      \t [ 0.42801231  0.53056997 14.          0.88001393  3.          0.60870677]. \t  -0.4956565139336144 \t -0.4423357727617705\n",
            "6      \t [ 0.33154545  2.45627958  8.          0.87454095 14.          0.94998466]. \t  \u001b[92m-0.4405807029170717\u001b[0m \t -0.4405807029170717\n",
            "7      \t [9.67414353 2.68949571 5.         0.62350468 9.         0.83649418]. \t  -0.4893925661153425 \t -0.4405807029170717\n",
            "8      \t [ 0.5259471   9.7567347  14.          0.91097263  1.          0.64281486]. \t  -0.49657614671134453 \t -0.4405807029170717\n",
            "9      \t [9.64880583 0.85455793 9.         0.80366346 1.         0.54097439]. \t  -0.5442200644862888 \t -0.4405807029170717\n",
            "10     \t [1.24717977 9.40645683 5.         0.65383928 3.         0.68852908]. \t  -0.5172211356155465 \t -0.4405807029170717\n",
            "11     \t [ 1.7633545   9.18687735 14.          0.62483521 19.          0.67316164]. \t  -0.4977308231633463 \t -0.4405807029170717\n",
            "12     \t [7.9980796  9.13466128 6.         0.81085598 9.         0.18640376]. \t  -0.6345727275625916 \t -0.4405807029170717\n",
            "13     \t [ 3.21802975  4.52251367 10.          0.91931377  1.          0.12302035]. \t  -0.6342698285007368 \t -0.4405807029170717\n",
            "14     \t [ 3.00873322  0.14737527 12.          0.50222445 10.          0.34409645]. \t  -0.5715820551871522 \t -0.4405807029170717\n",
            "15     \t [ 8.82566401  9.52943351 11.          0.94131416 17.          0.11574263]. \t  -0.6318490142275969 \t -0.4405807029170717\n",
            "16     \t [ 9.86354567  3.83813535  9.          0.75924362 13.          0.24806309]. \t  -0.6316030166906611 \t -0.4405807029170717\n",
            "17     \t [ 1.01828137  5.72294894 15.          1.          6.58067819  0.1       ]. \t  -0.6075734310937931 \t -0.4405807029170717\n",
            "18     \t [ 0.39655743  9.88537948  7.          0.8395494  15.          0.83639512]. \t  -0.46556996770739073 \t -0.4405807029170717\n",
            "19     \t [0.86243549 8.92584837 5.         0.6740487  9.         0.55305648]. \t  -0.5632466130939408 \t -0.4405807029170717\n",
            "20     \t [ 9.94984248  2.37676311  9.          0.96621815 19.          0.48539202]. \t  -0.531856562647136 \t -0.4405807029170717\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.047520592626375"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjVSH6caUgyy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc12719f-c2d5-43ed-9c4f-6f969d9ff406"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 6\n",
        "\n",
        "np.random.seed(run_num_6)\n",
        "surrogate_approx_6 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train6, X_test6, y_train6, y_test6 = train_test_split(X, y, test_size=test_perc, random_state=run_num_6)\n",
        "\n",
        "def f_syn_polarity6(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_6, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train6, y=y_train6).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_6 = GPGO(surrogate_approx_6, Acquisition_new(util_approx), f_syn_polarity6, param, n_jobs = -1) # define BayesOpt\n",
        "approx_6.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_6 = approx_6.getResult()[0]\n",
        "params_approx_6['max_depth'] = int(params_approx_6['max_depth'])\n",
        "params_approx_6['min_child_weight'] = int(params_approx_6['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train6 = xgb.DMatrix(X_train6, y_train6)\n",
        "dX_approx_test6 = xgb.DMatrix(X_test6, y_test6)\n",
        "model_approx_6 = xgb.train(params_approx_6, dX_approx_train6)\n",
        "pred_approx_6 = model_approx_6.predict(dX_approx_test6)\n",
        "\n",
        "rmse_approx_6 = np.sqrt(mean_squared_error(pred_approx_6, y_test6))\n",
        "rmse_approx_6"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [8.92860151 3.31979805 5.         0.99251441 2.         0.57683563]. \t  -0.5719256944003751 \t -0.5405445954433028\n",
            "init   \t [4.18807429 3.35407849 9.         0.87750649 3.         0.56623277]. \t  -0.6047098118480896 \t -0.5405445954433028\n",
            "init   \t [ 5.788586    6.45355096 14.          0.70660047 12.          0.82154882]. \t  -0.5405445954433028 \t -0.5405445954433028\n",
            "init   \t [4.58184578 6.73834679 5.         0.90108528 3.         0.65482895]. \t  -0.5678490550489279 \t -0.5405445954433028\n",
            "init   \t [ 4.42510505  5.75952352 14.          0.97882365 15.          0.29525604]. \t  -0.6145131146454834 \t -0.5405445954433028\n",
            "1      \t [ 2.61343239  0.80193947  5.          0.83898129 13.          0.84644718]. \t  -0.5477332582915869 \t -0.5405445954433028\n",
            "2      \t [ 9.72322443  9.21177696  5.          0.87917074 11.          0.86681736]. \t  \u001b[92m-0.4929247454390112\u001b[0m \t -0.4929247454390112\n",
            "3      \t [ 5.94160899  0.75325837 13.          0.80313713  9.          0.38465378]. \t  -0.622987021482589 \t -0.4929247454390112\n",
            "4      \t [ 8.54451719  6.55901746 13.          0.7507391   5.          0.45426156]. \t  -0.6083435565147685 \t -0.4929247454390112\n",
            "5      \t [ 9.98276075  2.51129284  8.          0.78524028 18.          0.90705498]. \t  \u001b[92m-0.4833479558228066\u001b[0m \t -0.4833479558228066\n",
            "6      \t [ 1.15162056  8.90964142  5.          0.51235759 16.          0.30257234]. \t  -0.6348710910727494 \t -0.4833479558228066\n",
            "7      \t [ 0.85068891  9.82901317 11.          0.8341869   1.          0.33880369]. \t  -0.6276360919465666 \t -0.4833479558228066\n",
            "8      \t [ 9.32420466  6.39616005 13.          0.93300527 17.          0.34904443]. \t  -0.618513635024325 \t -0.4833479558228066\n",
            "9      \t [ 8.18088231  9.44781209  7.          0.95869221 19.          0.77401414]. \t  -0.5389010350952639 \t -0.4833479558228066\n",
            "10     \t [ 0.19816257  1.95434851 14.          0.59292238  7.          0.17971262]. \t  -0.6983911087025447 \t -0.4833479558228066\n",
            "11     \t [ 0.56219975  9.42928268 11.          0.51903033 19.          0.52214278]. \t  -0.6178140448716308 \t -0.4833479558228066\n",
            "12     \t [ 1.90877122  0.88669904 11.          0.72802974 19.          0.27519153]. \t  -0.6920469274142503 \t -0.4833479558228066\n",
            "13     \t [ 0.45596011  8.24800111 12.          0.59058729  9.          0.26402873]. \t  -0.6950416018272121 \t -0.4833479558228066\n",
            "14     \t [ 9.66151696  2.12034328  6.          0.87947979 12.          0.86985697]. \t  -0.48788999476246586 \t -0.4833479558228066\n",
            "15     \t [ 3.68500147  6.04160102  8.          0.55594848 12.          0.2508545 ]. \t  -0.6923666983699771 \t -0.4833479558228066\n",
            "16     \t [0.52725495 9.82259272 6.         0.62080595 7.         0.68770749]. \t  -0.5804123305431794 \t -0.4833479558228066\n",
            "17     \t [1.20916044 1.67996637 8.         0.95434584 8.         0.65713107]. \t  -0.560720771561226 \t -0.4833479558228066\n",
            "18     \t [ 8.19647777  0.42845261 12.48159385  0.5         3.75185604  1.        ]. \t  \u001b[92m-0.48042710719120774\u001b[0m \t -0.48042710719120774\n",
            "19     \t [ 0.17525712  4.19183624 13.          0.93093846  1.          0.77496282]. \t  -0.537139253301325 \t -0.48042710719120774\n",
            "20     \t [ 1.59392983  0.4187331   5.          0.53325118 19.          0.2829738 ]. \t  -0.6911833881800746 \t -0.48042710719120774\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.6880443649469035"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1WsphKSUj19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c0b1215-0e42-426b-ef9f-d181c0e9e715"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 7\n",
        "\n",
        "np.random.seed(run_num_7)\n",
        "surrogate_approx_7 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train7, X_test7, y_train7, y_test7 = train_test_split(X, y, test_size=test_perc, random_state=run_num_7)\n",
        "\n",
        "def f_syn_polarity7(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_7, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train7, y=y_train7).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_7 = GPGO(surrogate_approx_7, Acquisition_new(util_approx), f_syn_polarity7, param, n_jobs = -1) # define BayesOpt\n",
        "approx_7.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_7 = approx_7.getResult()[0]\n",
        "params_approx_7['max_depth'] = int(params_approx_7['max_depth'])\n",
        "params_approx_7['min_child_weight'] = int(params_approx_7['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train7 = xgb.DMatrix(X_train7, y_train7)\n",
        "dX_approx_test7 = xgb.DMatrix(X_test7, y_test7)\n",
        "model_approx_7 = xgb.train(params_approx_7, dX_approx_train7)\n",
        "pred_approx_7 = model_approx_7.predict(dX_approx_test7)\n",
        "\n",
        "rmse_approx_7 = np.sqrt(mean_squared_error(pred_approx_7, y_test7))\n",
        "rmse_approx_7"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.76308289 7.79918792 8.         0.98911145 8.         0.98019056]. \t  -0.44500885348659536 \t -0.44173641078261416\n",
            "init   \t [ 5.3849587   5.01120464 13.          0.74994125  5.          0.88192131]. \t  -0.4488374676936292 \t -0.44173641078261416\n",
            "init   \t [ 3.30839249  3.9294231  12.          0.6440728  13.          0.41137564]. \t  -0.5669653799025498 \t -0.44173641078261416\n",
            "init   \t [9.29528191 2.6258377  5.         0.80027446 1.         0.86616513]. \t  -0.4661284696195417 \t -0.44173641078261416\n",
            "init   \t [ 1.74052764  7.90763512 14.          0.7244129   4.          0.77536887]. \t  -0.44173641078261416 \t -0.44173641078261416\n",
            "1      \t [3.43305102 3.00339076 8.         0.71322679 4.         0.33322219]. \t  -0.5720117286339644 \t -0.44173641078261416\n",
            "2      \t [ 7.6343627   1.31181598  5.          0.5769645  12.          0.84874959]. \t  -0.48924755963876193 \t -0.44173641078261416\n",
            "3      \t [ 9.12127254  9.64651695 14.          0.53624962  1.          0.38247449]. \t  -0.5784219709012162 \t -0.44173641078261416\n",
            "4      \t [ 4.51243396  9.79601217  8.          0.69773915 19.          0.69687222]. \t  -0.48670271968935647 \t -0.44173641078261416\n",
            "5      \t [ 8.06748781  9.6311716   5.          0.89165168 11.          0.90769253]. \t  -0.47467849504450826 \t -0.44173641078261416\n",
            "6      \t [ 9.84853722  9.76587477 12.          0.66808012 15.          0.83895675]. \t  -0.464300180546447 \t -0.44173641078261416\n",
            "7      \t [6.4915356  8.69600226 5.         0.66481282 2.         0.54976375]. \t  -0.5200045453863744 \t -0.44173641078261416\n",
            "8      \t [ 0.86712134  2.53401598  5.          0.75823741 18.          0.7884932 ]. \t  -0.4803186810834383 \t -0.44173641078261416\n",
            "9      \t [ 1.29932493  8.0055142  14.          0.51325501 19.          0.83654101]. \t  -0.4650670910068424 \t -0.44173641078261416\n",
            "10     \t [ 8.667653    2.8973594  14.          0.53825633 18.          0.10643456]. \t  -0.6861760180900373 \t -0.44173641078261416\n",
            "11     \t [ 9.89504759  2.29066357 10.          0.72562459  8.          0.65324681]. \t  -0.4791774660247169 \t -0.44173641078261416\n",
            "12     \t [ 9.94824081  0.39149062 12.          0.59113076  1.          0.49709751]. \t  -0.5081268521688408 \t -0.44173641078261416\n",
            "13     \t [ 9.60964399  8.52338044  5.          0.92796141 17.          0.69277707]. \t  -0.49365990657681785 \t -0.44173641078261416\n",
            "14     \t [ 3.34596156  0.67230605 11.          0.7366642  19.          0.29949997]. \t  -0.5628067831028366 \t -0.44173641078261416\n",
            "15     \t [ 9.60816545  8.33912452 11.          0.58307044  8.          0.36972424]. \t  -0.5786370523858145 \t -0.44173641078261416\n",
            "16     \t [ 0.47345619  1.31956961  7.          0.68987164 11.          0.9514247 ]. \t  -0.466265051270997 \t -0.44173641078261416\n",
            "17     \t [ 8.96081021  0.38413512 14.          0.90624871 12.          0.41560009]. \t  -0.565007973216504 \t -0.44173641078261416\n",
            "18     \t [ 9.71411962  1.71380043  5.          0.50726337 19.          0.71982498]. \t  -0.4912391351239423 \t -0.44173641078261416\n",
            "19     \t [ 0.18764716  0.58029521 13.          0.75995865  6.          0.69134836]. \t  -0.46855437085127594 \t -0.44173641078261416\n",
            "20     \t [ 1.77048754  9.0838881   6.          0.98375355 14.          0.13025417]. \t  -0.6815881776266557 \t -0.44173641078261416\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.499924380514474"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hI8sFP4ZUmOs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0352e5ac-81e6-47bb-e1e9-ce9fc648a819"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 8\n",
        "\n",
        "np.random.seed(run_num_8)\n",
        "surrogate_approx_8 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train8, X_test8, y_train8, y_test8 = train_test_split(X, y, test_size=test_perc, random_state=run_num_8)\n",
        "\n",
        "def f_syn_polarity8(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_8, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train8, y=y_train8).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_8 = GPGO(surrogate_approx_8, Acquisition_new(util_approx), f_syn_polarity8, param, n_jobs = -1) # define BayesOpt\n",
        "approx_8.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_8 = approx_8.getResult()[0]\n",
        "params_approx_8['max_depth'] = int(params_approx_8['max_depth'])\n",
        "params_approx_8['min_child_weight'] = int(params_approx_8['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train8 = xgb.DMatrix(X_train8, y_train8)\n",
        "dX_approx_test8 = xgb.DMatrix(X_test8, y_test8)\n",
        "model_approx_8 = xgb.train(params_approx_8, dX_approx_train8)\n",
        "pred_approx_8 = model_approx_8.predict(dX_approx_test8)\n",
        "\n",
        "rmse_approx_8 = np.sqrt(mean_squared_error(pred_approx_8, y_test8))\n",
        "rmse_approx_8"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 8.73429403  9.68540663 10.          0.68875849  9.          0.48011572]. \t  -0.5450023023990902 \t -0.47785117417083445\n",
            "init   \t [ 6.12033333  7.66062926  8.          0.76133734 13.          0.93379456]. \t  -0.48415390639601685 \t -0.47785117417083445\n",
            "init   \t [ 1.46524679  7.01527914  7.          0.90913299 10.          0.36016753]. \t  -0.5514374023096014 \t -0.47785117417083445\n",
            "init   \t [ 9.73855241  3.33774046 14.          0.53290419  7.          0.7088681 ]. \t  -0.509390123714371 \t -0.47785117417083445\n",
            "init   \t [ 3.00618018  1.82702795 11.          0.75681389 14.          0.98627449]. \t  -0.47785117417083445 \t -0.47785117417083445\n",
            "1      \t [4.42022545 5.48487111 9.         0.97165909 3.         0.63617522]. \t  -0.4933129789895931 \t -0.47785117417083445\n",
            "2      \t [ 9.3432851   3.80536023 13.          0.82203895 19.          0.99569116]. \t  -0.4825289719254064 \t -0.47785117417083445\n",
            "3      \t [ 2.52429836  9.02824683 14.          0.59641093 17.          0.61934886]. \t  -0.5047477495526641 \t -0.47785117417083445\n",
            "4      \t [ 9.53473907  5.08424998 11.          0.50652828 18.          0.67121466]. \t  -0.5164144636241208 \t -0.47785117417083445\n",
            "5      \t [6.89072012 1.88822945 5.         0.9252956  8.         0.40577637]. \t  -0.5624845374478475 \t -0.47785117417083445\n",
            "6      \t [ 2.42575645  9.87357367  5.          0.61143882 19.          0.11833201]. \t  -0.6358778400175291 \t -0.47785117417083445\n",
            "7      \t [ 0.9931658   1.40870497 14.          0.50614818  6.          0.71944448]. \t  -0.48485914970894306 \t -0.47785117417083445\n",
            "8      \t [ 9.09148899  1.42093493  5.          0.88801001 17.          0.53231573]. \t  -0.5546570042431702 \t -0.47785117417083445\n",
            "9      \t [9.69554908 3.70013633 5.         0.72727157 1.         0.49530336]. \t  -0.5595421515943506 \t -0.47785117417083445\n",
            "10     \t [ 2.66410938  9.83743919 13.          0.58899688  8.          0.29675269]. \t  -0.558869771245836 \t -0.47785117417083445\n",
            "11     \t [1.66316873 0.47469495 7.         0.60820298 1.         0.50689458]. \t  -0.5436576355709689 \t -0.47785117417083445\n",
            "12     \t [ 1.2277143   1.05411485  5.          0.50198686 13.          0.89258454]. \t  -0.5062409032591381 \t -0.47785117417083445\n",
            "13     \t [5.63420638 9.7026496  5.         0.64869539 8.         0.22475566]. \t  -0.6389332388103492 \t -0.47785117417083445\n",
            "14     \t [ 0.63194856  9.08760061 12.          0.51277257  1.          0.85579144]. \t  -0.4885511515989219 \t -0.47785117417083445\n",
            "15     \t [ 8.35277365  5.17929354 14.          0.67305838  1.          0.70101595]. \t  -0.5154357312421961 \t -0.47785117417083445\n",
            "16     \t [ 8.62413803  1.63568526 10.          0.78670071 12.          0.5099252 ]. \t  -0.5367709050823309 \t -0.47785117417083445\n",
            "17     \t [ 3.5121134   5.24088616  9.          0.68973249 19.          0.78159968]. \t  -0.4838024291467368 \t -0.47785117417083445\n",
            "18     \t [5.83203328 9.4812958  5.         0.60479193 1.         0.24995758]. \t  -0.6380286876071068 \t -0.47785117417083445\n",
            "19     \t [ 3.45271174  0.75931377  5.          0.81313484 19.          0.57119025]. \t  -0.5573456183368956 \t -0.47785117417083445\n",
            "20     \t [10.          0.         10.00991488  0.5         1.          0.1       ]. \t  -0.6418158390314135 \t -0.47785117417083445\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.797573101898328"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw5IYus6UpAn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3797665-8a58-4180-e9e1-74a48ce5f437"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 9\n",
        "\n",
        "np.random.seed(run_num_9)\n",
        "surrogate_approx_9 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train9, X_test9, y_train9, y_test9 = train_test_split(X, y, test_size=test_perc, random_state=run_num_9)\n",
        "\n",
        "def f_syn_polarity9(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_9, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train9, y=y_train9).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_9 = GPGO(surrogate_approx_9, Acquisition_new(util_approx), f_syn_polarity9, param, n_jobs = -1) # define BayesOpt\n",
        "approx_9.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_9 = approx_9.getResult()[0]\n",
        "params_approx_9['max_depth'] = int(params_approx_9['max_depth'])\n",
        "params_approx_9['min_child_weight'] = int(params_approx_9['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train9 = xgb.DMatrix(X_train9, y_train9)\n",
        "dX_approx_test9 = xgb.DMatrix(X_test9, y_test9)\n",
        "model_approx_9 = xgb.train(params_approx_9, dX_approx_train9)\n",
        "pred_approx_9 = model_approx_9.predict(dX_approx_test9)\n",
        "\n",
        "rmse_approx_9 = np.sqrt(mean_squared_error(pred_approx_9, y_test9))\n",
        "rmse_approx_9"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 0.10374154  5.01874592 11.          0.50377155  2.          0.29670281]. \t  -0.6545930802207814 \t -0.4584168030068045\n",
            "init   \t [ 4.18508181  2.48101168 13.          0.69794293  2.          0.25009871]. \t  -0.7166132091943936 \t -0.4584168030068045\n",
            "init   \t [ 8.78559086  9.50964032 13.          0.98395204 11.          0.90820641]. \t  -0.4584168030068045 \t -0.4584168030068045\n",
            "init   \t [ 6.66898973  5.47837783  6.          0.97165345 12.          0.72499481]. \t  -0.48839211091816903 \t -0.4584168030068045\n",
            "init   \t [ 8.24870465  4.65668475 13.          0.68760467  9.          0.98502332]. \t  -0.46354466019784824 \t -0.4584168030068045\n",
            "1      \t [ 4.77974014  4.35555465  8.          0.84383705 19.          0.93268007]. \t  -0.46846249768892934 \t -0.4584168030068045\n",
            "2      \t [ 4.24955662  9.67331527 12.          0.64012695  7.          0.96617478]. \t  -0.4599552738922936 \t -0.4584168030068045\n",
            "3      \t [ 3.60566534  9.79805332 11.          0.62032576 16.          0.3578496 ]. \t  -0.6301914521165797 \t -0.4584168030068045\n",
            "4      \t [5.1421602  8.15576484 5.         0.73724996 3.         0.93160054]. \t  -0.46784261503534524 \t -0.4584168030068045\n",
            "5      \t [ 0.42678797  0.40430921 14.          0.96202194 10.          0.10119674]. \t  -0.7201378581044144 \t -0.4584168030068045\n",
            "6      \t [ 6.47759341  0.32877119 12.          0.97031193 18.          0.58020409]. \t  -0.4855648625579333 \t -0.4584168030068045\n",
            "7      \t [9.20185355 9.40235017 8.         0.60433558 1.         0.94540222]. \t  -0.4678077722812364 \t -0.4584168030068045\n",
            "8      \t [2.23847616 1.05481765 6.         0.88971719 7.         0.87464495]. \t  -0.4663554386891513 \t -0.4584168030068045\n",
            "9      \t [9.98066288 1.46868871 7.         0.68668915 6.         0.1760674 ]. \t  -0.7156228931754152 \t -0.4584168030068045\n",
            "10     \t [ 9.89680111  6.16985579 13.          0.58428363 17.          0.77251451]. \t  -0.4901785694142925 \t -0.4584168030068045\n",
            "11     \t [ 0.26297271  5.35234043 10.          0.52938199  9.          0.37477938]. \t  -0.6374243039921744 \t -0.4584168030068045\n",
            "12     \t [ 7.86216061  0.28362131  5.          0.73470189 17.          0.13041415]. \t  -0.7162962352762121 \t -0.4584168030068045\n",
            "13     \t [ 2.40968827  3.05909821 10.          0.83751775 14.          0.11529988]. \t  -0.7189320791958078 \t -0.4584168030068045\n",
            "14     \t [ 0.80844375  8.9121894   5.          0.56134557 18.          0.84901701]. \t  -0.496220520490058 \t -0.4584168030068045\n",
            "15     \t [ 9.75708751  9.52851232  5.          0.99291385 16.          0.26645966]. \t  -0.7180136255291687 \t -0.4584168030068045\n",
            "16     \t [ 8.77945628  5.51694736 12.          0.84613589  4.          0.64741755]. \t  -0.4798840189273464 \t -0.4584168030068045\n",
            "17     \t [ 3.89448326  9.77793126 11.          0.87312755  1.          0.25420157]. \t  -0.7204829959803113 \t -0.4584168030068045\n",
            "18     \t [ 0.48953831  1.43059038 10.          0.65735568 19.          0.64376156]. \t  -0.4910460228992988 \t -0.4584168030068045\n",
            "19     \t [ 9.40169118 10.          7.36177871  0.60893885 10.73576509  0.6846292 ]. \t  -0.5004092724049022 \t -0.4584168030068045\n",
            "20     \t [ 2.97786479  9.66872573  7.          0.62646987 10.          0.90664407]. \t  -0.47716275766526534 \t -0.4584168030068045\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.6575353004618085"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD494io_Ur7V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b83c4566-60eb-4424-d6d1-f0118301583d"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 10\n",
        "\n",
        "np.random.seed(run_num_10)\n",
        "surrogate_approx_10 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train10, X_test10, y_train10, y_test10 = train_test_split(X, y, test_size=test_perc, random_state=run_num_10)\n",
        "\n",
        "def f_syn_polarity10(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_10, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train10, y=y_train10).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_10 = GPGO(surrogate_approx_10, Acquisition_new(util_approx), f_syn_polarity10, param, n_jobs = -1) # define BayesOpt\n",
        "approx_10.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_10 = approx_10.getResult()[0]\n",
        "params_approx_10['max_depth'] = int(params_approx_10['max_depth'])\n",
        "params_approx_10['min_child_weight'] = int(params_approx_10['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train10 = xgb.DMatrix(X_train10, y_train10)\n",
        "dX_approx_test10 = xgb.DMatrix(X_test10, y_test10)\n",
        "model_approx_10 = xgb.train(params_approx_10, dX_approx_train10)\n",
        "pred_approx_10 = model_approx_10.predict(dX_approx_test10)\n",
        "\n",
        "rmse_approx_10 = np.sqrt(mean_squared_error(pred_approx_10, y_test10))\n",
        "rmse_approx_10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 7.71320643  0.20751949  5.          0.72150747 17.          0.12265456]. \t  -0.7090674967614334 \t -0.4737745634473992\n",
            "init   \t [ 7.0920801   2.65566127 13.          0.57518893 17.          0.83494165]. \t  -0.4737745634473992 \t -0.4737745634473992\n",
            "init   \t [ 3.36071584  8.90816531  6.          0.86087766 15.          0.75469196]. \t  -0.4755277191484213 \t -0.4737745634473992\n",
            "init   \t [ 5.40880931  1.31458152  8.          0.57108502 14.          0.62551123]. \t  -0.48811859212530173 \t -0.4737745634473992\n",
            "init   \t [1.82631436 8.26082248 6.         0.80888349 5.         0.15900694]. \t  -0.7057210222477256 \t -0.4737745634473992\n",
            "1      \t [8.31989768 3.09778055 7.         0.64798085 3.         0.98471878]. \t  \u001b[92m-0.46336171949490257\u001b[0m \t -0.46336171949490257\n",
            "2      \t [ 1.51483713  6.46720195 14.          0.87676044  8.          0.10934204]. \t  -0.7062921047588426 \t -0.46336171949490257\n",
            "3      \t [ 1.40638864  6.36994003 14.          0.94554832 18.          0.42624162]. \t  -0.6046476616239911 \t -0.46336171949490257\n",
            "4      \t [ 6.47425096  8.4482791  10.          0.69239539 11.          0.47622913]. \t  -0.5685254207537167 \t -0.46336171949490257\n",
            "5      \t [ 9.63766998  0.33667719 14.          0.56957963  7.          0.90222914]. \t  -0.463452425520129 \t -0.46336171949490257\n",
            "6      \t [ 2.70513667  1.83577987 12.          0.56122064  1.          0.15848231]. \t  -0.7152283108383268 \t -0.46336171949490257\n",
            "7      \t [ 8.5382995   9.82970528 10.          0.72827815  4.          0.91090853]. \t  \u001b[92m-0.4482214729025003\u001b[0m \t -0.4482214729025003\n",
            "8      \t [ 0.13114685  2.69967978  5.          0.89490476 19.          0.55706236]. \t  -0.5697953373163872 \t -0.4482214729025003\n",
            "9      \t [ 9.76455747  9.71578983 14.          0.66293675 18.          0.1137209 ]. \t  -0.711142014680554 \t -0.4482214729025003\n",
            "10     \t [ 8.91866592  7.39892211  8.          0.67814307 19.          0.42475225]. \t  -0.6134207154658835 \t -0.4482214729025003\n",
            "11     \t [0.40833691 2.05040396 5.         0.83675528 2.         0.93839002]. \t  -0.45672281191304187 \t -0.4482214729025003\n",
            "12     \t [ 0.06083858  0.83347778 13.          0.60208867 14.          0.81102115]. \t  -0.4556981011772255 \t -0.4482214729025003\n",
            "13     \t [ 3.87733745  1.80097513 10.          0.87276131  7.          0.20829771]. \t  -0.7067646180181819 \t -0.4482214729025003\n",
            "14     \t [ 4.19755202  9.09268434 14.          0.54945508  1.          0.70144661]. \t  -0.4893545960096766 \t -0.4482214729025003\n",
            "15     \t [9.29172085 4.53921153 5.         0.72490904 9.         0.80222442]. \t  -0.4877400642311686 \t -0.4482214729025003\n",
            "16     \t [ 1.47623714  8.58014874 12.          0.98501224 13.          0.73010278]. \t  \u001b[92m-0.4431735147238962\u001b[0m \t -0.4431735147238962\n",
            "17     \t [ 8.55266632  0.8729167  12.          0.54639494  1.          0.10341981]. \t  -0.7132130084673767 \t -0.4431735147238962\n",
            "18     \t [ 3.51348801  1.47885981  5.          0.61755906 10.          0.59560105]. \t  -0.5150258208748587 \t -0.4431735147238962\n",
            "19     \t [ 9.70082045  2.90861386 11.          0.53565772 13.          0.71127619]. \t  -0.4888615020821664 \t -0.4431735147238962\n",
            "20     \t [6.46081033 9.19989249 5.         0.99579878 1.         0.40331905]. \t  -0.6132015265548795 \t -0.4431735147238962\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.704422370494913"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N03Sq0TvUuhp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8826b6ae-2247-4a64-cc8d-be3ce095f4a5"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 11\n",
        "\n",
        "np.random.seed(run_num_11)\n",
        "surrogate_approx_11 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train11, X_test11, y_train11, y_test11 = train_test_split(X, y, test_size=test_perc, random_state=run_num_11)\n",
        "\n",
        "def f_syn_polarity11(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_11, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train11, y=y_train11).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_11 = GPGO(surrogate_approx_11, Acquisition_new(util_approx), f_syn_polarity11, param, n_jobs = -1) # define BayesOpt\n",
        "approx_11.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_11 = approx_11.getResult()[0]\n",
        "params_approx_11['max_depth'] = int(params_approx_11['max_depth'])\n",
        "params_approx_11['min_child_weight'] = int(params_approx_11['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train11 = xgb.DMatrix(X_train11, y_train11)\n",
        "dX_approx_test11 = xgb.DMatrix(X_test11, y_test11)\n",
        "model_approx_11 = xgb.train(params_approx_11, dX_approx_train11)\n",
        "pred_approx_11 = model_approx_11.predict(dX_approx_test11)\n",
        "\n",
        "rmse_approx_11 = np.sqrt(mean_squared_error(pred_approx_11, y_test11))\n",
        "rmse_approx_11"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 1.80269689  0.19475241  6.          0.59705781 13.          0.47818324]. \t  -0.5922349044250168 \t -0.49898623219170346\n",
            "init   \t [ 4.85427098  0.12780815  5.          0.91309068 14.          0.86571558]. \t  -0.49898623219170346 \t -0.49898623219170346\n",
            "init   \t [ 7.2996447   1.08736072 10.          0.92857712 18.          0.66910061]. \t  -0.5404544349803458 \t -0.49898623219170346\n",
            "init   \t [ 0.20483613  1.16737269  7.          0.57895615 16.          0.83644782]. \t  -0.5108833748715963 \t -0.49898623219170346\n",
            "init   \t [ 3.44624491  3.18798797 14.          0.54197657 15.          0.63958906]. \t  -0.5545314939891337 \t -0.49898623219170346\n",
            "1      \t [9.77136617 6.6548802  7.         0.51036649 9.         0.81011527]. \t  -0.5252491147925742 \t -0.49898623219170346\n",
            "2      \t [0.5279662  8.15331655 5.         0.83127487 9.         0.53242685]. \t  -0.5931601503405173 \t -0.49898623219170346\n",
            "3      \t [8.62555756 1.5478147  8.         0.99964468 2.         0.74874718]. \t  \u001b[92m-0.490360342610192\u001b[0m \t -0.490360342610192\n",
            "4      \t [ 0.90299561  9.42808632 14.          0.71344248  9.          0.5250902 ]. \t  -0.5778138976577691 \t -0.490360342610192\n",
            "5      \t [ 5.37271973  6.74878506 12.          0.69507758  3.          0.34109729]. \t  -0.5771395586534209 \t -0.490360342610192\n",
            "6      \t [0.4982028  3.39252027 6.         0.94894432 2.         0.3491488 ]. \t  -0.5852850010711237 \t -0.490360342610192\n",
            "7      \t [ 5.0402397   9.42026535  8.          0.71577    16.          0.52045581]. \t  -0.5873554197790632 \t -0.490360342610192\n",
            "8      \t [ 0.07362338  1.12762958 13.          0.93121884  6.          0.44481438]. \t  -0.5703047717584466 \t -0.490360342610192\n",
            "9      \t [ 8.74582539  1.09960491 14.          0.69981761  9.          0.73083826]. \t  -0.4904447717887598 \t -0.490360342610192\n",
            "10     \t [ 9.62795963  5.53773092  5.          0.74613073 18.          0.44845649]. \t  -0.6039998092641087 \t -0.490360342610192\n",
            "11     \t [ 8.61765552  0.94349031 10.          0.85641829  4.          0.91576259]. \t  \u001b[92m-0.47852786064513103\u001b[0m \t -0.47852786064513103\n",
            "12     \t [3.50049766 0.06230783 7.         0.82711607 1.         0.94515625]. \t  -0.4818438762403437 \t -0.47852786064513103\n",
            "13     \t [5.71344477 9.31745465 5.         0.62710446 1.         0.57350664]. \t  -0.56563042311184 \t -0.47852786064513103\n",
            "14     \t [ 8.40730244  5.3235921  14.          0.57824885  9.          0.96689527]. \t  -0.4867986869106529 \t -0.47852786064513103\n",
            "15     \t [ 3.80424221  9.01046858 14.          0.56083724 18.          0.27280598]. \t  -0.6935551888073371 \t -0.47852786064513103\n",
            "16     \t [ 9.7602473   8.08368399 12.          0.65958526 18.          0.9544452 ]. \t  -0.4831334802506264 \t -0.47852786064513103\n",
            "17     \t [ 7.19988755  9.76929986 14.          0.62177947 13.          0.86328626]. \t  -0.4799844649576287 \t -0.47852786064513103\n",
            "18     \t [ 6.19006075  3.41925871 11.          0.95286331  6.          0.39133224]. \t  -0.5745107435758626 \t -0.47852786064513103\n",
            "19     \t [0.77256475 1.22732493 7.         0.97692145 7.         0.9071396 ]. \t  \u001b[92m-0.4728689341077363\u001b[0m \t -0.4728689341077363\n",
            "20     \t [7.46566309 0.73949694 7.         0.58224414 9.         0.25972328]. \t  -0.6904564119816002 \t -0.4728689341077363\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.084919441252919"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_nP9lQjUztV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dedd53ac-6959-4ead-af5c-7b0f95dd422b"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 12\n",
        "\n",
        "np.random.seed(run_num_12)\n",
        "surrogate_approx_12 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train12, X_test12, y_train12, y_test12 = train_test_split(X, y, test_size=test_perc, random_state=run_num_12)\n",
        "\n",
        "def f_syn_polarity12(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_12, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train12, y=y_train12).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_12 = GPGO(surrogate_approx_12, Acquisition_new(util_approx), f_syn_polarity12, param, n_jobs = -1) # define BayesOpt\n",
        "approx_12.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_12 = approx_12.getResult()[0]\n",
        "params_approx_12['max_depth'] = int(params_approx_12['max_depth'])\n",
        "params_approx_12['min_child_weight'] = int(params_approx_12['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train12 = xgb.DMatrix(X_train12, y_train12)\n",
        "dX_approx_test12 = xgb.DMatrix(X_test12, y_test12)\n",
        "model_approx_12 = xgb.train(params_approx_12, dX_approx_train12)\n",
        "pred_approx_12 = model_approx_12.predict(dX_approx_test12)\n",
        "\n",
        "rmse_approx_12 = np.sqrt(mean_squared_error(pred_approx_12, y_test12))\n",
        "rmse_approx_12"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [1.54162842 7.40049697 6.         0.54321714 4.         0.11311747]. \t  -0.6840535846029854 \t -0.5032799564384677\n",
            "init   \t [ 9.18747008  9.00714854 14.          0.97847467 11.          0.35544552]. \t  -0.6305456734924068 \t -0.5032799564384677\n",
            "init   \t [ 6.06083184  9.44225136 14.          0.95626942  5.          0.56910342]. \t  -0.6144010633484512 \t -0.5032799564384677\n",
            "init   \t [ 5.52037633  4.85377414  7.          0.97886436 17.          0.78810441]. \t  -0.5032799564384677 \t -0.5032799564384677\n",
            "init   \t [ 0.20809798  1.35210178  5.          0.65494879 16.          0.36062811]. \t  -0.6516977337723864 \t -0.5032799564384677\n",
            "1      \t [9.46555822 8.57190559 5.         0.50164398 5.         0.71992807]. \t  -0.5227768283895782 \t -0.5032799564384677\n",
            "2      \t [9.04256367 2.61736915 8.         0.66026854 8.         0.14510453]. \t  -0.6776847411315782 \t -0.5032799564384677\n",
            "3      \t [6.03751892 2.08855857 8.         0.88966175 1.         0.6215545 ]. \t  -0.537741041779077 \t -0.5032799564384677\n",
            "4      \t [ 0.24796255  2.18203944 14.          0.56497025 17.          0.63132662]. \t  -0.5478949507371567 \t -0.5032799564384677\n",
            "5      \t [ 1.93384153  7.13950146  8.          0.85480597 18.          0.33734734]. \t  -0.6395317281169034 \t -0.5032799564384677\n",
            "6      \t [ 0.40359854  2.22527636 10.          0.60258213 10.          0.38255809]. \t  -0.6389275427144069 \t -0.5032799564384677\n",
            "7      \t [ 0.28427394  4.67296732 14.          0.84909523  4.          0.99176009]. \t  \u001b[92m-0.46369522867609564\u001b[0m \t -0.46369522867609564\n",
            "8      \t [ 7.63658847  0.39719075 14.          0.96199388 14.          0.84093877]. \t  -0.48258324270646796 \t -0.46369522867609564\n",
            "9      \t [ 0.50213582  8.87075    12.          0.71856843 12.          0.66120412]. \t  -0.5367112816028642 \t -0.46369522867609564\n",
            "10     \t [ 4.27921374  9.2199845   6.          0.67076861 12.          0.56605459]. \t  -0.628155564863435 \t -0.46369522867609564\n",
            "11     \t [ 7.63578483  4.07501457 14.          0.97723751  1.          0.2033266 ]. \t  -0.6773954967709924 \t -0.46369522867609564\n",
            "12     \t [ 9.06259994  1.4172751   5.          0.81347212 19.          0.38881712]. \t  -0.650363142837499 \t -0.46369522867609564\n",
            "13     \t [ 9.38461996  5.62749581 12.          0.98689844 17.          0.89710846]. \t  -0.4762695359794075 \t -0.46369522867609564\n",
            "14     \t [ 4.55964005  0.30434123  5.          0.52399968 11.          0.14256504]. \t  -0.6841482061412913 \t -0.46369522867609564\n",
            "15     \t [ 6.59943135  1.71178305 14.          0.69283152  8.          0.30459736]. \t  -0.635622313137239 \t -0.46369522867609564\n",
            "16     \t [5.99294447 7.0114806  5.         0.86352024 2.         0.47030879]. \t  -0.629371597372417 \t -0.46369522867609564\n",
            "17     \t [ 9.63630565  6.83547158  8.          0.6195521  13.          0.11712353]. \t  -0.6780822711639433 \t -0.46369522867609564\n",
            "18     \t [0.93465239 0.11560545 5.         0.52904926 2.         0.78190279]. \t  -0.5147104266754287 \t -0.46369522867609564\n",
            "19     \t [ 4.02953989  6.35914994 11.          0.73063178  8.          0.53793685]. \t  -0.6140059235484745 \t -0.46369522867609564\n",
            "20     \t [ 0.49442426  9.20422434 11.          0.70522852  1.          0.50168224]. \t  -0.62709850175482 \t -0.46369522867609564\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.548920198104285"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDI2Bi9vU05U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c85044fa-7e44-43ce-ebfb-7997c6b5aed1"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 13\n",
        "\n",
        "np.random.seed(run_num_13)\n",
        "surrogate_approx_13 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train13, X_test13, y_train13, y_test13 = train_test_split(X, y, test_size=test_perc, random_state=run_num_13)\n",
        "\n",
        "def f_syn_polarity13(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_13, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train13, y=y_train13).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_13 = GPGO(surrogate_approx_13, Acquisition_new(util_approx), f_syn_polarity13, param, n_jobs = -1) # define BayesOpt\n",
        "approx_13.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_13 = approx_13.getResult()[0]\n",
        "params_approx_13['max_depth'] = int(params_approx_13['max_depth'])\n",
        "params_approx_13['min_child_weight'] = int(params_approx_13['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train13 = xgb.DMatrix(X_train13, y_train13)\n",
        "dX_approx_test13 = xgb.DMatrix(X_test13, y_test13)\n",
        "model_approx_13 = xgb.train(params_approx_13, dX_approx_train13)\n",
        "pred_approx_13 = model_approx_13.predict(dX_approx_test13)\n",
        "\n",
        "rmse_approx_13 = np.sqrt(mean_squared_error(pred_approx_13, y_test13))\n",
        "rmse_approx_13"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 7.77702411  2.3754122  11.          0.94649135 13.          0.7827256 ]. \t  -0.5099204187421568 \t -0.5099204187421568\n",
            "init   \t [ 7.51661514  6.07343344 11.          0.69402149 11.          0.13153287]. \t  -0.7086153631136594 \t -0.5099204187421568\n",
            "init   \t [ 2.98449471  0.58512492 10.          0.73579614 12.          0.33065195]. \t  -0.6372461781857162 \t -0.5099204187421568\n",
            "init   \t [ 3.47581215  0.0941277  11.          0.86143432  8.          0.58454932]. \t  -0.5702017504451442 \t -0.5099204187421568\n",
            "init   \t [ 4.70137857  6.24432527 10.          0.8149145  18.          0.10784416]. \t  -0.7101125715665313 \t -0.5099204187421568\n",
            "1      \t [1.1119361  5.43221306 6.         0.56899303 8.         0.32100319]. \t  -0.6493427493033831 \t -0.5099204187421568\n",
            "2      \t [5.39023698 3.80105709 8.         0.54170057 1.         0.56798884]. \t  -0.621866591058205 \t -0.5099204187421568\n",
            "3      \t [ 0.5185863   5.23876151 13.          0.63798348  5.          0.7914799 ]. \t  \u001b[92m-0.5090480969691882\u001b[0m \t -0.5090480969691882\n",
            "4      \t [ 9.65518672  0.13040633  6.          0.63296628 18.          0.44133279]. \t  -0.632314879589983 \t -0.5090480969691882\n",
            "5      \t [ 9.80722669  7.22571611  7.          0.5026908  19.          0.92519376]. \t  -0.5113851690128051 \t -0.5090480969691882\n",
            "6      \t [ 6.75965929  9.42320667 14.          0.75932127  4.          0.51195623]. \t  -0.6206028595311828 \t -0.5090480969691882\n",
            "7      \t [9.95671825 0.88335607 5.         0.76593799 7.         0.60049246]. \t  -0.5952873237754599 \t -0.5090480969691882\n",
            "8      \t [ 1.88898055  9.92199995 14.          0.53783103 12.          0.63359705]. \t  -0.5738907345204808 \t -0.5090480969691882\n",
            "9      \t [0.32121091 9.03384774 6.         0.79493663 1.         0.29330571]. \t  -0.6544818879601484 \t -0.5090480969691882\n",
            "10     \t [ 9.64211232  3.05396831 11.          0.80784352  5.          0.67910498]. \t  -0.5747201434527256 \t -0.5090480969691882\n",
            "11     \t [ 1.60018805  0.54211528  7.          0.80910607 18.          0.55232873]. \t  -0.6209454018308087 \t -0.5090480969691882\n",
            "12     \t [ 6.1829314   9.53799326  5.          0.66916589 13.          0.57013155]. \t  -0.6295351865431291 \t -0.5090480969691882\n",
            "13     \t [7.99022981 8.23715587 5.         0.79172469 5.         0.39852784]. \t  -0.6543343020941466 \t -0.5090480969691882\n",
            "14     \t [ 8.15066897  1.98276445 13.          0.64083395 19.          0.16153982]. \t  -0.7124294948180114 \t -0.5090480969691882\n",
            "15     \t [ 2.48128047  9.70146472  6.          0.59664322 19.          0.9781653 ]. \t  -0.5140838980696801 \t -0.5090480969691882\n",
            "16     \t [ 9.08793394  9.83715934 14.          0.60607659 14.          0.5136415 ]. \t  -0.6216172534981154 \t -0.5090480969691882\n",
            "17     \t [ 1.80857777  4.26197    14.          0.84061579 16.          0.40224246]. \t  -0.637460469665298 \t -0.5090480969691882\n",
            "18     \t [ 5.1333583   3.10658752 14.          0.74854361  1.          0.92539511]. \t  \u001b[92m-0.4793091157473782\u001b[0m \t -0.4793091157473782\n",
            "19     \t [ 0.65009462  9.91088996 13.          0.92448902  2.          0.37838494]. \t  -0.6501362550952002 \t -0.4793091157473782\n",
            "20     \t [ 0.18073363  6.71350851  7.          0.80658597 14.          0.6264676 ]. \t  -0.5752866688439547 \t -0.4793091157473782\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.601162573826364"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2F_Q194U3uu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a08d61a1-386d-4292-860b-de7b63102b33"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 14\n",
        "\n",
        "np.random.seed(run_num_14)\n",
        "surrogate_approx_14 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train14, X_test14, y_train14, y_test14 = train_test_split(X, y, test_size=test_perc, random_state=run_num_14)\n",
        "\n",
        "def f_syn_polarity14(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_14, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train14, y=y_train14).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_14 = GPGO(surrogate_approx_14, Acquisition_new(util_approx), f_syn_polarity14, param, n_jobs = -1) # define BayesOpt\n",
        "approx_14.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_14 = approx_14.getResult()[0]\n",
        "params_approx_14['max_depth'] = int(params_approx_14['max_depth'])\n",
        "params_approx_14['min_child_weight'] = int(params_approx_14['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train14 = xgb.DMatrix(X_train14, y_train14)\n",
        "dX_approx_test14 = xgb.DMatrix(X_test14, y_test14)\n",
        "model_approx_14 = xgb.train(params_approx_14, dX_approx_train14)\n",
        "pred_approx_14 = model_approx_14.predict(dX_approx_test14)\n",
        "\n",
        "rmse_approx_14 = np.sqrt(mean_squared_error(pred_approx_14, y_test14))\n",
        "rmse_approx_14"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 5.13943344  7.73165052 12.          0.6831412  11.          0.37876233]. \t  -0.558794499921046 \t -0.4448140077853998\n",
            "init   \t [ 9.57603739  5.13116712 14.          0.76959997 12.          0.71328228]. \t  -0.49979629433789113 \t -0.4448140077853998\n",
            "init   \t [5.34950319 2.47493539 5.         0.50293689 6.         0.29706373]. \t  -0.5741697988899073 \t -0.4448140077853998\n",
            "init   \t [ 2.94506579  3.45329697  8.          0.87620946 14.          0.9783044 ]. \t  -0.4448140077853998 \t -0.4448140077853998\n",
            "init   \t [ 1.11811929  1.73004086  5.          0.73745288 12.          0.20586008]. \t  -0.6214151152359092 \t -0.4448140077853998\n",
            "1      \t [ 6.50637223  2.67617722 14.          0.53562507  1.          0.16862152]. \t  -0.6294794339238933 \t -0.4448140077853998\n",
            "2      \t [ 9.97732733  0.9008687  13.          0.65397817 19.          0.96533011]. \t  -0.46274298441446626 \t -0.4448140077853998\n",
            "3      \t [ 0.28409124  4.13353348 13.          0.96339983  6.          0.90100709]. \t  \u001b[92m-0.42439805248956936\u001b[0m \t -0.42439805248956936\n",
            "4      \t [9.32373648 9.05676215 9.         0.53064322 3.         0.70657534]. \t  -0.5066999638361388 \t -0.42439805248956936\n",
            "5      \t [ 9.52454394  8.82757271  9.          0.90064956 19.          0.16022914]. \t  -0.6201852747998959 \t -0.42439805248956936\n",
            "6      \t [ 3.61508571  7.70718733 10.          0.62042707  5.          0.12186292]. \t  -0.6265638054423092 \t -0.42439805248956936\n",
            "7      \t [ 0.9687803   2.15143442 14.          0.51651811 18.          0.56051657]. \t  -0.5069463513331254 \t -0.42439805248956936\n",
            "8      \t [ 9.40430013  0.15700131  7.          0.99940272 12.          0.43771306]. \t  -0.50114980828739 \t -0.42439805248956936\n",
            "9      \t [ 8.97462379  3.07976653  6.          0.89115666 18.          0.90399549]. \t  -0.46259647676184984 \t -0.42439805248956936\n",
            "10     \t [ 2.08494663  9.70581169 14.          0.64307382  3.          0.10613693]. \t  -0.6314022013205511 \t -0.42439805248956936\n",
            "11     \t [ 1.55781918  0.46142569 10.          0.80240433 16.          0.22604037]. \t  -0.6223833972775541 \t -0.42439805248956936\n",
            "12     \t [ 8.32471637  8.64868248  5.          0.80719895 12.          0.64183859]. \t  -0.5064508572748014 \t -0.42439805248956936\n",
            "13     \t [ 1.40044045  8.51657075 10.          0.9376679  19.          0.10378975]. \t  -0.619787592651992 \t -0.42439805248956936\n",
            "14     \t [0.73443351 4.9474333  6.         0.76758914 1.         0.38158758]. \t  -0.5544761292575502 \t -0.42439805248956936\n",
            "15     \t [ 0.4418527   4.49961454  5.          0.81022894 19.          0.68885116]. \t  -0.5043665497579306 \t -0.42439805248956936\n",
            "16     \t [9.87159789 0.82301761 9.         0.69884198 1.         0.99856434]. \t  -0.4556379835154939 \t -0.42439805248956936\n",
            "17     \t [ 9.4187571   0.09158132 12.          0.99701098  7.          0.20997236]. \t  -0.6237568058972295 \t -0.42439805248956936\n",
            "18     \t [ 2.97507046  9.85127832  5.          0.75729568 12.          0.23402253]. \t  -0.6222125622086827 \t -0.42439805248956936\n",
            "19     \t [ 6.6896573   9.49786322 14.          0.98343455 18.          0.89331088]. \t  -0.44269918266909547 \t -0.42439805248956936\n",
            "20     \t [ 7.50974882  6.12589601 14.          0.77913808  6.          0.27444251]. \t  -0.6226087506678725 \t -0.42439805248956936\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.562117790499774"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po5wImJaU6VC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e53f02f0-a057-4a5c-fe26-614b16c118b2"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 15\n",
        "\n",
        "np.random.seed(run_num_15)\n",
        "surrogate_approx_15 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train15, X_test15, y_train15, y_test15 = train_test_split(X, y, test_size=test_perc, random_state=run_num_15)\n",
        "\n",
        "def f_syn_polarity15(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_15, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train15, y=y_train15).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_15 = GPGO(surrogate_approx_15, Acquisition_new(util_approx), f_syn_polarity15, param, n_jobs = -1) # define BayesOpt\n",
        "approx_15.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_15 = approx_15.getResult()[0]\n",
        "params_approx_15['max_depth'] = int(params_approx_15['max_depth'])\n",
        "params_approx_15['min_child_weight'] = int(params_approx_15['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train15 = xgb.DMatrix(X_train15, y_train15)\n",
        "dX_approx_test15 = xgb.DMatrix(X_test15, y_test15)\n",
        "model_approx_15 = xgb.train(params_approx_15, dX_approx_train15)\n",
        "pred_approx_15 = model_approx_15.predict(dX_approx_test15)\n",
        "\n",
        "rmse_approx_15 = np.sqrt(mean_squared_error(pred_approx_15, y_test15))\n",
        "rmse_approx_15"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 8.48817697  1.78895925 12.          0.55549316  8.          0.93397854]. \t  -0.48943791400638287 \t -0.48943791400638287\n",
            "init   \t [ 0.24953032  8.22298097 12.          0.62494951 11.          0.12924598]. \t  -0.6992441679399787 \t -0.48943791400638287\n",
            "init   \t [ 5.02017228  5.50882771 11.          0.85295832 19.          0.13548008]. \t  -0.69945028775584 \t -0.48943791400638287\n",
            "init   \t [2.0023081  9.98543403 7.         0.6295772  2.         0.526127  ]. \t  -0.6264981748624211 \t -0.48943791400638287\n",
            "init   \t [ 5.09715306  9.45038417 11.          0.7388277  16.          0.22739973]. \t  -0.6964615643692806 \t -0.48943791400638287\n",
            "1      \t [ 0.29158961  4.9949242  12.          0.89124583  3.          0.67554049]. \t  -0.56524595824364 \t -0.48943791400638287\n",
            "2      \t [3.68214008 4.55748717 6.         0.60488381 8.         0.88973248]. \t  -0.494310985641296 \t -0.48943791400638287\n",
            "3      \t [9.75991344 6.15203198 6.         0.65490407 1.         0.73816291]. \t  -0.49903240523735964 \t -0.48943791400638287\n",
            "4      \t [ 9.51793103  9.55070381  6.          0.93315157 11.          0.40416985]. \t  -0.688799230055169 \t -0.48943791400638287\n",
            "5      \t [ 6.65116837  8.16324548 14.          0.95750787  1.          0.74925927]. \t  \u001b[92m-0.4743330993644729\u001b[0m \t -0.4743330993644729\n",
            "6      \t [ 0.41861043  0.05076637  5.          0.78940316 12.          0.77619725]. \t  -0.5149313800202362 \t -0.4743330993644729\n",
            "7      \t [ 0.44758083  1.21361479 14.          0.72053858 16.          0.73785377]. \t  -0.48610261627787 \t -0.4743330993644729\n",
            "8      \t [ 9.36080884  1.0313168   5.          0.6330142  14.          0.51274968]. \t  -0.6459684741407418 \t -0.4743330993644729\n",
            "9      \t [ 3.89599673  7.59173972  5.          0.94509004 14.          0.68417344]. \t  -0.5757237316898676 \t -0.4743330993644729\n",
            "10     \t [4.3552321  3.34830177 9.         0.76229473 1.         0.13073039]. \t  -0.6974379414299371 \t -0.4743330993644729\n",
            "11     \t [ 0.22313453  7.46320923  9.          0.98956429 19.          0.22753615]. \t  -0.6992681026416028 \t -0.4743330993644729\n",
            "12     \t [ 3.91025291  0.94746935  6.          0.83827135 18.          0.68489482]. \t  -0.5761732475509362 \t -0.4743330993644729\n",
            "13     \t [ 1.41127451  0.02455301 14.          0.99438541  9.          0.56009967]. \t  -0.6155173676416096 \t -0.4743330993644729\n",
            "14     \t [ 7.09557213  0.02461437 14.          0.76122797 15.          0.64719348]. \t  -0.5671440080891083 \t -0.4743330993644729\n",
            "15     \t [ 7.70971055  5.9598343  10.          0.83735899 18.          0.36826156]. \t  -0.6853727999168309 \t -0.4743330993644729\n",
            "16     \t [0.         0.         5.         0.67913459 4.52932381 0.6656685 ]. \t  -0.5780493290636702 \t -0.4743330993644729\n",
            "17     \t [9.52146177 3.75389952 5.         0.5049997  7.         0.95818795]. \t  -0.5077587114042463 \t -0.4743330993644729\n",
            "18     \t [ 8.77636678  8.74391722 14.          0.79691628 11.          0.9639423 ]. \t  \u001b[92m-0.47422405894109615\u001b[0m \t -0.47422405894109615\n",
            "19     \t [ 2.27839391  3.48085254  9.          0.82265329 13.          0.31218776]. \t  -0.6838527397579454 \t -0.47422405894109615\n",
            "20     \t [10.   0.  15.   0.5  1.   1. ]. \t  -0.47516221601210623 \t -0.47422405894109615\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.589957692331628"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HrAQN-pU9Qo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3864f8a-e6c3-4367-96ad-f6dc3bd44e19"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 16\n",
        "\n",
        "np.random.seed(run_num_16)\n",
        "surrogate_approx_16 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train16, X_test16, y_train16, y_test16 = train_test_split(X, y, test_size=test_perc, random_state=run_num_16)\n",
        "\n",
        "def f_syn_polarity16(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_16, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train16, y=y_train16).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_16 = GPGO(surrogate_approx_16, Acquisition_new(util_approx), f_syn_polarity16, param, n_jobs = -1) # define BayesOpt\n",
        "approx_16.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_16 = approx_16.getResult()[0]\n",
        "params_approx_16['max_depth'] = int(params_approx_16['max_depth'])\n",
        "params_approx_16['min_child_weight'] = int(params_approx_16['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train16 = xgb.DMatrix(X_train16, y_train16)\n",
        "dX_approx_test16 = xgb.DMatrix(X_test16, y_test16)\n",
        "model_approx_16 = xgb.train(params_approx_16, dX_approx_train16)\n",
        "pred_approx_16 = model_approx_16.predict(dX_approx_test16)\n",
        "\n",
        "rmse_approx_16 = np.sqrt(mean_squared_error(pred_approx_16, y_test16))\n",
        "rmse_approx_16"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [2.23291079 5.23163341 6.         0.65430839 5.         0.30077285]. \t  -0.6357813258069683 \t -0.6345701590947206\n",
            "init   \t [6.88726162 1.63731425 7.         0.97050543 2.         0.25392012]. \t  -0.7029752724132097 \t -0.6345701590947206\n",
            "init   \t [ 5.94328983  5.6393473   5.          0.67602695 19.          0.42538144]. \t  -0.6345701590947206 \t -0.6345701590947206\n",
            "init   \t [ 0.88741148  3.08148142 14.          0.56043938  9.          0.27515386]. \t  -0.7076230970293895 \t -0.6345701590947206\n",
            "init   \t [ 2.74631586  1.30996118 11.          0.52160786  8.          0.27956463]. \t  -0.7061563820165734 \t -0.6345701590947206\n",
            "1      \t [ 7.8937256   1.5972923  14.          0.61610774 17.          0.78739284]. \t  \u001b[92m-0.5498317738591506\u001b[0m \t -0.5498317738591506\n",
            "2      \t [ 9.01655783  8.21383177  9.          0.60772965 10.          0.9401803 ]. \t  \u001b[92m-0.4830822737254163\u001b[0m \t -0.4830822737254163\n",
            "3      \t [ 4.35132073  9.89698316 12.          0.94137984 16.          0.57741056]. \t  -0.5389659972108385 \t -0.4830822737254163\n",
            "4      \t [ 3.38377852  9.31285251 11.          0.88244942  1.          0.67627774]. \t  -0.5404220213450739 \t -0.4830822737254163\n",
            "5      \t [ 0.02157337  9.97534925  5.          0.75404051 13.          0.40760752]. \t  -0.6336754873953304 \t -0.4830822737254163\n",
            "6      \t [ 0.19317903  0.6596816   6.          0.86233301 15.          0.41906313]. \t  -0.6308098904949025 \t -0.4830822737254163\n",
            "7      \t [ 9.2502617   3.00821528  6.          0.66523104 13.          0.86141057]. \t  -0.4940033314748349 \t -0.4830822737254163\n",
            "8      \t [ 1.22130867  0.64008351 12.          0.59515137 19.          0.65193522]. \t  -0.5486769508942775 \t -0.4830822737254163\n",
            "9      \t [ 9.94620544  1.66561851 11.          0.64793653  8.          0.53536185]. \t  -0.5699263659145453 \t -0.4830822737254163\n",
            "10     \t [8.12731949 9.23712019 5.         0.71442381 2.         0.11528188]. \t  -0.7071533993846538 \t -0.4830822737254163\n",
            "11     \t [ 8.63952355  8.87914214 14.          0.57943185  3.          0.83429859]. \t  -0.5495434658820855 \t -0.4830822737254163\n",
            "12     \t [ 2.23523952  3.62733473 12.          0.51556206  2.          0.2036675 ]. \t  -0.7124687886931153 \t -0.4830822737254163\n",
            "13     \t [ 7.72830432  0.56848968 14.          0.94940741  3.          0.61543829]. \t  -0.5394971785451323 \t -0.4830822737254163\n",
            "14     \t [2.43756281e-03 1.86203502e-01 1.10000000e+01 5.84519618e-01\n",
            " 1.30000000e+01 2.30149841e-01]. \t  -0.7072748319481598 \t -0.4830822737254163\n",
            "15     \t [ 3.22380477  8.8210053  12.          0.91827732  7.          0.1365336 ]. \t  -0.7049504170537606 \t -0.4830822737254163\n",
            "16     \t [ 9.28336661  6.57187836 11.          0.54297007 17.          0.56210295]. \t  -0.5785906968518683 \t -0.4830822737254163\n",
            "17     \t [ 0.03255143  5.62206767 10.          0.695628   16.          0.90161277]. \t  \u001b[92m-0.4734497149203408\u001b[0m \t -0.4734497149203408\n",
            "18     \t [ 0.06909596  9.96923496  8.          0.86088515 19.          0.34694652]. \t  -0.6319267098065176 \t -0.4734497149203408\n",
            "19     \t [ 6.18013749  9.69222015  6.          0.87704216 14.          0.79491401]. \t  -0.5399181165937633 \t -0.4734497149203408\n",
            "20     \t [ 6.23198582  4.61080248 11.          0.74322916 13.          0.31928721]. \t  -0.6340612777696275 \t -0.4734497149203408\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.9062523492935854"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXelbcAVVCqO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0d6d879-7abf-445e-b3e1-f8d2618ae184"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 17\n",
        "\n",
        "np.random.seed(run_num_17)\n",
        "surrogate_approx_17 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train17, X_test17, y_train17, y_test17 = train_test_split(X, y, test_size=test_perc, random_state=run_num_17)\n",
        "\n",
        "def f_syn_polarity17(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_17, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train17, y=y_train17).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_17 = GPGO(surrogate_approx_17, Acquisition_new(util_approx), f_syn_polarity17, param, n_jobs = -1) # define BayesOpt\n",
        "approx_17.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_17 = approx_17.getResult()[0]\n",
        "params_approx_17['max_depth'] = int(params_approx_17['max_depth'])\n",
        "params_approx_17['min_child_weight'] = int(params_approx_17['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train17 = xgb.DMatrix(X_train17, y_train17)\n",
        "dX_approx_test17 = xgb.DMatrix(X_test17, y_test17)\n",
        "model_approx_17 = xgb.train(params_approx_17, dX_approx_train17)\n",
        "pred_approx_17 = model_approx_17.predict(dX_approx_test17)\n",
        "\n",
        "rmse_approx_17 = np.sqrt(mean_squared_error(pred_approx_17, y_test17))\n",
        "rmse_approx_17"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 2.94665003  5.30586756 11.          0.94443241 14.          0.80828691]. \t  -0.48092361225642916 \t -0.48092361225642916\n",
            "init   \t [ 6.56333522  6.37520896 12.          0.81487881 18.          0.42203224]. \t  -0.634455605137701 \t -0.48092361225642916\n",
            "init   \t [ 9.45683187  0.6004468  11.          0.5171566  10.          0.53881211]. \t  -0.6046684392629649 \t -0.48092361225642916\n",
            "init   \t [2.72705857 1.19063434 6.         0.74176431 6.         0.10101151]. \t  -0.6562801618178493 \t -0.48092361225642916\n",
            "init   \t [ 4.77631812  5.24671297 13.          0.66254476 19.          0.36708086]. \t  -0.6415104035419145 \t -0.48092361225642916\n",
            "1      \t [ 0.65702322  5.79284078 13.          0.75136902  1.          0.30306068]. \t  -0.6424064809093688 \t -0.48092361225642916\n",
            "2      \t [ 6.93446178  8.68032298 13.          0.78195789  7.          0.91906958]. \t  \u001b[92m-0.47529593119031155\u001b[0m \t -0.47529593119031155\n",
            "3      \t [9.72843652 3.88893279 9.         0.6901555  1.         0.31608219]. \t  -0.6407338037654788 \t -0.47529593119031155\n",
            "4      \t [ 9.65057736  8.52725784  5.          0.68420234 13.          0.40008732]. \t  -0.6446152251367371 \t -0.47529593119031155\n",
            "5      \t [ 4.97204887  2.40072226  5.          0.54268748 19.          0.30995407]. \t  -0.6473150344064219 \t -0.47529593119031155\n",
            "6      \t [0.12174033 8.73496008 5.         0.89827646 5.         0.85354798]. \t  -0.4993728869548043 \t -0.47529593119031155\n",
            "7      \t [ 2.91443079  0.16723755 13.          0.598201    6.          0.91729605]. \t  -0.48363736808522184 \t -0.47529593119031155\n",
            "8      \t [7.20615247 9.36901627 6.         0.85465034 7.         0.6878262 ]. \t  -0.5223074457605629 \t -0.47529593119031155\n",
            "9      \t [ 9.02586164  0.59354638 10.          0.86038693 18.          0.90794111]. \t  -0.48184301693459747 \t -0.47529593119031155\n",
            "10     \t [ 0.          5.95382041  5.          0.5        11.37472151  0.1       ]. \t  -0.6636626772067994 \t -0.47529593119031155\n",
            "11     \t [ 0.12410542  7.60180472 13.          0.97425003  8.          0.76245421]. \t  \u001b[92m-0.47195842108145214\u001b[0m \t -0.47195842108145214\n",
            "12     \t [ 2.44282715  9.71851747  7.          0.86792183 17.          0.93015556]. \t  -0.48228384573163224 \t -0.47195842108145214\n",
            "13     \t [9.59190042 1.26233772 5.         0.55398722 6.         0.46259714]. \t  -0.6127976173878007 \t -0.47195842108145214\n",
            "14     \t [ 9.06002681  9.03779351 14.          0.60614154  1.          0.16421461]. \t  -0.6627557424336108 \t -0.47195842108145214\n",
            "15     \t [ 0.59590325  0.30071901  8.          0.9148403  16.          0.62633871]. \t  -0.507330476870976 \t -0.47195842108145214\n",
            "16     \t [ 8.69529605  0.27226865 14.          0.90636352  1.          0.39638219]. \t  -0.6352506435607296 \t -0.47195842108145214\n",
            "17     \t [ 5.5997101   2.80089542 11.          0.91397635  4.          0.58148876]. \t  -0.49267256921662134 \t -0.47195842108145214\n",
            "18     \t [ 0.          6.57711107 10.28785265  0.5        20.          0.1       ]. \t  -0.666643693957876 \t -0.47195842108145214\n",
            "19     \t [ 9.24004771  6.36004976 11.          0.81644504 12.          0.66235401]. \t  -0.5080582866060617 \t -0.47195842108145214\n",
            "20     \t [10.         10.          5.00003108  1.          1.          1.        ]. \t  -0.4876581060509898 \t -0.47195842108145214\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.758964442352727"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJG2fAtAVFDZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5393f817-cab3-40f2-bea3-f7305249e7ae"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 18\n",
        "\n",
        "np.random.seed(run_num_18)\n",
        "surrogate_approx_18 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train18, X_test18, y_train18, y_test18 = train_test_split(X, y, test_size=test_perc, random_state=run_num_18)\n",
        "\n",
        "def f_syn_polarity18(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_11, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train18, y=y_train18).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_18 = GPGO(surrogate_approx_18, Acquisition_new(util_approx), f_syn_polarity18, param, n_jobs = -1) # define BayesOpt\n",
        "approx_18.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_18 = approx_18.getResult()[0]\n",
        "params_approx_18['max_depth'] = int(params_approx_18['max_depth'])\n",
        "params_approx_18['min_child_weight'] = int(params_approx_18['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train18 = xgb.DMatrix(X_train18, y_train18)\n",
        "dX_approx_test18 = xgb.DMatrix(X_test18, y_test18)\n",
        "model_approx_18 = xgb.train(params_approx_18, dX_approx_train18)\n",
        "pred_approx_18 = model_approx_18.predict(dX_approx_test18)\n",
        "\n",
        "rmse_approx_18 = np.sqrt(mean_squared_error(pred_approx_18, y_test18))\n",
        "rmse_approx_18"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [6.50374242 5.05453374 6.         0.59092011 3.         0.28357516]. \t  -0.6513740959050699 \t -0.4474949996843899\n",
            "init   \t [0.11506734 4.26891483 9.         0.81785956 5.         0.63489043]. \t  -0.5068571689279089 \t -0.4474949996843899\n",
            "init   \t [ 2.8861259   6.35547834 11.          0.64267955 14.          0.27877092]. \t  -0.6466851980958979 \t -0.4474949996843899\n",
            "init   \t [6.57189031 6.99655629 8.         0.63235896 4.         0.52894035]. \t  -0.5514036168275981 \t -0.4474949996843899\n",
            "init   \t [ 6.66600348  2.11312037 14.          0.74363461  4.          0.73174558]. \t  -0.4474949996843899 \t -0.4474949996843899\n",
            "1      \t [ 8.67093232  0.11649132  5.          0.92962202 15.          0.53672863]. \t  -0.5562589356787108 \t -0.4474949996843899\n",
            "2      \t [ 8.43851229  2.41114508 13.          0.75771586 19.          0.86905071]. \t  \u001b[92m-0.44050164109333145\u001b[0m \t -0.44050164109333145\n",
            "3      \t [ 9.44281001  9.01534322  7.          0.99142432 16.          0.37631199]. \t  -0.549158457418693 \t -0.44050164109333145\n",
            "4      \t [ 3.19538294  9.91737336 14.          0.7976317   5.          0.25704487]. \t  -0.6515598146742108 \t -0.44050164109333145\n",
            "5      \t [ 1.97643014  8.37982471  5.          0.63246176 17.          0.45403539]. \t  -0.5634039832057651 \t -0.44050164109333145\n",
            "6      \t [ 1.26601315  0.31299408  6.          0.95296222 16.          0.13649883]. \t  -0.6466742489441083 \t -0.44050164109333145\n",
            "7      \t [ 1.18347798  2.03195078 14.          0.62549517 10.          0.6517083 ]. \t  -0.511373695923542 \t -0.44050164109333145\n",
            "8      \t [6.72039962 1.0287777  9.         0.62848622 9.         0.70815446]. \t  -0.5159589935554622 \t -0.44050164109333145\n",
            "9      \t [ 7.49192948  9.60283663 14.          0.93718151 19.          0.24625933]. \t  -0.6476549496904568 \t -0.44050164109333145\n",
            "10     \t [ 3.63870552  9.73349763  7.          0.73625258 11.          0.87968363]. \t  -0.4484432027321388 \t -0.44050164109333145\n",
            "11     \t [9.98653758 8.80568206 9.         0.86984433 9.         0.78984159]. \t  -0.45607631534129245 \t -0.44050164109333145\n",
            "12     \t [ 1.68019344  0.20490035 13.          0.89332378 19.          0.17761947]. \t  -0.6471945108281247 \t -0.44050164109333145\n",
            "13     \t [0.58655573 8.89860432 5.         0.62593909 1.         0.46819727]. \t  -0.5622837222481027 \t -0.44050164109333145\n",
            "14     \t [ 4.25762222  4.02301922  9.          0.6129246  19.          0.59981465]. \t  -0.5142020783326252 \t -0.44050164109333145\n",
            "15     \t [ 5.93963174  0.35038192 14.          0.99474968 14.          0.46057279]. \t  -0.5351521207701755 \t -0.44050164109333145\n",
            "16     \t [2.5556895  0.91787864 5.         0.57129972 6.         0.40466558]. \t  -0.5665188856299738 \t -0.44050164109333145\n",
            "17     \t [ 8.60576508  8.57930928 14.          0.78656855  7.          0.59728424]. \t  -0.5071486743154364 \t -0.44050164109333145\n",
            "18     \t [ 9.56072091  9.1368036  14.          0.68050527  1.          0.47597207]. \t  -0.5560730708083954 \t -0.44050164109333145\n",
            "19     \t [ 0.          6.72821976 10.97306698  1.         19.00755008  0.1       ]. \t  -0.7427115446644637 \t -0.44050164109333145\n",
            "20     \t [ 2.08722767  3.98919754  5.          0.76742571 11.          0.93277603]. \t  -0.46014482327322215 \t -0.44050164109333145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.746067780922308"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHidSEGcVHvG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "609afea7-82a1-41e9-e61b-9651cbe2c344"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 19\n",
        "\n",
        "np.random.seed(run_num_19)\n",
        "surrogate_approx_19 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train19, X_test19, y_train19, y_test19 = train_test_split(X, y, test_size=test_perc, random_state=run_num_19)\n",
        "\n",
        "def f_syn_polarity19(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_19, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train19, y=y_train19).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_19 = GPGO(surrogate_approx_19, Acquisition_new(util_approx), f_syn_polarity19, param, n_jobs = -1) # define BayesOpt\n",
        "approx_19.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_19 = approx_19.getResult()[0]\n",
        "params_approx_19['max_depth'] = int(params_approx_19['max_depth'])\n",
        "params_approx_19['min_child_weight'] = int(params_approx_19['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train19 = xgb.DMatrix(X_train19, y_train19)\n",
        "dX_approx_test19 = xgb.DMatrix(X_test19, y_test19)\n",
        "model_approx_19 = xgb.train(params_approx_19, dX_approx_train19)\n",
        "pred_approx_19 = model_approx_19.predict(dX_approx_test19)\n",
        "\n",
        "rmse_approx_19 = np.sqrt(mean_squared_error(pred_approx_19, y_test19))\n",
        "rmse_approx_19"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 0.97533602  7.61249717 13.          0.85765469 11.          0.39830191]. \t  -0.5851081958447377 \t -0.4870287725699859\n",
            "init   \t [ 0.82999565  6.71977081  6.          0.50407413 19.          0.67209466]. \t  -0.5245729886945251 \t -0.4870287725699859\n",
            "init   \t [ 2.15923256  5.49027432 12.          0.52588686 10.          0.20235326]. \t  -0.677999989539271 \t -0.4870287725699859\n",
            "init   \t [4.99659267 1.52108422 6.         0.73481085 4.         0.71949465]. \t  -0.4940235599803803 \t -0.4870287725699859\n",
            "init   \t [ 3.72927156  9.46160045  5.          0.80554614 18.          0.97708466]. \t  -0.4870287725699859 \t -0.4870287725699859\n",
            "1      \t [ 8.33060043  1.42030563  8.          0.92863724 14.          0.78606141]. \t  \u001b[92m-0.48699206254226385\u001b[0m \t -0.48699206254226385\n",
            "2      \t [ 4.70068371  4.9755295  14.          0.98901029  1.          0.96039614]. \t  \u001b[92m-0.454763872590455\u001b[0m \t -0.454763872590455\n",
            "3      \t [9.07948237 9.55063617 7.         0.80962147 4.         0.34142584]. \t  -0.5905722937491956 \t -0.454763872590455\n",
            "4      \t [ 3.65000245  2.90359952 13.          0.98940034 19.          0.29019455]. \t  -0.5803493338026307 \t -0.454763872590455\n",
            "5      \t [0.25768796 8.33414072 6.         0.99948369 4.         0.66680619]. \t  -0.5074502274890225 \t -0.454763872590455\n",
            "6      \t [ 8.89243569  4.2136102  10.          0.88870164  8.          0.77683659]. \t  -0.4793573657831819 \t -0.454763872590455\n",
            "7      \t [ 9.20734788  9.40702602 11.          0.68264617 14.          0.68723167]. \t  -0.5088698943836598 \t -0.454763872590455\n",
            "8      \t [1.60895472e-01 8.27074864e-03 1.30000000e+01 6.91893018e-01\n",
            " 5.00000000e+00 4.60327119e-01]. \t  -0.5676975299111877 \t -0.454763872590455\n",
            "9      \t [ 0.32873959  7.7155114   5.          0.56871173 11.          0.34471029]. \t  -0.5850396812677789 \t -0.454763872590455\n",
            "10     \t [ 6.55489773  0.06438745 14.          0.53351105 11.          0.76391016]. \t  -0.4835963309582638 \t -0.454763872590455\n",
            "11     \t [ 9.32390837  9.51845123 14.          0.71072327  2.          0.55726506]. \t  -0.5721136978716921 \t -0.454763872590455\n",
            "12     \t [ 4.31405249  0.92741236  7.          0.67333637 19.          0.97097788]. \t  -0.47827249796188526 \t -0.454763872590455\n",
            "13     \t [ 4.44431879  9.49168646 13.          0.64581011 19.          0.4702202 ]. \t  -0.5592489367596285 \t -0.454763872590455\n",
            "14     \t [ 5.91102876  9.59864462 12.          0.78362129  7.          0.97877384]. \t  -0.4591791053241341 \t -0.454763872590455\n",
            "15     \t [0.22611985 0.1170465  7.         0.55795985 9.         0.86758401]. \t  -0.47279581874539717 \t -0.454763872590455\n",
            "16     \t [ 9.0780433   8.49155787  5.          0.8925855  13.          0.38273904]. \t  -0.5938832064204094 \t -0.454763872590455\n",
            "17     \t [ 9.89996921  0.59570014 13.          0.67906413  1.          0.37793763]. \t  -0.5890751717161915 \t -0.454763872590455\n",
            "18     \t [ 0.65734769  9.79668398 13.          0.57710479  1.          0.50646708]. \t  -0.5771756215263869 \t -0.454763872590455\n",
            "19     \t [ 0.17032432  0.5511349   8.          0.8772351  15.          0.24483614]. \t  -0.6798814652826352 \t -0.454763872590455\n",
            "20     \t [ 3.82670531  7.06245628  8.          0.7747773  14.          0.11384763]. \t  -0.67893464439286 \t -0.454763872590455\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.63424117920896"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWGPYRJhVKsO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "791ec445-2379-434c-ecf6-2cad71bec18d"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 20\n",
        "\n",
        "np.random.seed(run_num_20)\n",
        "surrogate_approx_20 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train20, X_test20, y_train20, y_test20 = train_test_split(X, y, test_size=test_perc, random_state=run_num_20)\n",
        "\n",
        "def f_syn_polarity20(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_20, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train20, y=y_train20).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_20 = GPGO(surrogate_approx_20, Acquisition_new(util_approx), f_syn_polarity20, param, n_jobs = -1) # define BayesOpt\n",
        "approx_20.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_20 = approx_20.getResult()[0]\n",
        "params_approx_20['max_depth'] = int(params_approx_20['max_depth'])\n",
        "params_approx_20['min_child_weight'] = int(params_approx_20['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train20 = xgb.DMatrix(X_train20, y_train20)\n",
        "dX_approx_test20 = xgb.DMatrix(X_test20, y_test20)\n",
        "model_approx_20 = xgb.train(params_approx_20, dX_approx_train20)\n",
        "pred_approx_20 = model_approx_20.predict(dX_approx_test20)\n",
        "\n",
        "rmse_approx_20 = np.sqrt(mean_squared_error(pred_approx_20, y_test20))\n",
        "rmse_approx_20"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 5.88130801  8.97713728 14.          0.81074445  8.          0.95540649]. \t  -0.4485352768858121 \t -0.4485352768858121\n",
            "init   \t [6.72865655 0.41173329 8.         0.6361582  7.         0.76174061]. \t  -0.47208091450542966 \t -0.4485352768858121\n",
            "init   \t [ 4.77387703  8.66202323 10.          0.51833215  7.          0.10123387]. \t  -0.7316473600840852 \t -0.4485352768858121\n",
            "init   \t [ 5.75489985  4.74524381  8.          0.78084343 15.          0.26643049]. \t  -0.7314226542252507 \t -0.4485352768858121\n",
            "init   \t [ 4.53444     4.47342833  8.          0.91974896 18.          0.35997552]. \t  -0.6494230116583573 \t -0.4485352768858121\n",
            "1      \t [ 7.96566073  7.15509535  7.          0.79906691 11.          0.34132075]. \t  -0.6502222800629637 \t -0.4485352768858121\n",
            "2      \t [0.0691652  5.34850007 7.         0.63667652 1.         0.21496993]. \t  -0.734189618090561 \t -0.4485352768858121\n",
            "3      \t [ 3.00704909  2.42524876 14.          0.95062509 15.          0.83595087]. \t  -0.4577111911042998 \t -0.4485352768858121\n",
            "4      \t [ 7.32450119  0.97088138 14.          0.62864562  2.          0.93189305]. \t  -0.45820457406982984 \t -0.4485352768858121\n",
            "5      \t [8.0846212  5.99993376 6.         0.83941375 1.         0.46362124]. \t  -0.5681524533474447 \t -0.4485352768858121\n",
            "6      \t [ 4.85539645  9.01721781 14.          0.60995232 19.          0.22249343]. \t  -0.736197854033078 \t -0.4485352768858121\n",
            "7      \t [ 0.72788527  2.26655356 10.          0.97273032 15.          0.85843758]. \t  -0.45084600130879665 \t -0.4485352768858121\n",
            "8      \t [ 7.29847873  0.61439441  5.          0.60353619 15.          0.628184  ]. \t  -0.5276788324413187 \t -0.4485352768858121\n",
            "9      \t [ 0.05422088  9.41967109  9.          0.63564274 14.          0.96864948]. \t  -0.46187798796290325 \t -0.4485352768858121\n",
            "10     \t [ 9.46105078  8.51558179 14.          0.6234267   1.          0.59075489]. \t  -0.5032366764216073 \t -0.4485352768858121\n",
            "11     \t [ 3.28444135  4.88068826 13.          0.83217983  5.          0.1064095 ]. \t  -0.7345026006644485 \t -0.4485352768858121\n",
            "12     \t [ 9.95790482  0.39582549 14.          0.73682131 13.          0.88500223]. \t  -0.46684081731949795 \t -0.4485352768858121\n",
            "13     \t [ 8.98143836  8.7693897  12.          0.89468403 12.          0.66552576]. \t  -0.49793969514395464 \t -0.4485352768858121\n",
            "14     \t [ 9.53401947  2.04639571 13.          0.59498138 19.          0.43345618]. \t  -0.5779866795713233 \t -0.4485352768858121\n",
            "15     \t [ 5.37444991  0.3056877   9.          0.99777328 15.          0.5903115 ]. \t  -0.5008636074552522 \t -0.4485352768858121\n",
            "16     \t [1.01173572 1.57355816 5.         0.66922967 6.         0.97562515]. \t  -0.4761297636811378 \t -0.4485352768858121\n",
            "17     \t [ 9.44977056  8.08706416 10.          0.57562031 19.          0.10040302]. \t  -0.7354086895092465 \t -0.4485352768858121\n",
            "18     \t [ 0.95166608  0.72165502 12.          0.68549843  9.          0.11447959]. \t  -0.7323877943597793 \t -0.4485352768858121\n",
            "19     \t [ 0.72440064  9.37673317 12.          0.5979442   2.          0.11910674]. \t  -0.7380201541985442 \t -0.4485352768858121\n",
            "20     \t [ 1.39513001  1.37149056  5.          0.56200696 12.          0.29219492]. \t  -0.6531158385825743 \t -0.4485352768858121\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.454763173494824"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1d_1LyydIfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55bfcaaf-e4ff-48fb-9f37-66ba0cb2f888"
      },
      "source": [
        "end_approx = time.time()\n",
        "end_approx\n",
        "\n",
        "time_approx = end_approx - start_approx\n",
        "time_approx\n",
        "\n",
        "start_exact = time.time()\n",
        "start_exact"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1623252576.0246754"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAyOw7XYVwAf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "414fc670-4b39-4af2-ccda-404250c77c8c"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 1 \n",
        "\n",
        "np.random.seed(run_num_1)\n",
        "surrogate_exact_1 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=test_perc, random_state=run_num_1)\n",
        "\n",
        "def f_syn_polarity1(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_1, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train1, y=y_train1).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_1 = dGPGO(surrogate_exact_1, Acquisition_new(util_exact), f_syn_polarity1, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_1.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_1 = exact_1.getResult()[0]\n",
        "params_exact_1['max_depth'] = int(params_exact_1['max_depth'])\n",
        "params_exact_1['min_child_weight'] = int(params_exact_1['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train1 = xgb.DMatrix(X_train1, y_train1)\n",
        "dX_exact_test1 = xgb.DMatrix(X_test1, y_test1)\n",
        "model_exact_1 = xgb.train(params_exact_1, dX_exact_train1)\n",
        "pred_exact_1 = model_exact_1.predict(dX_exact_test1)\n",
        "\n",
        "rmse_exact_1 = np.sqrt(mean_squared_error(pred_exact_1, y_test1))\n",
        "rmse_exact_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [5.48813504 7.15189366 8.         0.92897281 8.         0.48128932]. \t  -0.5626915313589341 \t -0.46143572360276275\n",
            "init   \t [ 6.45894113  4.37587211 11.          0.52835649 13.          0.44509737]. \t  -0.5772881365468763 \t -0.46143572360276275\n",
            "init   \t [ 7.91725038  5.2889492  13.          0.6963924  14.          0.40365654]. \t  -0.5870544636272766 \t -0.46143572360276275\n",
            "init   \t [ 6.48171872  3.6824154  10.          0.88907838 16.          0.88307853]. \t  -0.46143572360276275 \t -0.46143572360276275\n",
            "init   \t [4.73608045 8.00910752 8.         0.83943977 8.         0.67592892]. \t  -0.5051288806760134 \t -0.46143572360276275\n",
            "1      \t [ 0.96098408  9.76459465  7.          0.75481219 17.          0.64436097]. \t  -0.5149059967458438 \t -0.46143572360276275\n",
            "2      \t [ 5.13759733  2.22657933 12.          0.58106013  2.          0.92007745]. \t  -0.46868154430393166 \t -0.46143572360276275\n",
            "3      \t [9.58067178 9.65734278 7.         0.88193436 1.         0.38223155]. \t  -0.5888715285109799 \t -0.46143572360276275\n",
            "4      \t [0.  0.  5.  0.5 1.  0.1]. \t  -0.6779967301528039 \t -0.46143572360276275\n",
            "5      \t [ 0.12917683  7.27788751 10.          0.94371091  2.          0.12091296]. \t  -0.6739913400324926 \t -0.46143572360276275\n",
            "6      \t [ 8.87166351  9.3367646   5.          0.58200219 19.          0.4055524 ]. \t  -0.6087566280502396 \t -0.46143572360276275\n",
            "7      \t [ 0.51228404  8.90605177 14.          0.7949699  11.          0.73913262]. \t  \u001b[92m-0.46104762612970374\u001b[0m \t -0.46104762612970374\n",
            "8      \t [ 2.05150398  0.53599727  5.          0.71551734 11.          0.37377971]. \t  -0.60261611749113 \t -0.46104762612970374\n",
            "9      \t [8.38797278 0.6003286  6.         0.6181346  1.         0.60370114]. \t  -0.526164863483156 \t -0.46104762612970374\n",
            "10     \t [ 9.06530919  9.40796401 14.          0.73452132  4.          0.22638202]. \t  -0.6737273666958219 \t -0.46104762612970374\n",
            "11     \t [ 2.92761431  0.02841708 13.          0.97950295  9.          0.31091424]. \t  -0.5822275926277118 \t -0.46104762612970374\n",
            "12     \t [9.14092793 0.64739809 8.         0.90967035 8.         0.70435457]. \t  -0.5029298264030027 \t -0.46104762612970374\n",
            "13     \t [ 1.99180311  1.76156949  6.          0.52474573 18.          0.69397695]. \t  -0.5292680491699555 \t -0.46104762612970374\n",
            "14     \t [ 1.47165443  0.32474578 13.          0.93757169 15.          0.40230457]. \t  -0.5795930586132758 \t -0.46104762612970374\n",
            "15     \t [ 3.33998723  9.61997442 13.          0.87678219 17.          0.47112812]. \t  -0.562089749118206 \t -0.46104762612970374\n",
            "16     \t [ 0.59268574  5.88934857  8.          0.90451848 12.          0.19426621]. \t  -0.6701635295211161 \t -0.46104762612970374\n",
            "17     \t [ 7.96942817  9.76181769  7.          0.91046857 13.          0.32455735]. \t  -0.5870001390492389 \t -0.46104762612970374\n",
            "18     \t [4.22240748 6.41687796 5.         0.84764325 1.         0.63972487]. \t  -0.5262902306647949 \t -0.46104762612970374\n",
            "19     \t [ 8.8155061   8.22817745 14.          0.53858872 19.          0.2617363 ]. \t  -0.6742981553252253 \t -0.46104762612970374\n",
            "20     \t [ 0.37157734  3.11392041 14.          0.79304737  5.          0.73468784]. \t  -0.4627112112746034 \t -0.46104762612970374\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.667222167746296"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrDQbChpZ48F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f047c684-44b4-438a-abcb-efd9bc4ddfad"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 2 \n",
        "\n",
        "np.random.seed(run_num_2)\n",
        "surrogate_exact_2 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=test_perc, random_state=run_num_2)\n",
        "\n",
        "def f_syn_polarity2(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_2, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train2, y=y_train2).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_2 = dGPGO(surrogate_exact_2, Acquisition_new(util_exact), f_syn_polarity2, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_2.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_2 = exact_2.getResult()[0]\n",
        "params_exact_2['max_depth'] = int(params_exact_2['max_depth'])\n",
        "params_exact_2['min_child_weight'] = int(params_exact_2['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train2 = xgb.DMatrix(X_train2, y_train2)\n",
        "dX_exact_test2 = xgb.DMatrix(X_test2, y_test2)\n",
        "model_exact_2 = xgb.train(params_exact_2, dX_exact_train2)\n",
        "pred_exact_2 = model_exact_2.predict(dX_exact_test2)\n",
        "\n",
        "rmse_exact_2 = np.sqrt(mean_squared_error(pred_exact_2, y_test2))\n",
        "rmse_exact_2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 4.35994902  0.25926232 11.          0.97386531 12.          0.47833102]. \t  -0.5147867600449748 \t -0.4765694615523879\n",
            "init   \t [ 3.30334821  2.04648634 10.          0.55997527  6.          0.71472339]. \t  -0.4765694615523879 \t -0.4765694615523879\n",
            "init   \t [ 4.9856117   5.86796978  8.          0.89266757 11.          0.59158659]. \t  -0.4946399399702889 \t -0.4765694615523879\n",
            "init   \t [ 4.07307832  1.76984624 13.          0.75262305  7.          0.35908193]. \t  -0.5884370816585467 \t -0.4765694615523879\n",
            "init   \t [ 1.16193318  1.81727038  9.          0.79837265 19.          0.29965165]. \t  -0.584982798458911 \t -0.4765694615523879\n",
            "1      \t [ 9.41115874  8.16019152 11.          0.70945365  2.          0.28765225]. \t  -0.5900551627442152 \t -0.4765694615523879\n",
            "2      \t [ 8.78180153  6.61060882 12.          0.91523653 18.          0.29687212]. \t  -0.5840366351865409 \t -0.4765694615523879\n",
            "3      \t [ 0.66591974  9.26661294 14.          0.96342421 18.          0.94909068]. \t  \u001b[92m-0.3879430352217851\u001b[0m \t -0.3879430352217851\n",
            "4      \t [0.53023554 8.79041977 6.         0.85342606 1.         0.93968064]. \t  -0.41489686189456554 \t -0.3879430352217851\n",
            "5      \t [6.47584802 1.65960359 8.         0.80737784 1.         0.90602123]. \t  -0.4063073187409662 \t -0.3879430352217851\n",
            "6      \t [ 2.29390808  9.72620131 13.          0.87738596  7.          0.2041919 ]. \t  -0.6789018673924765 \t -0.3879430352217851\n",
            "7      \t [ 9.77744834  2.26597384  5.          0.98618685 19.          0.58642903]. \t  -0.520384169717879 \t -0.3879430352217851\n",
            "8      \t [7.36877801 8.87815651 5.         0.56972286 4.         0.80625064]. \t  -0.5008693406902159 \t -0.3879430352217851\n",
            "9      \t [ 5.76886466  6.30636441 11.          0.85075313  6.          0.94564556]. \t  -0.39766690308447894 \t -0.3879430352217851\n",
            "10     \t [0.  0.  5.  0.5 1.  0.1]. \t  -0.6760687561093285 \t -0.3879430352217851\n",
            "11     \t [ 8.66397635  9.94226364  5.          0.61754568 19.          0.46861962]. \t  -0.5385752501499373 \t -0.3879430352217851\n",
            "12     \t [ 2.21750241  8.1937508   6.          0.88756269 17.          0.73205426]. \t  -0.4886010805216155 \t -0.3879430352217851\n",
            "13     \t [ 0.          0.          5.          0.5        10.23889203  0.1       ]. \t  -0.6746044484552947 \t -0.3879430352217851\n",
            "14     \t [ 2.61078484  8.48438058 14.          0.79784401 12.          0.37480602]. \t  -0.5873563000820609 \t -0.3879430352217851\n",
            "15     \t [ 9.63046012  9.46551843 14.          0.83717129 10.          0.78268661]. \t  -0.4661700953958383 \t -0.3879430352217851\n",
            "16     \t [ 8.39253634  0.41975132  5.          0.53583299 10.          0.93462258]. \t  -0.4369912210415411 \t -0.3879430352217851\n",
            "17     \t [ 1.36729794  4.89791321 13.          0.50996816  1.          0.64172429]. \t  -0.5046458287629003 \t -0.3879430352217851\n",
            "18     \t [ 8.76615518  1.51167594 13.          0.97549904  3.          0.62972174]. \t  -0.49119762998794947 \t -0.3879430352217851\n",
            "19     \t [ 5.41002785  1.04159958  6.36505818  0.5        16.36505818  0.1       ]. \t  -0.6749155416720527 \t -0.3879430352217851\n",
            "20     \t [ 8.94175283  9.74417102 10.          0.87790285 14.          0.24925416]. \t  -0.6776655819581459 \t -0.3879430352217851\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.600295852493361"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpUPyXRfZ95Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5cc2fc7-c753-4e30-d3c3-1ac34221a66c"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 3 \n",
        "\n",
        "np.random.seed(run_num_3)\n",
        "surrogate_exact_3 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train3, X_test3, y_train3, y_test3 = train_test_split(X, y, test_size=test_perc, random_state=run_num_3)\n",
        "\n",
        "def f_syn_polarity3(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_3, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train3, y=y_train3).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_3 = dGPGO(surrogate_exact_3, Acquisition_new(util_exact), f_syn_polarity3, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_3.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_3 = exact_3.getResult()[0]\n",
        "params_exact_3['max_depth'] = int(params_exact_3['max_depth'])\n",
        "params_exact_3['min_child_weight'] = int(params_exact_3['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train3 = xgb.DMatrix(X_train3, y_train3)\n",
        "dX_exact_test3 = xgb.DMatrix(X_test3, y_test3)\n",
        "model_exact_3 = xgb.train(params_exact_3, dX_exact_train3)\n",
        "pred_exact_3 = model_exact_3.predict(dX_exact_test3)\n",
        "\n",
        "rmse_exact_3 = np.sqrt(mean_squared_error(pred_exact_3, y_test3))\n",
        "rmse_exact_3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 5.50797903  7.08147823 13.          0.56066429 11.          0.11687321]. \t  -0.7165783188757435 \t -0.6409647951145182\n",
            "init   \t [ 0.40630737  2.47888297 11.          0.72040492 13.          0.23083313]. \t  -0.7204431346766296 \t -0.6409647951145182\n",
            "init   \t [ 4.53172301  2.15577008 11.          0.74631796  2.          0.60296868]. \t  -0.6409647951145182 \t -0.6409647951145182\n",
            "init   \t [ 2.59252447  4.15101197 13.          0.79330998  8.          0.24118096]. \t  -0.7214290072967551 \t -0.6409647951145182\n",
            "init   \t [ 5.44649018  7.80314765 10.          0.62879264 18.          0.44917413]. \t  -0.6558401549443297 \t -0.6409647951145182\n",
            "1      \t [1.56262424 9.7795241  5.         0.91450054 5.         0.53102391]. \t  -0.652766690473656 \t -0.6409647951145182\n",
            "2      \t [ 8.93142368  1.52910591 13.          0.84039318 17.          0.60846833]. \t  \u001b[92m-0.6320347814043803\u001b[0m \t -0.6320347814043803\n",
            "3      \t [ 6.38594331  1.19109066  5.          0.81189053 13.          0.59164768]. \t  \u001b[92m-0.6289274956252369\u001b[0m \t -0.6289274956252369\n",
            "4      \t [ 1.02918863  9.32189805 13.          0.88333707  1.          0.86998588]. \t  \u001b[92m-0.45190108244647254\u001b[0m \t -0.45190108244647254\n",
            "5      \t [ 9.74929058  1.51205926 11.          0.50025602  8.          0.46132437]. \t  -0.6593087000926661 \t -0.45190108244647254\n",
            "6      \t [ 9.45052852  8.62641484  7.          0.79615518 14.          0.32790361]. \t  -0.708730491334048 \t -0.45190108244647254\n",
            "7      \t [ 8.92744991  9.09956287 12.          0.74944313  3.          0.11030352]. \t  -0.7194264138705575 \t -0.45190108244647254\n",
            "8      \t [6.90239429 4.38257693 5.         0.77543741 6.         0.209803  ]. \t  -0.7198213013052538 \t -0.45190108244647254\n",
            "9      \t [ 3.41151761  3.44257275  8.          0.91039266 17.          0.41829904]. \t  -0.7078036656752346 \t -0.45190108244647254\n",
            "10     \t [9.43215663 9.14652183 5.         0.95117899 1.         0.516629  ]. \t  -0.657104878100571 \t -0.45190108244647254\n",
            "11     \t [ 3.07505056  9.78732799  6.          0.96847152 12.          0.34771766]. \t  -0.7064602508420503 \t -0.45190108244647254\n",
            "12     \t [0.20657469 2.03837081 5.         0.940951   6.         0.11008073]. \t  -0.7187989632053008 \t -0.45190108244647254\n",
            "13     \t [ 0.63366318  7.00411349 14.          0.89817768 18.          0.82387154]. \t  -0.5088999933243639 \t -0.45190108244647254\n",
            "14     \t [ 9.9224789   2.12085607  6.          0.82807413 19.          0.27539821]. \t  -0.7196366943027934 \t -0.45190108244647254\n",
            "15     \t [ 5.7586577   1.42812945 10.          0.74022438  8.          0.79053147]. \t  -0.5219655798647203 \t -0.45190108244647254\n",
            "16     \t [ 7.41867878  4.36581543 14.          0.99315379  6.          0.89117614]. \t  -0.4557702743530953 \t -0.45190108244647254\n",
            "17     \t [3.69167267 6.10773586 6.         0.9974767  1.         0.55722723]. \t  -0.6550020105283487 \t -0.45190108244647254\n",
            "18     \t [ 2.77081064  4.33888713  7.          0.86748866 10.          0.91605352]. \t  -0.4747430674172078 \t -0.45190108244647254\n",
            "19     \t [ 0.2848593   7.24262219  6.          0.70597553 19.          0.97089957]. \t  -0.4870655187666578 \t -0.45190108244647254\n",
            "20     \t [8.69445334 9.32412616 7.         0.88093126 7.         0.17908776]. \t  -0.720811785466753 \t -0.45190108244647254\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.649527586702978"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKX_nfEaaAwm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "982dd86d-6753-466d-b49b-e6e884a186d3"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 4 \n",
        "\n",
        "np.random.seed(run_num_4)\n",
        "surrogate_exact_4 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train4, X_test4, y_train4, y_test4 = train_test_split(X, y, test_size=test_perc, random_state=run_num_4)\n",
        "\n",
        "def f_syn_polarity4(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_4, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train4, y=y_train4).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_4 = dGPGO(surrogate_exact_4, Acquisition_new(util_exact), f_syn_polarity4, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_4.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_4 = exact_4.getResult()[0]\n",
        "params_exact_4['max_depth'] = int(params_exact_4['max_depth'])\n",
        "params_exact_4['min_child_weight'] = int(params_exact_4['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train4 = xgb.DMatrix(X_train4, y_train4)\n",
        "dX_exact_test4 = xgb.DMatrix(X_test4, y_test4)\n",
        "model_exact_4 = xgb.train(params_exact_4, dX_exact_train4)\n",
        "pred_exact_4 = model_exact_4.predict(dX_exact_test4)\n",
        "\n",
        "rmse_exact_4 = np.sqrt(mean_squared_error(pred_exact_4, y_test4))\n",
        "rmse_exact_4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [9.67029839 5.47232249 6.         0.92781047 9.         0.72795594]. \t  -0.5993772224326677 \t -0.4983304913999733\n",
            "init   \t [ 2.16089496  9.76274455 12.          0.62649118  9.          0.66966679]. \t  -0.6069567430422909 \t -0.4983304913999733\n",
            "init   \t [ 0.05159149  5.72356491  9.          0.99170034 10.          0.10808749]. \t  -0.7139334307278753 \t -0.4983304913999733\n",
            "init   \t [ 3.86571283  0.44160058 10.          0.90553105 18.          0.95407958]. \t  -0.4983304913999733 \t -0.4983304913999733\n",
            "init   \t [ 7.86305986  8.66289299  6.          0.53285477 14.          0.25117497]. \t  -0.7091576633146701 \t -0.4983304913999733\n",
            "1      \t [ 8.45443649  8.61014312 11.          0.83475494  1.          0.14018305]. \t  -0.7189305559932541 \t -0.4983304913999733\n",
            "2      \t [ 0.77431146  1.96668116 12.          0.50723361  3.          0.74768925]. \t  -0.6140173026050956 \t -0.4983304913999733\n",
            "3      \t [2.27858743 6.23199766 5.         0.58705984 2.         0.80794289]. \t  -0.5986031600147258 \t -0.4983304913999733\n",
            "4      \t [ 6.832625    9.87635293 14.          0.84450885 19.          0.20389666]. \t  -0.7153744507380464 \t -0.4983304913999733\n",
            "5      \t [ 7.37255369  2.03491596 13.          0.8921741   9.          0.46934318]. \t  -0.625550615237801 \t -0.4983304913999733\n",
            "6      \t [ 0.05992751  6.06320143 14.          0.89322475 17.          0.32211096]. \t  -0.6540035079472759 \t -0.4983304913999733\n",
            "7      \t [ 0.79250634  6.36332745  6.          0.84703891 17.          0.8628914 ]. \t  -0.5176542387032834 \t -0.4983304913999733\n",
            "8      \t [9.26767626 0.09691703 5.         0.59554562 3.         0.95249041]. \t  -0.524958204283032 \t -0.4983304913999733\n",
            "9      \t [ 9.93824172  2.34876498  7.          0.94210707 16.          0.6947317 ]. \t  -0.6069344861897712 \t -0.4983304913999733\n",
            "10     \t [3.43076773 0.51115291 6.         0.80398076 7.         0.163561  ]. \t  -0.7152347423610873 \t -0.4983304913999733\n",
            "11     \t [8.12039932 9.82838311 5.         0.6851891  3.         0.87462757]. \t  -0.5209212303565759 \t -0.4983304913999733\n",
            "12     \t [ 6.03647398  5.02077859  7.          0.51964174 12.          0.90396407]. \t  -0.5232196825739268 \t -0.4983304913999733\n",
            "13     \t [ 9.03174101  2.34471053 13.          0.52042845  3.          0.20136175]. \t  -0.7105427027924398 \t -0.4983304913999733\n",
            "14     \t [ 9.29091353  0.24848851 14.          0.65742606 17.          0.33836791]. \t  -0.655558370799832 \t -0.4983304913999733\n",
            "15     \t [3.19488299 9.73527155 6.         0.65266597 9.         0.60657999]. \t  -0.6104166590688074 \t -0.4983304913999733\n",
            "16     \t [ 2.02212851  9.9407933  10.          0.71009222  3.          0.59925198]. \t  -0.6118231860074616 \t -0.4983304913999733\n",
            "17     \t [0.         0.         5.24159865 0.5        1.         0.1       ]. \t  -0.7094830419675008 \t -0.4983304913999733\n",
            "18     \t [ 6.65760625  2.35253217 11.          0.58483338 14.          0.21088543]. \t  -0.7100640025661658 \t -0.4983304913999733\n",
            "19     \t [ 0.9141999   0.89707594 12.          0.91410151 11.          0.69348379]. \t  -0.6076939108347638 \t -0.4983304913999733\n",
            "20     \t [ 6.39825002  5.88858918  9.          0.67432081 18.          0.813834  ]. \t  -0.5921986299757287 \t -0.4983304913999733\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.04081354533672"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJmI9saAaEG1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff227f10-803b-4507-fae2-a86b485bc565"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 5 \n",
        "\n",
        "np.random.seed(run_num_5)\n",
        "surrogate_exact_5 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train5, X_test5, y_train5, y_test5 = train_test_split(X, y, test_size=test_perc, random_state=run_num_5)\n",
        "\n",
        "def f_syn_polarity5(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_5, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train5, y=y_train5).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_5 = dGPGO(surrogate_exact_5, Acquisition_new(util_exact), f_syn_polarity5, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_5.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_5 = exact_5.getResult()[0]\n",
        "params_exact_5['max_depth'] = int(params_exact_5['max_depth'])\n",
        "params_exact_5['min_child_weight'] = int(params_exact_5['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train5 = xgb.DMatrix(X_train5, y_train5)\n",
        "dX_exact_test5 = xgb.DMatrix(X_test5, y_test5)\n",
        "model_exact_5 = xgb.train(params_exact_5, dX_exact_train5)\n",
        "pred_exact_5 = model_exact_5.predict(dX_exact_test5)\n",
        "\n",
        "rmse_exact_5 = np.sqrt(mean_squared_error(pred_exact_5, y_test5))\n",
        "rmse_exact_5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 2.21993171  8.70732306 11.          0.68186845 10.          0.53957007]. \t  -0.5323233521622429 \t -0.48683475961332984\n",
            "init   \t [ 6.11743863  7.65907856  5.          0.64840025 16.          0.82745351]. \t  -0.48683475961332984 \t -0.48683475961332984\n",
            "init   \t [ 6.49458883  8.19472793  6.          0.93996852 19.          0.36647194]. \t  -0.586475577548452 \t -0.48683475961332984\n",
            "init   \t [ 6.28787909  5.7983781   6.          0.63290956 17.          0.18402673]. \t  -0.633609225551848 \t -0.48683475961332984\n",
            "init   \t [8.26554249 8.33492742 9.         0.97900675 3.         0.26957319]. \t  -0.6326249738244012 \t -0.48683475961332984\n",
            "1      \t [1.95474956 1.21548467 5.         0.65548996 6.         0.3261206 ]. \t  -0.5882279171378358 \t -0.48683475961332984\n",
            "2      \t [ 7.93606002  2.5573513  12.          0.51144437  9.          0.97705142]. \t  \u001b[92m-0.45360464536197265\u001b[0m \t -0.45360464536197265\n",
            "3      \t [ 6.12310163  2.21013771 14.          0.74740665 18.          0.42989776]. \t  -0.5333068626906653 \t -0.45360464536197265\n",
            "4      \t [ 2.51924113  6.01871441 14.          0.73887463  3.          0.83338103]. \t  -0.46077122810557763 \t -0.45360464536197265\n",
            "5      \t [ 0.45511658  1.05531983  8.          0.5285983  14.          0.24399377]. \t  -0.6352890994881417 \t -0.45360464536197265\n",
            "6      \t [ 7.94120484  0.92506262 13.          0.63913817  1.          0.95746958]. \t  \u001b[92m-0.4436029998827319\u001b[0m \t -0.4436029998827319\n",
            "7      \t [ 3.55127355  9.21511435 13.          0.7432394  19.          0.48251811]. \t  -0.5307483586952177 \t -0.4436029998827319\n",
            "8      \t [9.06798103 6.21762396 5.         0.8435399  9.         0.45913475]. \t  -0.5618090677205061 \t -0.4436029998827319\n",
            "9      \t [ 7.68019847  0.14272251  5.          0.84271757 13.          0.46064437]. \t  -0.5609457236924665 \t -0.4436029998827319\n",
            "10     \t [1.24717977 9.40645683 5.         0.65383928 3.         0.68852908]. \t  -0.5172211356155465 \t -0.4436029998827319\n",
            "11     \t [ 9.92907009  9.56290601 12.          0.96474935 11.          0.11977881]. \t  -0.6320919733626622 \t -0.4436029998827319\n",
            "12     \t [9.35577232 0.06717833 6.         0.63643955 3.         0.33760798]. \t  -0.589017905989588 \t -0.4436029998827319\n",
            "13     \t [ 0.26037909  7.96430976  5.          0.57300432 18.          0.65170572]. \t  -0.517380641657496 \t -0.4436029998827319\n",
            "14     \t [ 1.42238814  0.69874859 12.          0.81050321  6.          0.18951707]. \t  -0.6356736669549067 \t -0.4436029998827319\n",
            "15     \t [2.03762865 4.34961943 8.         0.53797581 1.         0.36410352]. \t  -0.5730025877297991 \t -0.4436029998827319\n",
            "16     \t [ 0.20979055  3.48699735 13.          0.91075437 12.          0.42671314]. \t  -0.5627299932785415 \t -0.4436029998827319\n",
            "17     \t [ 2.57490322  0.33895391 10.          0.88927583 19.          0.31386234]. \t  -0.5608234896334385 \t -0.4436029998827319\n",
            "18     \t [ 9.2875561   9.15624524 13.          0.91867239 19.          0.68652241]. \t  -0.49408070326820824 \t -0.4436029998827319\n",
            "19     \t [ 0.31616346  9.22865905  5.          0.69019314 12.          0.52233884]. \t  -0.5624310412729423 \t -0.4436029998827319\n",
            "20     \t [ 9.94984248  2.37676311  9.          0.96621815 19.          0.48539202]. \t  -0.531856562647136 \t -0.4436029998827319\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.8115063045669055"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulhEolsxaG4k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3f65c69-4195-4295-a101-f3fb832e513c"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 6 \n",
        "\n",
        "np.random.seed(run_num_6)\n",
        "surrogate_exact_6 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train6, X_test6, y_train6, y_test6 = train_test_split(X, y, test_size=test_perc, random_state=run_num_6)\n",
        "\n",
        "def f_syn_polarity6(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=int(min_child_weight),\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_6, objective = 'reg:squarederror', eval_metric = 'rmse')\n",
        "    score = np.array(cross_val_score(reg, X=X_train6, y=y_train6).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_6 = dGPGO(surrogate_exact_6, Acquisition_new(util_exact), f_syn_polarity6, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_6.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_6 = exact_6.getResult()[0]\n",
        "params_exact_6['max_depth'] = int(params_exact_6['max_depth'])\n",
        "params_exact_6['min_child_weight'] = int(params_exact_6['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train6 = xgb.DMatrix(X_train6, y_train6)\n",
        "dX_exact_test6 = xgb.DMatrix(X_test6, y_test6)\n",
        "model_exact_6 = xgb.train(params_exact_6, dX_exact_train6)\n",
        "pred_exact_6 = model_exact_6.predict(dX_exact_test6)\n",
        "\n",
        "rmse_exact_6 = np.sqrt(mean_squared_error(pred_exact_6, y_test6))\n",
        "rmse_exact_6"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [8.92860151 3.31979805 5.         0.99251441 2.         0.57683563]. \t  -0.5719256944003751 \t -0.5405445954433028\n",
            "init   \t [4.18807429 3.35407849 9.         0.87750649 3.         0.56623277]. \t  -0.6047098118480896 \t -0.5405445954433028\n",
            "init   \t [ 5.788586    6.45355096 14.          0.70660047 12.          0.82154882]. \t  -0.5405445954433028 \t -0.5405445954433028\n",
            "init   \t [4.58184578 6.73834679 5.         0.90108528 3.         0.65482895]. \t  -0.5678490550489279 \t -0.5405445954433028\n",
            "init   \t [ 4.42510505  5.75952352 14.          0.97882365 15.          0.29525604]. \t  -0.6145131146454834 \t -0.5405445954433028\n",
            "1      \t [0.         0.         5.         0.5        9.28951254 0.1       ]. \t  -0.6934569463406091 \t -0.5405445954433028\n",
            "2      \t [ 9.24343066  2.50578958  7.          0.73023742 13.          0.6940436 ]. \t  -0.5767008292506094 \t -0.5405445954433028\n",
            "3      \t [8.18334854 9.97104849 8.         0.91869016 8.         0.37558961]. \t  -0.6144590591119746 \t -0.5405445954433028\n",
            "4      \t [ 8.54451719  6.55901746 13.          0.7507391   5.          0.45426156]. \t  -0.6083435565147685 \t -0.5405445954433028\n",
            "5      \t [ 1.35461816  3.68867636  7.          0.97358458 19.          0.99760691]. \t  \u001b[92m-0.4813823942223731\u001b[0m \t -0.4813823942223731\n",
            "6      \t [ 0.58299146  9.62458538  9.          0.94830232 11.          0.21492907]. \t  -0.6913953288776318 \t -0.4813823942223731\n",
            "7      \t [ 7.23238967  9.57077424  9.          0.98910406 19.          0.89873182]. \t  \u001b[92m-0.47582972183930894\u001b[0m \t -0.47582972183930894\n",
            "8      \t [ 9.32420466  6.39616005 13.          0.93300527 17.          0.34904443]. \t  -0.618513635024325 \t -0.47582972183930894\n",
            "9      \t [ 2.3330023   9.76264059 12.          0.88161689  4.          0.98638718]. \t  \u001b[92m-0.45728038685033284\u001b[0m \t -0.45728038685033284\n",
            "10     \t [ 6.80447195  6.69417926  5.          0.74586765 13.          0.74060763]. \t  -0.5548815051793727 \t -0.45728038685033284\n",
            "11     \t [ 0.56219975  9.42928268 11.          0.51903033 19.          0.52214278]. \t  -0.6178140448716308 \t -0.45728038685033284\n",
            "12     \t [ 2.15833867  2.09607443 11.          0.61964692  9.          0.5751364 ]. \t  -0.5749792197746819 \t -0.45728038685033284\n",
            "13     \t [ 5.43877488  0.17504551 13.          0.58721411 19.          0.60115325]. \t  -0.5742354992220393 \t -0.45728038685033284\n",
            "14     \t [0.  0.  5.  0.5 1.  0.1]. \t  -0.6973217959617746 \t -0.45728038685033284\n",
            "15     \t [ 7.781102    0.66670976 14.          0.78656914  6.          0.19023326]. \t  -0.6928429311509378 \t -0.45728038685033284\n",
            "16     \t [ 9.16380122  1.57669417  6.          0.94496183 19.          0.68061955]. \t  -0.5688115802929719 \t -0.45728038685033284\n",
            "17     \t [ 2.24051343  5.25045532  5.          0.81492378 10.          0.3308004 ]. \t  -0.6241963642158097 \t -0.45728038685033284\n",
            "18     \t [ 7.23381367  0.21465732 13.          0.75484136 13.          0.44717401]. \t  -0.6072661390452375 \t -0.45728038685033284\n",
            "19     \t [ 0.17525712  4.19183624 13.          0.93093846  1.          0.77496282]. \t  -0.537139253301325 \t -0.45728038685033284\n",
            "20     \t [ 1.53502905  8.80147943  5.          0.95765304 16.          0.87842144]. \t  -0.49016682016016233 \t -0.45728038685033284\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.571943125342289"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYebx3RVaJ1w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7109a0d8-64d9-4422-dd38-9919211eaa62"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 7 \n",
        "\n",
        "np.random.seed(run_num_7)\n",
        "surrogate_exact_7 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train7, X_test7, y_train7, y_test7 = train_test_split(X, y, test_size=test_perc, random_state=run_num_7)\n",
        "\n",
        "def f_syn_polarity7(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_7, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train7, y=y_train7).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_7 = dGPGO(surrogate_exact_7, Acquisition_new(util_exact), f_syn_polarity7, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_7.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_7 = exact_7.getResult()[0]\n",
        "params_exact_7['max_depth'] = int(params_exact_7['max_depth'])\n",
        "params_exact_7['min_child_weight'] = int(params_exact_7['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train7 = xgb.DMatrix(X_train7, y_train7)\n",
        "dX_exact_test7 = xgb.DMatrix(X_test7, y_test7)\n",
        "model_exact_7 = xgb.train(params_exact_7, dX_exact_train7)\n",
        "pred_exact_7 = model_exact_7.predict(dX_exact_test7)\n",
        "\n",
        "rmse_exact_7 = np.sqrt(mean_squared_error(pred_exact_7, y_test7))\n",
        "rmse_exact_7"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.76308289 7.79918792 8.         0.98911145 8.         0.98019056]. \t  -0.44500885348659536 \t -0.44173641078261416\n",
            "init   \t [ 5.3849587   5.01120464 13.          0.74994125  5.          0.88192131]. \t  -0.4488374676936292 \t -0.44173641078261416\n",
            "init   \t [ 3.30839249  3.9294231  12.          0.6440728  13.          0.41137564]. \t  -0.5669653799025498 \t -0.44173641078261416\n",
            "init   \t [9.29528191 2.6258377  5.         0.80027446 1.         0.86616513]. \t  -0.4661284696195417 \t -0.44173641078261416\n",
            "init   \t [ 1.74052764  7.90763512 14.          0.7244129   4.          0.77536887]. \t  -0.44173641078261416 \t -0.44173641078261416\n",
            "1      \t [3.43305102 3.00339076 8.         0.71322679 4.         0.33322219]. \t  -0.5720117286339644 \t -0.44173641078261416\n",
            "2      \t [ 6.11582972  9.74457247  9.          0.93736571 17.          0.66419177]. \t  -0.470247493642424 \t -0.44173641078261416\n",
            "3      \t [ 5.02225215  1.96894301  6.          0.89946836 15.          0.14043834]. \t  -0.681806668511342 \t -0.44173641078261416\n",
            "4      \t [ 8.68686713  7.27037095  5.          0.65538775 10.          0.84203491]. \t  -0.483133641434514 \t -0.44173641078261416\n",
            "5      \t [ 9.19325593  0.04766771 13.          0.95594397 16.          0.80133063]. \t  -0.45183470285935157 \t -0.44173641078261416\n",
            "6      \t [ 9.9951683   8.29291133 11.          0.98998997 12.          0.32159774]. \t  -0.5663372725560041 \t -0.44173641078261416\n",
            "7      \t [6.4915356  8.69600226 5.         0.66481282 2.         0.54976375]. \t  -0.5200045453863744 \t -0.44173641078261416\n",
            "8      \t [ 1.41319611  2.5751638  10.          0.98767908 19.          0.27216707]. \t  -0.6824540914353586 \t -0.44173641078261416\n",
            "9      \t [9.91546913 0.35662679 7.         0.87706909 8.         0.31009443]. \t  -0.5699297548076715 \t -0.44173641078261416\n",
            "10     \t [0.24073844 8.35501727 5.         0.58617015 2.         0.49753279]. \t  -0.5203386209868126 \t -0.44173641078261416\n",
            "11     \t [0.70289771 0.26831186 8.         0.54339287 9.         0.70811191]. \t  -0.4907315091597959 \t -0.44173641078261416\n",
            "12     \t [ 9.94824081  0.39149062 12.          0.59113076  1.          0.49709751]. \t  -0.5081268521688408 \t -0.44173641078261416\n",
            "13     \t [ 7.67822637  9.80667081 12.          0.90255729  1.          0.17725725]. \t  -0.6847107241961032 \t -0.44173641078261416\n",
            "14     \t [ 0.34344431  9.08335969 10.          0.76989135 16.          0.16354482]. \t  -0.6845756096348126 \t -0.44173641078261416\n",
            "15     \t [ 9.57070021  3.68128181  5.          0.59329325 19.          0.44442317]. \t  -0.5323526036989618 \t -0.44173641078261416\n",
            "16     \t [ 1.43297985  0.60163245 14.          0.83220406  8.          0.35678245]. \t  -0.565496037242404 \t -0.44173641078261416\n",
            "17     \t [ 9.45137179  0.74358028 14.          0.78939199  9.          0.47186777]. \t  -0.4954827567728435 \t -0.44173641078261416\n",
            "18     \t [ 2.47393117  8.12932833  5.          0.62482376 15.          0.55882726]. \t  -0.5316605334480753 \t -0.44173641078261416\n",
            "19     \t [ 9.66250325  8.26845592 14.          0.97780715 18.          0.16442988]. \t  -0.6821620347281179 \t -0.44173641078261416\n",
            "20     \t [8.53226416 4.72551917 6.         0.70114141 6.         0.95505376]. \t  -0.48241657779021835 \t -0.44173641078261416\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.499924380514474"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk0IPTSTbIl3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "548ecd6b-8a22-4bf2-fe8a-e5b2cfd62db5"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 8 \n",
        "\n",
        "np.random.seed(run_num_8)\n",
        "surrogate_exact_8 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train8, X_test8, y_train8, y_test8 = train_test_split(X, y, test_size=test_perc, random_state=run_num_8)\n",
        "\n",
        "def f_syn_polarity8(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_8, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train8, y=y_train8).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_8 = dGPGO(surrogate_exact_8, Acquisition_new(util_exact), f_syn_polarity8, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_8.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_8 = exact_8.getResult()[0]\n",
        "params_exact_8['max_depth'] = int(params_exact_8['max_depth'])\n",
        "params_exact_8['min_child_weight'] = int(params_exact_8['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train8 = xgb.DMatrix(X_train8, y_train8)\n",
        "dX_exact_test8 = xgb.DMatrix(X_test8, y_test8)\n",
        "model_exact_8 = xgb.train(params_exact_8, dX_exact_train8)\n",
        "pred_exact_8 = model_exact_8.predict(dX_exact_test8)\n",
        "\n",
        "rmse_exact_8 = np.sqrt(mean_squared_error(pred_exact_8, y_test8))\n",
        "rmse_exact_8"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 8.73429403  9.68540663 10.          0.68875849  9.          0.48011572]. \t  -0.5450023023990902 \t -0.47785117417083445\n",
            "init   \t [ 6.12033333  7.66062926  8.          0.76133734 13.          0.93379456]. \t  -0.48415390639601685 \t -0.47785117417083445\n",
            "init   \t [ 1.46524679  7.01527914  7.          0.90913299 10.          0.36016753]. \t  -0.5514374023096014 \t -0.47785117417083445\n",
            "init   \t [ 9.73855241  3.33774046 14.          0.53290419  7.          0.7088681 ]. \t  -0.509390123714371 \t -0.47785117417083445\n",
            "init   \t [ 3.00618018  1.82702795 11.          0.75681389 14.          0.98627449]. \t  -0.47785117417083445 \t -0.47785117417083445\n",
            "1      \t [4.42022545 5.48487111 9.         0.97165909 3.         0.63617522]. \t  -0.4933129789895931 \t -0.47785117417083445\n",
            "2      \t [ 2.28246361  4.04949256 14.          0.80786608  7.          0.81285698]. \t  \u001b[92m-0.4761088391590496\u001b[0m \t -0.4761088391590496\n",
            "3      \t [ 2.52429836  9.02824683 14.          0.59641093 17.          0.61934886]. \t  -0.5047477495526641 \t -0.4761088391590496\n",
            "4      \t [ 9.53473907  5.08424998 11.          0.50652828 18.          0.67121466]. \t  -0.5164144636241208 \t -0.4761088391590496\n",
            "5      \t [6.89072012 1.88822945 5.         0.9252956  8.         0.40577637]. \t  -0.5624845374478475 \t -0.4761088391590496\n",
            "6      \t [ 2.42575645  9.87357367  5.          0.61143882 19.          0.11833201]. \t  -0.6358778400175291 \t -0.4761088391590496\n",
            "7      \t [ 6.91772081  1.78286748  5.          0.91502226 18.          0.49192842]. \t  -0.5539976789608894 \t -0.4761088391590496\n",
            "8      \t [ 3.43855934  0.02041647 14.          0.50910442  1.          0.11324275]. \t  -0.6463022153645648 \t -0.4761088391590496\n",
            "9      \t [9.69554908 3.70013633 5.         0.72727157 1.         0.49530336]. \t  -0.5595421515943506 \t -0.4761088391590496\n",
            "10     \t [0.55400363 9.97465254 6.         0.64565646 3.         0.58326638]. \t  -0.5271698514354731 \t -0.4761088391590496\n",
            "11     \t [1.66316873 0.47469495 7.         0.60820298 1.         0.50689458]. \t  -0.5436576355709689 \t -0.4761088391590496\n",
            "12     \t [ 1.2277143   1.05411485  5.          0.50198686 13.          0.89258454]. \t  -0.5062409032591381 \t -0.4761088391590496\n",
            "13     \t [5.63420638 9.7026496  5.         0.64869539 8.         0.22475566]. \t  -0.6389332388103492 \t -0.4761088391590496\n",
            "14     \t [ 0.63194856  9.08760061 12.          0.51277257  1.          0.85579144]. \t  -0.4885511515989219 \t -0.4761088391590496\n",
            "15     \t [ 8.35277365  5.17929354 14.          0.67305838  1.          0.70101595]. \t  -0.5154357312421961 \t -0.4761088391590496\n",
            "16     \t [ 8.62413803  1.63568526 10.          0.78670071 12.          0.5099252 ]. \t  -0.5367709050823309 \t -0.4761088391590496\n",
            "17     \t [ 3.5121134   5.24088616  9.          0.68973249 19.          0.78159968]. \t  -0.4838024291467368 \t -0.4761088391590496\n",
            "18     \t [ 2.95370204  9.27299412 14.          0.7994754  10.          0.47804824]. \t  -0.5396535046523426 \t -0.4761088391590496\n",
            "19     \t [ 8.21638369  0.11131191 14.          0.86289711 17.          0.28011015]. \t  -0.6324732044366765 \t -0.4761088391590496\n",
            "20     \t [ 7.79664999  9.9555277   7.          0.88786243 19.          0.48083734]. \t  -0.5413755664817078 \t -0.4761088391590496\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.462721253378859"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UroEj_RbLSb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4b21083-603f-41f3-8bd4-077ee4a18399"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 9 \n",
        "\n",
        "np.random.seed(run_num_9)\n",
        "surrogate_exact_9 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train9, X_test9, y_train9, y_test9 = train_test_split(X, y, test_size=test_perc, random_state=run_num_9)\n",
        "\n",
        "def f_syn_polarity9(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_9, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train9, y=y_train9).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_9 = dGPGO(surrogate_exact_9, Acquisition_new(util_exact), f_syn_polarity9, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_9.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_9 = exact_9.getResult()[0]\n",
        "params_exact_9['max_depth'] = int(params_exact_9['max_depth'])\n",
        "params_exact_9['min_child_weight'] = int(params_exact_9['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train9 = xgb.DMatrix(X_train9, y_train9)\n",
        "dX_exact_test9 = xgb.DMatrix(X_test9, y_test9)\n",
        "model_exact_9 = xgb.train(params_exact_9, dX_exact_train9)\n",
        "pred_exact_9 = model_exact_9.predict(dX_exact_test9)\n",
        "\n",
        "rmse_exact_9 = np.sqrt(mean_squared_error(pred_exact_9, y_test9))\n",
        "rmse_exact_9"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 0.10374154  5.01874592 11.          0.50377155  2.          0.29670281]. \t  -0.6545930802207814 \t -0.4584168030068045\n",
            "init   \t [ 4.18508181  2.48101168 13.          0.69794293  2.          0.25009871]. \t  -0.7166132091943936 \t -0.4584168030068045\n",
            "init   \t [ 8.78559086  9.50964032 13.          0.98395204 11.          0.90820641]. \t  -0.4584168030068045 \t -0.4584168030068045\n",
            "init   \t [ 6.66898973  5.47837783  6.          0.97165345 12.          0.72499481]. \t  -0.48839211091816903 \t -0.4584168030068045\n",
            "init   \t [ 8.24870465  4.65668475 13.          0.68760467  9.          0.98502332]. \t  -0.46354466019784824 \t -0.4584168030068045\n",
            "1      \t [6.73714319 2.39608167 5.         0.58130302 3.         0.163077  ]. \t  -0.7145926373770018 \t -0.4584168030068045\n",
            "2      \t [ 4.24955662  9.67331527 12.          0.64012695  7.          0.96617478]. \t  -0.4599552738922936 \t -0.4584168030068045\n",
            "3      \t [ 3.60566534  9.79805332 11.          0.62032576 16.          0.3578496 ]. \t  -0.6301914521165797 \t -0.4584168030068045\n",
            "4      \t [ 4.86601509  0.61279594  8.          0.72162785 18.          0.68911833]. \t  -0.4897803511428914 \t -0.4584168030068045\n",
            "5      \t [1.01192549e-02 2.87791832e+00 1.30000000e+01 5.02360812e-01\n",
            " 1.60000000e+01 5.53454779e-01]. \t  -0.4943219873025823 \t -0.4584168030068045\n",
            "6      \t [1.13863488 5.86180669 5.         0.9953054  3.         0.88639082]. \t  -0.4613511892865009 \t -0.4584168030068045\n",
            "7      \t [9.20185355 9.40235017 8.         0.60433558 1.         0.94540222]. \t  -0.4678077722812364 \t -0.4584168030068045\n",
            "8      \t [ 7.07313313  8.94084339  5.          0.99439529 19.          0.33798274]. \t  -0.6320298567588886 \t -0.4584168030068045\n",
            "9      \t [9.55073356 0.68128714 7.         0.82844939 9.         0.80267865]. \t  -0.4865447931894753 \t -0.4584168030068045\n",
            "10     \t [ 1.48405781  3.2282945  12.          0.72755713  8.          0.45582302]. \t  -0.4796592938464645 \t -0.4584168030068045\n",
            "11     \t [ 8.41810681  0.28363289 14.          0.70665052 14.          0.98883394]. \t  -0.47311243562864586 \t -0.4584168030068045\n",
            "12     \t [0.         0.         5.         0.5        6.21322258 0.1       ]. \t  -0.7197162056195492 \t -0.4584168030068045\n",
            "13     \t [ 8.8503125   5.34876568 11.          0.94536212 19.          0.39914726]. \t  -0.6253125328412295 \t -0.4584168030068045\n",
            "14     \t [ 1.5822225   4.71560548  5.          0.51218922 16.          0.7972216 ]. \t  -0.509323444922597 \t -0.4584168030068045\n",
            "15     \t [4.62485155 9.65182222 5.         0.58896427 8.         0.36022331]. \t  -0.6322698857670199 \t -0.4584168030068045\n",
            "16     \t [ 8.77945628  5.51694736 12.          0.84613589  4.          0.64741755]. \t  -0.4798840189273464 \t -0.4584168030068045\n",
            "17     \t [ 3.89448326  9.77793126 11.          0.87312755  1.          0.25420157]. \t  -0.7204829959803113 \t -0.4584168030068045\n",
            "18     \t [ 4.36796248  0.46487554  9.          0.72990768 12.          0.19754102]. \t  -0.7169238992129088 \t -0.4584168030068045\n",
            "19     \t [ 2.87706677  6.16957719 14.          0.55246385 12.          0.92866915]. \t  -0.4653617556003965 \t -0.4584168030068045\n",
            "20     \t [ 1.87277969  9.36196526  9.          0.51233211 11.          0.1932108 ]. \t  -0.7194546023699788 \t -0.4584168030068045\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.6575353004618085"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VgaJOoJbOIE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f6cde26-7f56-433a-f114-d6f6da26c566"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 10 \n",
        "\n",
        "np.random.seed(run_num_10)\n",
        "surrogate_exact_10 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train10, X_test10, y_train10, y_test10 = train_test_split(X, y, test_size=test_perc, random_state=run_num_10)\n",
        "\n",
        "def f_syn_polarity10(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_10, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train10, y=y_train10).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_10 = dGPGO(surrogate_exact_10, Acquisition_new(util_exact), f_syn_polarity10, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_10.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_10 = exact_10.getResult()[0]\n",
        "params_exact_10['max_depth'] = int(params_exact_10['max_depth'])\n",
        "params_exact_10['min_child_weight'] = int(params_exact_10['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train10 = xgb.DMatrix(X_train10, y_train10)\n",
        "dX_exact_test10 = xgb.DMatrix(X_test10, y_test10)\n",
        "model_exact_10 = xgb.train(params_exact_10, dX_exact_train10)\n",
        "pred_exact_10 = model_exact_10.predict(dX_exact_test10)\n",
        "\n",
        "rmse_exact_10 = np.sqrt(mean_squared_error(pred_exact_10, y_test10))\n",
        "rmse_exact_10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 7.71320643  0.20751949  5.          0.72150747 17.          0.12265456]. \t  -0.7090674967614334 \t -0.4737745634473992\n",
            "init   \t [ 7.0920801   2.65566127 13.          0.57518893 17.          0.83494165]. \t  -0.4737745634473992 \t -0.4737745634473992\n",
            "init   \t [ 3.36071584  8.90816531  6.          0.86087766 15.          0.75469196]. \t  -0.4755277191484213 \t -0.4737745634473992\n",
            "init   \t [ 5.40880931  1.31458152  8.          0.57108502 14.          0.62551123]. \t  -0.48811859212530173 \t -0.4737745634473992\n",
            "init   \t [1.82631436 8.26082248 6.         0.80888349 5.         0.15900694]. \t  -0.7057210222477256 \t -0.4737745634473992\n",
            "1      \t [8.31989768 3.09778055 7.         0.64798085 3.         0.98471878]. \t  \u001b[92m-0.46336171949490257\u001b[0m \t -0.46336171949490257\n",
            "2      \t [ 1.51483713  6.46720195 14.          0.87676044  8.          0.10934204]. \t  -0.7062921047588426 \t -0.46336171949490257\n",
            "3      \t [ 1.40638864  6.36994003 14.          0.94554832 18.          0.42624162]. \t  -0.6046476616239911 \t -0.46336171949490257\n",
            "4      \t [ 6.23532773  8.31439809 13.          0.65134225  1.          0.75774237]. \t  \u001b[92m-0.4627563233127832\u001b[0m \t -0.4627563233127832\n",
            "5      \t [ 9.32103763  8.04997374 14.          0.76165598 11.          0.58576369]. \t  -0.4786871541296465 \t -0.4627563233127832\n",
            "6      \t [ 2.70513667  1.83577987 12.          0.56122064  1.          0.15848231]. \t  -0.7152283108383268 \t -0.4627563233127832\n",
            "7      \t [ 9.16520307  0.72602801 12.          0.91999471  9.          0.54336218]. \t  -0.5572402945816037 \t -0.4627563233127832\n",
            "8      \t [ 0.13114685  2.69967978  5.          0.89490476 19.          0.55706236]. \t  -0.5697953373163872 \t -0.4627563233127832\n",
            "9      \t [ 9.57603828  8.81375557  5.          0.56495862 19.          0.45710368]. \t  -0.5855932574449119 \t -0.4627563233127832\n",
            "10     \t [0.         1.09967587 5.         0.5        9.58020938 0.1       ]. \t  -0.7112992185914038 \t -0.4627563233127832\n",
            "11     \t [0.40833691 2.05040396 5.         0.83675528 2.         0.93839002]. \t  \u001b[92m-0.45672281191304187\u001b[0m \t -0.45672281191304187\n",
            "12     \t [ 0.06083858  0.83347778 13.          0.60208867 14.          0.81102115]. \t  \u001b[92m-0.4556981011772255\u001b[0m \t -0.4556981011772255\n",
            "13     \t [6.98730996 4.97466872 6.         0.84829188 9.         0.46079499]. \t  -0.5691198681605976 \t -0.4556981011772255\n",
            "14     \t [ 0.42759101  9.94526216 13.          0.83538077 13.          0.34479326]. \t  -0.6094679703467385 \t -0.4556981011772255\n",
            "15     \t [9.80244061 9.59221257 6.         0.81318958 4.         0.96637387]. \t  -0.4586700434144483 \t -0.4556981011772255\n",
            "16     \t [3.30594456 0.27909177 9.         0.73871386 6.         0.22083085]. \t  -0.7093772539407449 \t -0.4556981011772255\n",
            "17     \t [ 9.71047899  2.77697649 13.          0.98225484  2.          0.32725448]. \t  -0.6105934635470132 \t -0.4556981011772255\n",
            "18     \t [ 3.45239739  3.71668204  9.          0.77283325 19.          0.7941719 ]. \t  -0.46194519954869123 \t -0.4556981011772255\n",
            "19     \t [ 8.10151611  9.78827602 14.          0.68048433 19.          0.19392154]. \t  -0.7116333725331636 \t -0.4556981011772255\n",
            "20     \t [ 9.10340821  9.56875896  8.          0.96862007 13.          0.97727525]. \t  \u001b[92m-0.4511391281751472\u001b[0m \t -0.4511391281751472\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.142778903321004"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51z87uHWbRGr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "758b1bcb-c3a8-4f00-9a36-3dadbab94be7"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 11 \n",
        "\n",
        "np.random.seed(run_num_11)\n",
        "surrogate_exact_11 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train11, X_test11, y_train11, y_test11 = train_test_split(X, y, test_size=test_perc, random_state=run_num_11)\n",
        "\n",
        "def f_syn_polarity11(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_11, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train11, y=y_train11).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_11 = dGPGO(surrogate_exact_11, Acquisition_new(util_exact), f_syn_polarity11, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_11.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_11 = exact_11.getResult()[0]\n",
        "params_exact_11['max_depth'] = int(params_exact_11['max_depth'])\n",
        "params_exact_11['min_child_weight'] = int(params_exact_11['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train11 = xgb.DMatrix(X_train11, y_train11)\n",
        "dX_exact_test11 = xgb.DMatrix(X_test11, y_test11)\n",
        "model_exact_11 = xgb.train(params_exact_11, dX_exact_train11)\n",
        "pred_exact_11 = model_exact_11.predict(dX_exact_test11)\n",
        "\n",
        "rmse_exact_11 = np.sqrt(mean_squared_error(pred_exact_11, y_test11))\n",
        "rmse_exact_11"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 1.80269689  0.19475241  6.          0.59705781 13.          0.47818324]. \t  -0.5922349044250168 \t -0.49898623219170346\n",
            "init   \t [ 4.85427098  0.12780815  5.          0.91309068 14.          0.86571558]. \t  -0.49898623219170346 \t -0.49898623219170346\n",
            "init   \t [ 7.2996447   1.08736072 10.          0.92857712 18.          0.66910061]. \t  -0.5404544349803458 \t -0.49898623219170346\n",
            "init   \t [ 0.20483613  1.16737269  7.          0.57895615 16.          0.83644782]. \t  -0.5108833748715963 \t -0.49898623219170346\n",
            "init   \t [ 3.44624491  3.18798797 14.          0.54197657 15.          0.63958906]. \t  -0.5545314939891337 \t -0.49898623219170346\n",
            "1      \t [ 3.00661074  5.9321586  13.          0.93375268  7.          0.32533139]. \t  -0.5712265807436425 \t -0.49898623219170346\n",
            "2      \t [7.20868744 6.83428849 8.         0.68837575 6.         0.28591593]. \t  -0.5833992322133288 \t -0.49898623219170346\n",
            "3      \t [ 4.28856064  9.51262941  9.          0.76647308 19.          0.1192808 ]. \t  -0.6869531822881431 \t -0.49898623219170346\n",
            "4      \t [0.  0.  5.  0.5 1.  0.1]. \t  -0.6979829745079476 \t -0.49898623219170346\n",
            "5      \t [ 6.44177252  1.37885806 12.          0.74571582  1.          0.110379  ]. \t  -0.6916013861614152 \t -0.49898623219170346\n",
            "6      \t [ 8.80621297  1.41648139 14.          0.58742169  8.          0.82618778]. \t  -0.5033855071125977 \t -0.49898623219170346\n",
            "7      \t [0.56806539 7.69746805 6.         0.94796222 9.         0.37129588]. \t  -0.5901121363604664 \t -0.49898623219170346\n",
            "8      \t [0.47065357 6.80536856 5.         0.94482943 1.         0.93677618]. \t  -0.5032158363867651 \t -0.49898623219170346\n",
            "9      \t [ 5.5178254   9.65002018 13.          0.7661485  13.          0.91577641]. \t  \u001b[92m-0.4724354491680155\u001b[0m \t -0.4724354491680155\n",
            "10     \t [ 9.62795963  5.53773092  5.          0.74613073 18.          0.44845649]. \t  -0.6039998092641087 \t -0.4724354491680155\n",
            "11     \t [ 8.61765552  0.94349031 10.          0.85641829  4.          0.91576259]. \t  -0.478802422007202 \t -0.4724354491680155\n",
            "12     \t [9.1689709  8.67069462 6.         0.8799734  8.         0.25184132]. \t  -0.6877875402485593 \t -0.4724354491680155\n",
            "13     \t [ 0.25928331  1.26365177 10.          0.55099024  5.          0.58845859]. \t  -0.5533357663281473 \t -0.4724354491680155\n",
            "14     \t [ 8.40730244  5.3235921  14.          0.57824885  9.          0.96689527]. \t  -0.48694111460803785 \t -0.4724354491680155\n",
            "15     \t [ 8.27597005  9.04237822 13.          0.54506528  3.          0.15059174]. \t  -0.6967640241521383 \t -0.4724354491680155\n",
            "16     \t [ 9.7602473   8.08368399 12.          0.65958526 18.          0.9544452 ]. \t  -0.4831334802506264 \t -0.4724354491680155\n",
            "17     \t [9.96111126 6.75429616 8.         0.78500956 1.         0.98009511]. \t  -0.48688631093442664 \t -0.4724354491680155\n",
            "18     \t [5.61170222 0.67547973 9.         0.79238564 3.         0.84547685]. \t  -0.4879562724289731 \t -0.4724354491680155\n",
            "19     \t [ 0.03452186  8.83860607 13.          0.62313645 17.          0.60519619]. \t  -0.5509245043497702 \t -0.4724354491680155\n",
            "20     \t [ 9.73835913  1.55882873  8.          0.78667186 10.          0.52052364]. \t  -0.5838416310099452 \t -0.4724354491680155\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.794073214993642"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8jZUeoWbTvn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d98b96c-0e6f-47dc-de80-38fe078ba967"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 12\n",
        "\n",
        "np.random.seed(run_num_12)\n",
        "surrogate_exact_12 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train12, X_test12, y_train12, y_test12 = train_test_split(X, y, test_size=test_perc, random_state=run_num_12)\n",
        "\n",
        "def f_syn_polarity12(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_12, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train12, y=y_train12).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_12 = dGPGO(surrogate_exact_12, Acquisition_new(util_exact), f_syn_polarity12, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_12.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_12 = exact_12.getResult()[0]\n",
        "params_exact_12['max_depth'] = int(params_exact_12['max_depth'])\n",
        "params_exact_12['min_child_weight'] = int(params_exact_12['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train12 = xgb.DMatrix(X_train12, y_train12)\n",
        "dX_exact_test12 = xgb.DMatrix(X_test12, y_test12)\n",
        "model_exact_12 = xgb.train(params_exact_12, dX_exact_train12)\n",
        "pred_exact_12 = model_exact_12.predict(dX_exact_test12)\n",
        "\n",
        "rmse_exact_12 = np.sqrt(mean_squared_error(pred_exact_12, y_test12))\n",
        "rmse_exact_12"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [1.54162842 7.40049697 6.         0.54321714 4.         0.11311747]. \t  -0.6840535846029854 \t -0.5032799564384677\n",
            "init   \t [ 9.18747008  9.00714854 14.          0.97847467 11.          0.35544552]. \t  -0.6305456734924068 \t -0.5032799564384677\n",
            "init   \t [ 6.06083184  9.44225136 14.          0.95626942  5.          0.56910342]. \t  -0.6144010633484512 \t -0.5032799564384677\n",
            "init   \t [ 5.52037633  4.85377414  7.          0.97886436 17.          0.78810441]. \t  -0.5032799564384677 \t -0.5032799564384677\n",
            "init   \t [ 0.20809798  1.35210178  5.          0.65494879 16.          0.36062811]. \t  -0.6516977337723864 \t -0.5032799564384677\n",
            "1      \t [9.46555822 8.57190559 5.         0.50164398 5.         0.71992807]. \t  -0.5227768283895782 \t -0.5032799564384677\n",
            "2      \t [9.04256367 2.61736915 8.         0.66026854 8.         0.14510453]. \t  -0.6776847411315782 \t -0.5032799564384677\n",
            "3      \t [ 5.00829307  3.38593972 11.          0.93206268  3.          0.37397626]. \t  -0.633394524427203 \t -0.5032799564384677\n",
            "4      \t [ 0.24796255  2.18203944 14.          0.56497025 17.          0.63132662]. \t  -0.5478949507371567 \t -0.5032799564384677\n",
            "5      \t [ 1.93384153  7.13950146  8.          0.85480597 18.          0.33734734]. \t  -0.6432864186552534 \t -0.5032799564384677\n",
            "6      \t [ 0.40359854  2.22527636 10.          0.60258213 10.          0.38255809]. \t  -0.6389275427144069 \t -0.5032799564384677\n",
            "7      \t [ 2.74186895  8.07635126 13.          0.52228241 13.          0.8380668 ]. \t  \u001b[92m-0.49886123934683424\u001b[0m \t -0.49886123934683424\n",
            "8      \t [ 7.63658847  0.39719075 14.          0.96199388 14.          0.84093877]. \t  \u001b[92m-0.48258324270646796\u001b[0m \t -0.48258324270646796\n",
            "9      \t [0.31974577 0.28426423 5.         0.59429506 1.         0.19680364]. \t  -0.6807903714596163 \t -0.48258324270646796\n",
            "10     \t [ 4.27921374  9.2199845   6.          0.67076861 12.          0.56605459]. \t  -0.628155564863435 \t -0.48258324270646796\n",
            "11     \t [7.8127487  4.2013177  5.         0.76692189 1.         0.91258108]. \t  -0.4948056803943882 \t -0.48258324270646796\n",
            "12     \t [ 9.06259994  1.4172751   5.          0.81347212 19.          0.38881712]. \t  -0.650363142837499 \t -0.48258324270646796\n",
            "13     \t [ 9.38461996  5.62749581 12.          0.98689844 17.          0.89710846]. \t  \u001b[92m-0.4762695359794075\u001b[0m \t -0.4762695359794075\n",
            "14     \t [ 4.55964005  0.30434123  5.          0.52399968 11.          0.14256504]. \t  -0.6841482061412913 \t -0.4762695359794075\n",
            "15     \t [ 6.59943135  1.71178305 14.          0.69283152  8.          0.30459736]. \t  -0.635622313137239 \t -0.4762695359794075\n",
            "16     \t [4.73437062 4.4400116  6.         0.99309254 5.         0.34740604]. \t  -0.6465725592964799 \t -0.4762695359794075\n",
            "17     \t [ 0.96920037  6.62909386 14.          0.51410819  2.          0.40605393]. \t  -0.6487406723348934 \t -0.4762695359794075\n",
            "18     \t [ 9.28353185  7.64677585 13.          0.64776953  1.          0.57523721]. \t  -0.5447026279210141 \t -0.4762695359794075\n",
            "19     \t [ 0.74125723  1.19413421 14.          0.98017931  5.          0.4597857 ]. \t  -0.6211022196287329 \t -0.4762695359794075\n",
            "20     \t [ 9.66945773  0.96666963 10.          0.70845514  1.          0.55906204]. \t  -0.6210781177251955 \t -0.4762695359794075\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.772452859101784"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snTrqE2RbWbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7840b94-c855-4a55-acdb-2b94f66b0099"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 13 \n",
        "\n",
        "np.random.seed(run_num_13)\n",
        "surrogate_exact_13 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train13, X_test13, y_train13, y_test13 = train_test_split(X, y, test_size=test_perc, random_state=run_num_13)\n",
        "\n",
        "def f_syn_polarity13(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_13, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train13, y=y_train13).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_13 = dGPGO(surrogate_exact_13, Acquisition_new(util_exact), f_syn_polarity13, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_13.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_13 = exact_13.getResult()[0]\n",
        "params_exact_13['max_depth'] = int(params_exact_13['max_depth'])\n",
        "params_exact_13['min_child_weight'] = int(params_exact_13['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train13 = xgb.DMatrix(X_train13, y_train13)\n",
        "dX_exact_test13 = xgb.DMatrix(X_test13, y_test13)\n",
        "model_exact_13 = xgb.train(params_exact_13, dX_exact_train13)\n",
        "pred_exact_13 = model_exact_13.predict(dX_exact_test13)\n",
        "\n",
        "rmse_exact_13 = np.sqrt(mean_squared_error(pred_exact_13, y_test13))\n",
        "rmse_exact_13"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 7.77702411  2.3754122  11.          0.94649135 13.          0.7827256 ]. \t  -0.5099204187421568 \t -0.5099204187421568\n",
            "init   \t [ 7.51661514  6.07343344 11.          0.69402149 11.          0.13153287]. \t  -0.7086153631136594 \t -0.5099204187421568\n",
            "init   \t [ 2.98449471  0.58512492 10.          0.73579614 12.          0.33065195]. \t  -0.6372461781857162 \t -0.5099204187421568\n",
            "init   \t [ 3.47581215  0.0941277  11.          0.86143432  8.          0.58454932]. \t  -0.5702017504451442 \t -0.5099204187421568\n",
            "init   \t [ 4.70137857  6.24432527 10.          0.8149145  18.          0.10784416]. \t  -0.7101125715665313 \t -0.5099204187421568\n",
            "1      \t [1.1119361  5.43221306 6.         0.56899303 8.         0.32100319]. \t  -0.6493427493033831 \t -0.5099204187421568\n",
            "2      \t [5.39023698 3.80105709 8.         0.54170057 1.         0.56798884]. \t  -0.621866591058205 \t -0.5099204187421568\n",
            "3      \t [ 0.5185863   5.23876151 13.          0.63798348  5.          0.7914799 ]. \t  \u001b[92m-0.5090480969691882\u001b[0m \t -0.5090480969691882\n",
            "4      \t [ 9.65518672  0.13040633  6.          0.63296628 18.          0.44133279]. \t  -0.632314879589983 \t -0.5090480969691882\n",
            "5      \t [ 9.80722669  7.22571611  7.          0.5026908  19.          0.92519376]. \t  -0.5113851690128051 \t -0.5090480969691882\n",
            "6      \t [ 6.75965929  9.42320667 14.          0.75932127  4.          0.51195623]. \t  -0.6206028595311828 \t -0.5090480969691882\n",
            "7      \t [9.95671825 0.88335607 5.         0.76593799 7.         0.60049246]. \t  -0.5952873237754599 \t -0.5090480969691882\n",
            "8      \t [ 1.88898055  9.92199995 14.          0.53783103 12.          0.63359705]. \t  -0.5738907345204808 \t -0.5090480969691882\n",
            "9      \t [0.32121091 9.03384774 6.         0.79493663 1.         0.29330571]. \t  -0.6544818879601484 \t -0.5090480969691882\n",
            "10     \t [ 9.64211232  3.05396831 11.          0.80784352  5.          0.67910498]. \t  -0.5747201434527256 \t -0.5090480969691882\n",
            "11     \t [ 1.60018805  0.54211528  7.          0.80910607 18.          0.55232873]. \t  -0.6209454018308087 \t -0.5090480969691882\n",
            "12     \t [ 6.1829314   9.53799326  5.          0.66916589 13.          0.57013155]. \t  -0.6295351865431291 \t -0.5090480969691882\n",
            "13     \t [7.99022981 8.23715587 5.         0.79172469 5.         0.39852784]. \t  -0.6543343020941466 \t -0.5090480969691882\n",
            "14     \t [ 8.15066897  1.98276445 13.          0.64083395 19.          0.16153982]. \t  -0.7124294948180114 \t -0.5090480969691882\n",
            "15     \t [ 2.48128047  9.70146472  6.          0.59664322 19.          0.9781653 ]. \t  -0.5140838980696801 \t -0.5090480969691882\n",
            "16     \t [ 9.08793394  9.83715934 14.          0.60607659 14.          0.5136415 ]. \t  -0.6216172534981154 \t -0.5090480969691882\n",
            "17     \t [ 1.80857777  4.26197    14.          0.84061579 16.          0.40224246]. \t  -0.637460469665298 \t -0.5090480969691882\n",
            "18     \t [ 5.1333583   3.10658752 14.          0.74854361  1.          0.92539511]. \t  \u001b[92m-0.4793091157473782\u001b[0m \t -0.4793091157473782\n",
            "19     \t [ 0.65009462  9.91088996 13.          0.92448902  2.          0.37838494]. \t  -0.6501362550952002 \t -0.4793091157473782\n",
            "20     \t [0.         0.         5.         0.5        5.17679633 0.1       ]. \t  -0.7092277536421888 \t -0.4793091157473782\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.601162573826364"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAuEsXYbtOnC",
        "outputId": "e43c973d-34db-48e6-e13b-bf181f3ce280"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 14 \n",
        "\n",
        "np.random.seed(run_num_14)\n",
        "surrogate_exact_14 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train14, X_test14, y_train14, y_test14 = train_test_split(X, y, test_size=test_perc, random_state=run_num_14)\n",
        "\n",
        "def f_syn_polarity14(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_14, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train14, y=y_train14).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_14 = dGPGO(surrogate_exact_14, Acquisition_new(util_exact), f_syn_polarity14, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_14.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_14 = exact_14.getResult()[0]\n",
        "params_exact_14['max_depth'] = int(params_exact_14['max_depth'])\n",
        "params_exact_14['min_child_weight'] = int(params_exact_14['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train14 = xgb.DMatrix(X_train14, y_train14)\n",
        "dX_exact_test14 = xgb.DMatrix(X_test14, y_test14)\n",
        "model_exact_14 = xgb.train(params_exact_14, dX_exact_train14)\n",
        "pred_exact_14 = model_exact_14.predict(dX_exact_test14)\n",
        "\n",
        "rmse_exact_14 = np.sqrt(mean_squared_error(pred_exact_14, y_test14))\n",
        "rmse_exact_14"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 5.13943344  7.73165052 12.          0.6831412  11.          0.37876233]. \t  -0.558794499921046 \t -0.4448140077853998\n",
            "init   \t [ 9.57603739  5.13116712 14.          0.76959997 12.          0.71328228]. \t  -0.49979629433789113 \t -0.4448140077853998\n",
            "init   \t [5.34950319 2.47493539 5.         0.50293689 6.         0.29706373]. \t  -0.5741697988899073 \t -0.4448140077853998\n",
            "init   \t [ 2.94506579  3.45329697  8.          0.87620946 14.          0.9783044 ]. \t  -0.4448140077853998 \t -0.4448140077853998\n",
            "init   \t [ 1.11811929  1.73004086  5.          0.73745288 12.          0.20586008]. \t  -0.6214151152359092 \t -0.4448140077853998\n",
            "1      \t [ 6.50637223  2.67617722 14.          0.53562507  1.          0.16862152]. \t  -0.6294794339238933 \t -0.4448140077853998\n",
            "2      \t [ 9.97732733  0.9008687  13.          0.65397817 19.          0.96533011]. \t  -0.46274298441446626 \t -0.4448140077853998\n",
            "3      \t [ 6.6877751   9.48200682  5.          0.90861826 11.          0.9411861 ]. \t  -0.4578630344523679 \t -0.4448140077853998\n",
            "4      \t [9.32373648 9.05676215 9.         0.53064322 3.         0.70657534]. \t  -0.5066999638361388 \t -0.4448140077853998\n",
            "5      \t [ 1.03495546  6.36597852 14.          0.95388015  5.          0.12529639]. \t  -0.6235755319012176 \t -0.4448140077853998\n",
            "6      \t [1.11245291 7.32536364 9.         0.80287741 8.         0.8335634 ]. \t  -0.4719553230676576 \t -0.4448140077853998\n",
            "7      \t [ 0.9687803   2.15143442 14.          0.51651811 18.          0.56051657]. \t  -0.5069463513331254 \t -0.4448140077853998\n",
            "8      \t [ 5.82553366  9.44318255  6.          0.63592424 19.          0.54190567]. \t  -0.5148607213430376 \t -0.4448140077853998\n",
            "9      \t [ 8.97462379  3.07976653  6.          0.89115666 18.          0.90399549]. \t  -0.46259647676184984 \t -0.4448140077853998\n",
            "10     \t [ 2.08494663  9.70581169 14.          0.64307382  3.          0.10613693]. \t  -0.6314279131128486 \t -0.4448140077853998\n",
            "11     \t [ 8.75151385  7.75347333 14.          0.98873367 11.          0.55773854]. \t  -0.4966381629863901 \t -0.4448140077853998\n",
            "12     \t [ 5.13735441  7.34260278 13.          0.50594951 19.          0.81583776]. \t  -0.49627903196985884 \t -0.4448140077853998\n",
            "13     \t [0.  0.  5.  0.5 1.  0.1]. \t  -0.6278549001305299 \t -0.4448140077853998\n",
            "14     \t [3.93459841 8.46767954 5.         0.86837551 3.         0.67826473]. \t  -0.5009962598057055 \t -0.4448140077853998\n",
            "15     \t [ 0.4418527   4.49961454  5.          0.81022894 19.          0.68885116]. \t  -0.5043665497579306 \t -0.4448140077853998\n",
            "16     \t [ 2.37733654  0.06526826 14.          0.97689212  7.          0.3543897 ]. \t  -0.5458929603671377 \t -0.4448140077853998\n",
            "17     \t [ 9.64196863  0.25770476  7.          0.95281681 11.          0.28516842]. \t  -0.6210154002708375 \t -0.4448140077853998\n",
            "18     \t [9.95902868 1.23916696 7.         0.60336262 2.         0.41962125]. \t  -0.5646831606854809 \t -0.4448140077853998\n",
            "19     \t [0.88193847 5.43558093 9.         0.70213239 1.         0.9736566 ]. \t  -0.44943887067929394 \t -0.4448140077853998\n",
            "20     \t [ 8.21075716  2.88666417 12.          0.5197222   7.          0.73645545]. \t  -0.49237459018292923 \t -0.4448140077853998\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.080359514778575"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgxvE7Irbbj_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db039654-edd6-4cc6-832b-4adce5a2e385"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 15 \n",
        "\n",
        "np.random.seed(run_num_15)\n",
        "surrogate_exact_15 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train15, X_test15, y_train15, y_test15 = train_test_split(X, y, test_size=test_perc, random_state=run_num_15)\n",
        "\n",
        "def f_syn_polarity15(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_15, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train15, y=y_train15).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_15 = dGPGO(surrogate_exact_15, Acquisition_new(util_exact), f_syn_polarity15, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_15.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_15 = exact_15.getResult()[0]\n",
        "params_exact_15['max_depth'] = int(params_exact_15['max_depth'])\n",
        "params_exact_15['min_child_weight'] = int(params_exact_15['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train15 = xgb.DMatrix(X_train15, y_train15)\n",
        "dX_exact_test15 = xgb.DMatrix(X_test15, y_test15)\n",
        "model_exact_15 = xgb.train(params_exact_15, dX_exact_train15)\n",
        "pred_exact_15 = model_exact_15.predict(dX_exact_test15)\n",
        "\n",
        "rmse_exact_15 = np.sqrt(mean_squared_error(pred_exact_15, y_test15))\n",
        "rmse_exact_15"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 8.48817697  1.78895925 12.          0.55549316  8.          0.93397854]. \t  -0.48943791400638287 \t -0.48943791400638287\n",
            "init   \t [ 0.24953032  8.22298097 12.          0.62494951 11.          0.12924598]. \t  -0.6992441679399787 \t -0.48943791400638287\n",
            "init   \t [ 5.02017228  5.50882771 11.          0.85295832 19.          0.13548008]. \t  -0.69945028775584 \t -0.48943791400638287\n",
            "init   \t [2.0023081  9.98543403 7.         0.6295772  2.         0.526127  ]. \t  -0.6264981748624211 \t -0.48943791400638287\n",
            "init   \t [ 5.09715306  9.45038417 11.          0.7388277  16.          0.22739973]. \t  -0.6964615643692806 \t -0.48943791400638287\n",
            "1      \t [ 0.29158961  4.9949242  12.          0.89124583  3.          0.67554049]. \t  -0.56524595824364 \t -0.48943791400638287\n",
            "2      \t [3.68214008 4.55748717 6.         0.60488381 8.         0.88973248]. \t  -0.494310985641296 \t -0.48943791400638287\n",
            "3      \t [9.75991344 6.15203198 6.         0.65490407 1.         0.73816291]. \t  -0.49903240523735964 \t -0.48943791400638287\n",
            "4      \t [ 9.51793103  9.55070381  6.          0.93315157 11.          0.40416985]. \t  -0.688799230055169 \t -0.48943791400638287\n",
            "5      \t [ 6.65116837  8.16324548 14.          0.95750787  1.          0.74925927]. \t  \u001b[92m-0.4743330993644729\u001b[0m \t -0.4743330993644729\n",
            "6      \t [ 0.41861043  0.05076637  5.          0.78940316 12.          0.77619725]. \t  -0.5149313800202362 \t -0.4743330993644729\n",
            "7      \t [ 0.44758083  1.21361479 14.          0.72053858 16.          0.73785377]. \t  -0.48610261627787 \t -0.4743330993644729\n",
            "8      \t [ 9.36080884  1.0313168   5.          0.6330142  14.          0.51274968]. \t  -0.6459684741407418 \t -0.4743330993644729\n",
            "9      \t [ 3.89599673  7.59173972  5.          0.94509004 14.          0.68417344]. \t  -0.5757237316898676 \t -0.4743330993644729\n",
            "10     \t [4.3552321  3.34830177 9.         0.76229473 1.         0.13073039]. \t  -0.6974379414299371 \t -0.4743330993644729\n",
            "11     \t [ 8.34799874  7.25398106 12.          0.79127771  8.          0.66608041]. \t  -0.5650351752891302 \t -0.4743330993644729\n",
            "12     \t [ 3.91025291  0.94746935  6.          0.83827135 18.          0.68489482]. \t  -0.5761732475509362 \t -0.4743330993644729\n",
            "13     \t [ 1.41127451  0.02455301 14.          0.99438541  9.          0.56009967]. \t  -0.6155173676416096 \t -0.4743330993644729\n",
            "14     \t [ 7.09557213  0.02461437 14.          0.76122797 15.          0.64719348]. \t  -0.5671440080891083 \t -0.4743330993644729\n",
            "15     \t [4.17102171 2.37589806 9.         0.69724056 2.         0.3810416 ]. \t  -0.6868911213834418 \t -0.4743330993644729\n",
            "16     \t [0.  0.  5.  0.5 1.  0.1]. \t  -0.6979248471795549 \t -0.4743330993644729\n",
            "17     \t [ 9.39083863  5.32748652 10.          0.99453894 14.          0.35726977]. \t  -0.6887084257210615 \t -0.4743330993644729\n",
            "18     \t [ 7.9436584   8.63416202  5.          0.90235853 19.          0.37180179]. \t  -0.6881238418287372 \t -0.4743330993644729\n",
            "19     \t [ 1.30779693  9.32518463 14.          0.80733828 19.          0.87810773]. \t  \u001b[92m-0.4716209737148477\u001b[0m \t -0.4716209737148477\n",
            "20     \t [0.01993927 9.65913928 7.         0.55264739 8.         0.94506564]. \t  -0.49306942918418556 \t -0.4716209737148477\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.772034603321413"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TaP6RoGuiNT",
        "outputId": "cdc80536-31a2-44bb-8fda-ac628bcb832f"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 16 \n",
        "\n",
        "np.random.seed(run_num_16)\n",
        "surrogate_exact_16 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train16, X_test16, y_train16, y_test16 = train_test_split(X, y, test_size=test_perc, random_state=run_num_16)\n",
        "\n",
        "def f_syn_polarity16(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_16, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train16, y=y_train16).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_16 = dGPGO(surrogate_exact_16, Acquisition_new(util_exact), f_syn_polarity16, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_16.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_16 = exact_16.getResult()[0]\n",
        "params_exact_16['max_depth'] = int(params_exact_16['max_depth'])\n",
        "params_exact_16['min_child_weight'] = int(params_exact_16['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train16 = xgb.DMatrix(X_train16, y_train16)\n",
        "dX_exact_test16 = xgb.DMatrix(X_test16, y_test16)\n",
        "model_exact_16 = xgb.train(params_exact_16, dX_exact_train16)\n",
        "pred_exact_16 = model_exact_16.predict(dX_exact_test16)\n",
        "\n",
        "rmse_exact_16 = np.sqrt(mean_squared_error(pred_exact_16, y_test16))\n",
        "rmse_exact_16"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [2.23291079 5.23163341 6.         0.65430839 5.         0.30077285]. \t  -0.6357813258069683 \t -0.6345701590947206\n",
            "init   \t [6.88726162 1.63731425 7.         0.97050543 2.         0.25392012]. \t  -0.7029752724132097 \t -0.6345701590947206\n",
            "init   \t [ 5.94328983  5.6393473   5.          0.67602695 19.          0.42538144]. \t  -0.6345701590947206 \t -0.6345701590947206\n",
            "init   \t [ 0.88741148  3.08148142 14.          0.56043938  9.          0.27515386]. \t  -0.7076230970293895 \t -0.6345701590947206\n",
            "init   \t [ 2.74631586  1.30996118 11.          0.52160786  8.          0.27956463]. \t  -0.7061563820165734 \t -0.6345701590947206\n",
            "1      \t [ 7.8937256   1.5972923  14.          0.61610774 17.          0.78739284]. \t  \u001b[92m-0.5498317738591506\u001b[0m \t -0.5498317738591506\n",
            "2      \t [ 9.01655783  8.21383177  9.          0.60772965 10.          0.9401803 ]. \t  \u001b[92m-0.4830822737254163\u001b[0m \t -0.4830822737254163\n",
            "3      \t [ 4.35132073  9.89698316 12.          0.94137984 16.          0.57741056]. \t  -0.5389659972108385 \t -0.4830822737254163\n",
            "4      \t [ 3.38377852  9.31285251 11.          0.88244942  1.          0.67627774]. \t  -0.5404220213450739 \t -0.4830822737254163\n",
            "5      \t [ 0.02157337  9.97534925  5.          0.75404051 13.          0.40760752]. \t  -0.6336754873953304 \t -0.4830822737254163\n",
            "6      \t [ 0.19317903  0.6596816   6.          0.86233301 15.          0.41906313]. \t  -0.6308098904949025 \t -0.4830822737254163\n",
            "7      \t [ 9.2502617   3.00821528  6.          0.66523104 13.          0.86141057]. \t  -0.4940033314748349 \t -0.4830822737254163\n",
            "8      \t [ 6.47975614  6.0777358  14.          0.94769551 10.          0.71957196]. \t  -0.5294319908052441 \t -0.4830822737254163\n",
            "9      \t [0.  0.  5.  0.5 1.  0.1]. \t  -0.7101090677178151 \t -0.4830822737254163\n",
            "10     \t [8.12731949 9.23712019 5.         0.71442381 2.         0.11528188]. \t  -0.7071533993846538 \t -0.4830822737254163\n",
            "11     \t [ 2.41144535  2.21533362 12.          0.76496867  2.          0.96363399]. \t  \u001b[92m-0.4574614661469763\u001b[0m \t -0.4574614661469763\n",
            "12     \t [ 1.24563612  3.10729143 13.          0.58075831 18.          0.47226166]. \t  -0.573887601427922 \t -0.4574614661469763\n",
            "13     \t [ 8.07210564  2.37313091 13.          0.95420407  5.          0.85204589]. \t  -0.5309549313126745 \t -0.4574614661469763\n",
            "14     \t [2.43756281e-03 1.86203502e-01 1.10000000e+01 5.84519618e-01\n",
            " 1.30000000e+01 2.30149841e-01]. \t  -0.7072748319481598 \t -0.4574614661469763\n",
            "15     \t [ 0.04536026  8.66345072  8.          0.81293119 18.          0.29833721]. \t  -0.6309006075443738 \t -0.4574614661469763\n",
            "16     \t [ 9.28336661  6.57187836 11.          0.54297007 17.          0.56210295]. \t  -0.5785906968518683 \t -0.4574614661469763\n",
            "17     \t [ 8.15124198  9.52841363 14.          0.99393976  5.          0.10936576]. \t  -0.7040869215530783 \t -0.4574614661469763\n",
            "18     \t [ 7.67925358  0.29024289 11.          0.73122052 11.          0.40437158]. \t  -0.6338548926200112 \t -0.4574614661469763\n",
            "19     \t [ 6.18013749  9.69222015  6.          0.87704216 14.          0.79491401]. \t  -0.5399181165937633 \t -0.4574614661469763\n",
            "20     \t [ 4.77306317  4.41011512 11.          0.84776341 14.          0.81171734]. \t  -0.5369344236849007 \t -0.4574614661469763\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.701236723580356"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiOaMUmgulbx",
        "outputId": "e7b2b9b9-8d7c-4085-e9a3-81ab668220b8"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 17 \n",
        "\n",
        "np.random.seed(run_num_17)\n",
        "surrogate_exact_17 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train17, X_test17, y_train17, y_test17 = train_test_split(X, y, test_size=test_perc, random_state=run_num_17)\n",
        "\n",
        "def f_syn_polarity17(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_17, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train17, y=y_train17).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_17 = dGPGO(surrogate_exact_17, Acquisition_new(util_exact), f_syn_polarity17, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_17.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_17 = exact_17.getResult()[0]\n",
        "params_exact_17['max_depth'] = int(params_exact_17['max_depth'])\n",
        "params_exact_17['min_child_weight'] = int(params_exact_17['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train17 = xgb.DMatrix(X_train17, y_train17)\n",
        "dX_exact_test17 = xgb.DMatrix(X_test17, y_test17)\n",
        "model_exact_17 = xgb.train(params_exact_17, dX_exact_train17)\n",
        "pred_exact_17 = model_exact_17.predict(dX_exact_test17)\n",
        "\n",
        "rmse_exact_17 = np.sqrt(mean_squared_error(pred_exact_17, y_test17))\n",
        "rmse_exact_17"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 2.94665003  5.30586756 11.          0.94443241 14.          0.80828691]. \t  -0.48092361225642916 \t -0.48092361225642916\n",
            "init   \t [ 6.56333522  6.37520896 12.          0.81487881 18.          0.42203224]. \t  -0.634455605137701 \t -0.48092361225642916\n",
            "init   \t [ 9.45683187  0.6004468  11.          0.5171566  10.          0.53881211]. \t  -0.6046684392629649 \t -0.48092361225642916\n",
            "init   \t [2.72705857 1.19063434 6.         0.74176431 6.         0.10101151]. \t  -0.6562801618178493 \t -0.48092361225642916\n",
            "init   \t [ 4.77631812  5.24671297 13.          0.66254476 19.          0.36708086]. \t  -0.6415104035419145 \t -0.48092361225642916\n",
            "1      \t [ 0.65702322  5.79284078 13.          0.75136902  1.          0.30306068]. \t  -0.6424064809093688 \t -0.48092361225642916\n",
            "2      \t [ 6.93446178  8.68032298 13.          0.78195789  7.          0.91906958]. \t  \u001b[92m-0.47529593119031155\u001b[0m \t -0.47529593119031155\n",
            "3      \t [9.72843652 3.88893279 9.         0.6901555  1.         0.31608219]. \t  -0.6407338037654788 \t -0.47529593119031155\n",
            "4      \t [ 9.65057736  8.52725784  5.          0.68420234 13.          0.40008732]. \t  -0.6446152251367371 \t -0.47529593119031155\n",
            "5      \t [ 4.97204887  2.40072226  5.          0.54268748 19.          0.30995407]. \t  -0.6473150344064219 \t -0.47529593119031155\n",
            "6      \t [0.12174033 8.73496008 5.         0.89827646 5.         0.85354798]. \t  -0.4993728869548043 \t -0.47529593119031155\n",
            "7      \t [ 2.91443079  0.16723755 13.          0.598201    6.          0.91729605]. \t  -0.48363736808522184 \t -0.47529593119031155\n",
            "8      \t [7.20615247 9.36901627 6.         0.85465034 7.         0.6878262 ]. \t  -0.5223074457605629 \t -0.47529593119031155\n",
            "9      \t [ 9.02586164  0.59354638 10.          0.86038693 18.          0.90794111]. \t  -0.48184301693459747 \t -0.47529593119031155\n",
            "10     \t [ 1.66641474  7.47633023  5.          0.68203645 17.          0.15512069]. \t  -0.6612773320145335 \t -0.47529593119031155\n",
            "11     \t [ 0.12410542  7.60180472 13.          0.97425003  8.          0.76245421]. \t  \u001b[92m-0.47195842108145214\u001b[0m \t -0.47195842108145214\n",
            "12     \t [0.         0.         8.68066173 0.5        1.         0.1       ]. \t  -0.6623843987781577 \t -0.47195842108145214\n",
            "13     \t [9.59190042 1.26233772 5.         0.55398722 6.         0.46259714]. \t  -0.6127976173878007 \t -0.47195842108145214\n",
            "14     \t [ 9.06002681  9.03779351 14.          0.60614154  1.          0.16421461]. \t  -0.6627557424336108 \t -0.47195842108145214\n",
            "15     \t [ 0.91894312  0.          5.          0.5        14.21833141  0.1       ]. \t  -0.6641565627867368 \t -0.47195842108145214\n",
            "16     \t [ 8.69529605  0.27226865 14.          0.90636352  1.          0.39638219]. \t  -0.6352506435607296 \t -0.47195842108145214\n",
            "17     \t [ 4.56335883  2.35318071 11.          0.75925047 16.          0.7697429 ]. \t  -0.4897622420273162 \t -0.47195842108145214\n",
            "18     \t [ 0.25691043  8.80430419 11.          0.61482757 19.          0.833227  ]. \t  -0.497522195612467 \t -0.47195842108145214\n",
            "19     \t [ 9.24004771  6.36004976 11.          0.81644504 12.          0.66235401]. \t  -0.5080582866060617 \t -0.47195842108145214\n",
            "20     \t [ 7.9822505   0.1930237   5.          0.88184327 12.          0.30139498]. \t  -0.6375373096353469 \t -0.47195842108145214\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.758964442352727"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H4MWSXFcZjO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a62773d-5b69-438a-ce96-c86fb0e9ea87"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 18 \n",
        "\n",
        "np.random.seed(run_num_18)\n",
        "surrogate_exact_18 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train18, X_test18, y_train18, y_test18 = train_test_split(X, y, test_size=test_perc, random_state=run_num_18)\n",
        "\n",
        "def f_syn_polarity18(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_18, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train18, y=y_train18).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_18 = dGPGO(surrogate_exact_18, Acquisition_new(util_exact), f_syn_polarity18, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_18.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_18 = exact_18.getResult()[0]\n",
        "params_exact_18['max_depth'] = int(params_exact_18['max_depth'])\n",
        "params_exact_18['min_child_weight'] = int(params_exact_18['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train18 = xgb.DMatrix(X_train18, y_train18)\n",
        "dX_exact_test18 = xgb.DMatrix(X_test18, y_test18)\n",
        "model_exact_18 = xgb.train(params_exact_18, dX_exact_train18)\n",
        "pred_exact_18 = model_exact_18.predict(dX_exact_test18)\n",
        "\n",
        "rmse_exact_18 = np.sqrt(mean_squared_error(pred_exact_18, y_test18))\n",
        "rmse_exact_18"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [6.50374242 5.05453374 6.         0.59092011 3.         0.28357516]. \t  -0.6408812889056655 \t -0.45563901799042095\n",
            "init   \t [0.11506734 4.26891483 9.         0.81785956 5.         0.63489043]. \t  -0.5015618704267137 \t -0.45563901799042095\n",
            "init   \t [ 2.8861259   6.35547834 11.          0.64267955 14.          0.27877092]. \t  -0.6438813467576416 \t -0.45563901799042095\n",
            "init   \t [6.57189031 6.99655629 8.         0.63235896 4.         0.52894035]. \t  -0.5434165841486521 \t -0.45563901799042095\n",
            "init   \t [ 6.66600348  2.11312037 14.          0.74363461  4.          0.73174558]. \t  -0.45563901799042095 \t -0.45563901799042095\n",
            "1      \t [ 8.67093232  0.11649132  5.          0.92962202 15.          0.53672863]. \t  -0.5446894741691042 \t -0.45563901799042095\n",
            "2      \t [ 8.43851229  2.41114508 13.          0.75771586 19.          0.86905071]. \t  \u001b[92m-0.4388122674991237\u001b[0m \t -0.4388122674991237\n",
            "3      \t [ 9.44281001  9.01534322  7.          0.99142432 16.          0.37631199]. \t  -0.6085057891370991 \t -0.4388122674991237\n",
            "4      \t [ 3.19538294  9.91737336 14.          0.7976317   5.          0.25704487]. \t  -0.6461355983082889 \t -0.4388122674991237\n",
            "5      \t [ 1.97643014  8.37982471  5.          0.63246176 17.          0.45403539]. \t  -0.5418357136590688 \t -0.4388122674991237\n",
            "6      \t [ 1.26601315  0.31299408  6.          0.95296222 16.          0.13649883]. \t  -0.6415890749054423 \t -0.4388122674991237\n",
            "7      \t [ 1.18347798  2.03195078 14.          0.62549517 10.          0.6517083 ]. \t  -0.4904188649425268 \t -0.4388122674991237\n",
            "8      \t [6.72039962 1.0287777  9.         0.62848622 9.         0.70815446]. \t  -0.500682280008227 \t -0.4388122674991237\n",
            "9      \t [ 7.49192948  9.60283663 14.          0.93718151 19.          0.24625933]. \t  -0.6450414392723344 \t -0.4388122674991237\n",
            "10     \t [ 3.63870552  9.73349763  7.          0.73625258 11.          0.87968363]. \t  -0.4451950322267574 \t -0.4388122674991237\n",
            "11     \t [0.         0.         5.90250308 0.5        1.         0.1       ]. \t  -0.6425312957388465 \t -0.4388122674991237\n",
            "12     \t [ 1.68019344  0.20490035 13.          0.89332378 19.          0.17761947]. \t  -0.6459442308420904 \t -0.4388122674991237\n",
            "13     \t [ 9.38974126  5.86345962 14.          0.7410326  12.          0.80551421]. \t  -0.4571344681957464 \t -0.4388122674991237\n",
            "14     \t [ 0.81446253  9.28654597 10.          0.69058086  1.          0.88113937]. \t  -0.4399183519742422 \t -0.4388122674991237\n",
            "15     \t [0.         0.         5.         0.5        8.29200619 0.1       ]. \t  -0.6434438049617356 \t -0.4388122674991237\n",
            "16     \t [ 7.5232407   0.14021923 14.          0.63702182 13.          0.19869251]. \t  -0.6427128700884437 \t -0.4388122674991237\n",
            "17     \t [9.18740115 8.8684293  7.         0.964289   9.         0.7517104 ]. \t  -0.45573491608277106 \t -0.4388122674991237\n",
            "18     \t [ 9.56072091  9.1368036  14.          0.68050527  1.          0.47597207]. \t  -0.5470344217999699 \t -0.4388122674991237\n",
            "19     \t [ 6.33394188  3.31142716  8.          0.64110795 18.          0.66631055]. \t  -0.5027625467774752 \t -0.4388122674991237\n",
            "20     \t [ 1.47346798  3.42280397 13.          0.87173303  1.          0.71719115]. \t  -0.4411780295132647 \t -0.4388122674991237\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.746067780922308"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-zaPbk2uuzH",
        "outputId": "dcd8d6ce-d054-4bc9-f49e-ec05098d5ff6"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 19 \n",
        "\n",
        "np.random.seed(run_num_19)\n",
        "surrogate_exact_19 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train19, X_test19, y_train19, y_test19 = train_test_split(X, y, test_size=test_perc, random_state=run_num_19)\n",
        "\n",
        "def f_syn_polarity19(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_19, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train19, y=y_train19).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_19 = dGPGO(surrogate_exact_19, Acquisition_new(util_exact), f_syn_polarity19, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_19.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_19 = exact_19.getResult()[0]\n",
        "params_exact_19['max_depth'] = int(params_exact_19['max_depth'])\n",
        "params_exact_19['min_child_weight'] = int(params_exact_19['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train19 = xgb.DMatrix(X_train19, y_train19)\n",
        "dX_exact_test19 = xgb.DMatrix(X_test19, y_test19)\n",
        "model_exact_19 = xgb.train(params_exact_19, dX_exact_train19)\n",
        "pred_exact_19 = model_exact_19.predict(dX_exact_test19)\n",
        "\n",
        "rmse_exact_19 = np.sqrt(mean_squared_error(pred_exact_19, y_test19))\n",
        "rmse_exact_19"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 0.97533602  7.61249717 13.          0.85765469 11.          0.39830191]. \t  -0.5851081958447377 \t -0.4870287725699859\n",
            "init   \t [ 0.82999565  6.71977081  6.          0.50407413 19.          0.67209466]. \t  -0.5245729886945251 \t -0.4870287725699859\n",
            "init   \t [ 2.15923256  5.49027432 12.          0.52588686 10.          0.20235326]. \t  -0.677999989539271 \t -0.4870287725699859\n",
            "init   \t [4.99659267 1.52108422 6.         0.73481085 4.         0.71949465]. \t  -0.4940235599803803 \t -0.4870287725699859\n",
            "init   \t [ 3.72927156  9.46160045  5.          0.80554614 18.          0.97708466]. \t  -0.4870287725699859 \t -0.4870287725699859\n",
            "1      \t [ 8.33060043  1.42030563  8.          0.92863724 14.          0.78606141]. \t  \u001b[92m-0.48699206254226385\u001b[0m \t -0.48699206254226385\n",
            "2      \t [ 4.70068371  4.9755295  14.          0.98901029  1.          0.96039614]. \t  \u001b[92m-0.454763872590455\u001b[0m \t -0.454763872590455\n",
            "3      \t [5.72592037 9.8573523  7.         0.62344236 5.         0.18058155]. \t  -0.6798800603605933 \t -0.454763872590455\n",
            "4      \t [ 3.65000245  2.90359952 13.          0.98940034 19.          0.29019455]. \t  -0.5803493338026307 \t -0.454763872590455\n",
            "5      \t [ 9.25987473  8.07672103 11.          0.53393029 18.          0.59858945]. \t  -0.5118733553375746 \t -0.454763872590455\n",
            "6      \t [ 9.76186054  4.90300619 10.          0.67721911  6.          0.88084199]. \t  -0.4682001417984802 \t -0.454763872590455\n",
            "7      \t [ 1.86342862  0.38142632  7.          0.62393245 10.          0.46180447]. \t  -0.5682060751104595 \t -0.454763872590455\n",
            "8      \t [1.60895472e-01 8.27074864e-03 1.30000000e+01 6.91893018e-01\n",
            " 5.00000000e+00 4.60327119e-01]. \t  -0.5676975299111877 \t -0.454763872590455\n",
            "9      \t [ 0.32873959  7.7155114   5.          0.56871173 11.          0.34471029]. \t  -0.5850396812677789 \t -0.454763872590455\n",
            "10     \t [ 6.55489773  0.06438745 14.          0.53351105 11.          0.76391016]. \t  -0.4835963309582638 \t -0.454763872590455\n",
            "11     \t [ 6.96994971  9.387078    8.          0.7367405  12.          0.10249646]. \t  -0.6800907597326502 \t -0.454763872590455\n",
            "12     \t [ 0.77535612  8.78405201 10.          0.78862322  1.          0.52634822]. \t  -0.5630745983947831 \t -0.454763872590455\n",
            "13     \t [ 3.86326609  1.40312943  6.          0.7852563  18.          0.23797267]. \t  -0.6783515415434671 \t -0.454763872590455\n",
            "14     \t [ 8.38895111  9.39819527 14.          0.57861776  4.          0.75378716]. \t  -0.48811013508761436 \t -0.454763872590455\n",
            "15     \t [ 0.11219244  8.71714366 12.          0.84271463 17.          0.71017966]. \t  -0.49865128698956995 \t -0.454763872590455\n",
            "16     \t [0.        0.        5.        0.5       1.1548736 0.1      ]. \t  -0.6806130073081017 \t -0.454763872590455\n",
            "17     \t [ 9.89996921  0.59570014 13.          0.67906413  1.          0.37793763]. \t  -0.5890751717161915 \t -0.454763872590455\n",
            "18     \t [ 9.4335981   8.77998409 14.          0.6133824  11.          0.10869753]. \t  -0.6785740560675692 \t -0.454763872590455\n",
            "19     \t [6.1285861  5.61245367 5.         0.51193162 9.         0.99608349]. \t  -0.49631001660661783 \t -0.454763872590455\n",
            "20     \t [1.56098356 6.50826155 8.         0.88730571 6.         0.9791372 ]. \t  -0.46297256698184375 \t -0.454763872590455\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.63424117920896"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvkuHKlQuxRy",
        "outputId": "2908199f-fd8a-4dbe-fc14-d760b9d344da"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 20 \n",
        "\n",
        "np.random.seed(run_num_20)\n",
        "surrogate_exact_20 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train20, X_test20, y_train20, y_test20 = train_test_split(X, y, test_size=test_perc, random_state=run_num_20)\n",
        "\n",
        "def f_syn_polarity20(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_20, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train20, y=y_train20).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_20 = dGPGO(surrogate_exact_20, Acquisition_new(util_exact), f_syn_polarity20, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_20.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_20 = exact_20.getResult()[0]\n",
        "params_exact_20['max_depth'] = int(params_exact_20['max_depth'])\n",
        "params_exact_20['min_child_weight'] = int(params_exact_20['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train20 = xgb.DMatrix(X_train20, y_train20)\n",
        "dX_exact_test20 = xgb.DMatrix(X_test20, y_test20)\n",
        "model_exact_20 = xgb.train(params_exact_20, dX_exact_train20)\n",
        "pred_exact_20 = model_exact_20.predict(dX_exact_test20)\n",
        "\n",
        "rmse_exact_20 = np.sqrt(mean_squared_error(pred_exact_20, y_test20))\n",
        "rmse_exact_20"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 5.88130801  8.97713728 14.          0.81074445  8.          0.95540649]. \t  -0.4485352768858121 \t -0.4485352768858121\n",
            "init   \t [6.72865655 0.41173329 8.         0.6361582  7.         0.76174061]. \t  -0.47208091450542966 \t -0.4485352768858121\n",
            "init   \t [ 4.77387703  8.66202323 10.          0.51833215  7.          0.10123387]. \t  -0.7316473600840852 \t -0.4485352768858121\n",
            "init   \t [ 5.75489985  4.74524381  8.          0.78084343 15.          0.26643049]. \t  -0.7314226542252507 \t -0.4485352768858121\n",
            "init   \t [ 4.53444     4.47342833  8.          0.91974896 18.          0.35997552]. \t  -0.6494230116583573 \t -0.4485352768858121\n",
            "1      \t [ 7.96566073  7.15509535  7.          0.79906691 11.          0.34132075]. \t  -0.6502222800629637 \t -0.4485352768858121\n",
            "2      \t [ 1.98667885  1.35773177 13.          0.57199118  2.          0.39498908]. \t  -0.6661970064789862 \t -0.4485352768858121\n",
            "3      \t [ 3.00704909  2.42524876 14.          0.95062509 15.          0.83595087]. \t  -0.4577111911042998 \t -0.4485352768858121\n",
            "4      \t [2.60714073 4.21905962 5.         0.5        2.43949111 0.1       ]. \t  -0.7322260277870013 \t -0.4485352768858121\n",
            "5      \t [ 9.60625049  8.19354987 13.          0.6912874  18.          0.13826635]. \t  -0.7314105574615608 \t -0.4485352768858121\n",
            "6      \t [ 8.79913956  5.84239608 13.          0.98638201  1.          0.70495849]. \t  -0.4953677800811775 \t -0.4485352768858121\n",
            "7      \t [ 0.72788527  2.26655356 10.          0.97273032 15.          0.85843758]. \t  -0.4523452808760881 \t -0.4485352768858121\n",
            "8      \t [4.62702633 9.6876243  5.         0.9923406  1.         0.38132515]. \t  -0.6522172440468724 \t -0.4485352768858121\n",
            "9      \t [ 1.44692101  9.96202174 12.          0.76092884 18.          0.10523817]. \t  -0.731303133317551 \t -0.4485352768858121\n",
            "10     \t [ 1.01814405  9.81807131 14.          0.52908047  1.          0.89345697]. \t  -0.4570018264326601 \t -0.4485352768858121\n",
            "11     \t [9.53736401 9.25093671 6.         0.95646227 5.         0.53751962]. \t  -0.5717284676909282 \t -0.4485352768858121\n",
            "12     \t [ 9.95790482  0.39582549 14.          0.73682131 13.          0.88500223]. \t  -0.46684081731949795 \t -0.4485352768858121\n",
            "13     \t [7.12982753 6.84003365 7.         0.76458922 2.         0.82832765]. \t  -0.4776155563767387 \t -0.4485352768858121\n",
            "14     \t [ 7.47036597  0.87634126 13.          0.90366023 19.          0.17017133]. \t  -0.732072189688284 \t -0.4485352768858121\n",
            "15     \t [ 5.37444991  0.3056877   9.          0.99777328 15.          0.5903115 ]. \t  -0.5051733349539412 \t -0.4485352768858121\n",
            "16     \t [0.         0.         5.99088653 0.5        9.99088653 0.1       ]. \t  -0.7306870228413046 \t -0.4485352768858121\n",
            "17     \t [ 0.0269108   5.63927067 14.          0.80391219 10.          0.28928667]. \t  -0.6555537944017766 \t -0.4485352768858121\n",
            "18     \t [ 6.16018658  2.45414677 14.          0.93866062  8.          0.74546669]. \t  -0.4544981816339891 \t -0.4485352768858121\n",
            "19     \t [ 9.64898386  6.20494423  6.          0.8469719  19.          0.57533849]. \t  -0.5209730469573338 \t -0.4485352768858121\n",
            "20     \t [9.07371937 0.79321581 6.         0.88798724 2.         0.43366394]. \t  -0.5701703307285997 \t -0.4485352768858121\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.454763173494824"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFKuwvS3uzrs",
        "outputId": "08111fac-da3f-45b0-b9cc-3b577c7a561e"
      },
      "source": [
        "end_exact = time.time()\n",
        "end_exact\n",
        "\n",
        "time_exact = end_exact - start_exact\n",
        "time_exact"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "685.1470732688904"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CU2FlhY4vHUk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b90e57d-9973-4413-da93-e9dd574cc041"
      },
      "source": [
        "rmse_approx = [rmse_approx_1,\n",
        "rmse_approx_2,\n",
        "rmse_approx_3,\n",
        "rmse_approx_4,\n",
        "rmse_approx_5,\n",
        "rmse_approx_6,\n",
        "rmse_approx_7,\n",
        "rmse_approx_8,\n",
        "rmse_approx_9,\n",
        "rmse_approx_10,\n",
        "rmse_approx_11,\n",
        "rmse_approx_12,\n",
        "rmse_approx_13,\n",
        "rmse_approx_14,\n",
        "rmse_approx_15,\n",
        "rmse_approx_16,\n",
        "rmse_approx_17,\n",
        "rmse_approx_18,\n",
        "rmse_approx_19,\n",
        "rmse_approx_20]\n",
        "\n",
        "np.mean(rmse_approx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.712012294225476"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZ53FsWXu3J1",
        "outputId": "6428130d-d2f5-44c6-e156-03520aa708f4"
      },
      "source": [
        "rmse_exact = [rmse_exact_1,\n",
        "rmse_exact_2,\n",
        "rmse_exact_3,\n",
        "rmse_exact_4,\n",
        "rmse_exact_5,\n",
        "rmse_exact_6,\n",
        "rmse_exact_7,\n",
        "rmse_exact_8,\n",
        "rmse_exact_9,\n",
        "rmse_exact_10,\n",
        "rmse_exact_11,\n",
        "rmse_exact_12,\n",
        "rmse_exact_13,\n",
        "rmse_exact_14,\n",
        "rmse_exact_15,\n",
        "rmse_exact_16,\n",
        "rmse_exact_17,\n",
        "rmse_exact_18,\n",
        "rmse_exact_19,\n",
        "rmse_exact_20]\n",
        "\n",
        "np.mean(rmse_exact)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.720981224272282"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9FOyoH8u5Wx",
        "outputId": "d5acfb07-7c72-40d3-f4bb-211ce822c53f"
      },
      "source": [
        "min_rmse_approx = min_max_array(rmse_approx)\n",
        "min_rmse_approx, len(min_rmse_approx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([4.667222167746296,\n",
              "  4.600295852493361,\n",
              "  4.600295852493361,\n",
              "  4.600295852493361,\n",
              "  4.600295852493361,\n",
              "  4.600295852493361,\n",
              "  4.499924380514474,\n",
              "  4.499924380514474,\n",
              "  4.499924380514474,\n",
              "  4.499924380514474,\n",
              "  4.499924380514474,\n",
              "  4.499924380514474,\n",
              "  4.499924380514474,\n",
              "  4.499924380514474,\n",
              "  4.499924380514474,\n",
              "  4.499924380514474,\n",
              "  4.499924380514474,\n",
              "  4.499924380514474,\n",
              "  4.499924380514474,\n",
              "  4.454763173494824],\n",
              " 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unXOpKHcvO15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0de384f0-a752-40bc-a050-54da7b7e8acd"
      },
      "source": [
        "min_rmse_exact = min_max_array(rmse_exact)\n",
        "min_rmse_exact, len(min_rmse_exact)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([4.667222167746296,\n",
              "  4.600295852493361,\n",
              "  4.600295852493361,\n",
              "  4.600295852493361,\n",
              "  4.600295852493361,\n",
              "  4.571943125342289,\n",
              "  4.499924380514474,\n",
              "  4.462721253378859,\n",
              "  4.462721253378859,\n",
              "  4.462721253378859,\n",
              "  4.462721253378859,\n",
              "  4.462721253378859,\n",
              "  4.462721253378859,\n",
              "  4.462721253378859,\n",
              "  4.462721253378859,\n",
              "  4.462721253378859,\n",
              "  4.462721253378859,\n",
              "  4.462721253378859,\n",
              "  4.462721253378859,\n",
              "  4.454763173494824],\n",
              " 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yxo85-HEvRPi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "048a84b0-cfbd-4b2d-fd82-32ad1ac310ff"
      },
      "source": [
        "### Visualise!\n",
        "\n",
        "title = obj_func\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(min_rmse_approx, color = 'Green', label='RMSE: GP EI ')\n",
        "plt.plot(min_rmse_exact, color = 'Red', label='RMSE: GP dEI ')# r'($\\nu$' ' = {})'.format(df))\n",
        "\n",
        "plt.title(title, weight = 'bold', family = 'Arial')\n",
        "plt.xlabel('Experiment(s)', weight = 'bold', family = 'Arial') # x-axis label\n",
        "plt.ylabel('RMSE ($)', weight = 'bold', family = 'Arial') # y-axis label\n",
        "plt.legend(loc=0) # add plot legend\n",
        "\n",
        "### Make the x-ticks integers, not floats:\n",
        "count = len(min_rmse_approx)\n",
        "plt.xticks(np.arange(count), np.arange(1, count + 1))\n",
        "plt.grid(b=None)\n",
        "plt.show() #visualize!\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwyO7_iZvT7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "450839cc-84e2-4e62-c9f1-68c8edef2bba"
      },
      "source": [
        "time_approx, time_exact"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(802.8092265129089, 685.1470732688904)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHLA-0DnVXxD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}